{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "949d3f63-8150-413e-ad58-593e114a8d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5459bf03-ff49-4b49-8359-38fc235ad52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Preview:\n",
      "                 id                                       comment_text  toxic  \\\n",
      "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
      "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
      "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
      "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
      "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
      "\n",
      "   severe_toxic  obscene  threat  insult  identity_hate  \\\n",
      "0             0        0       0       0              0   \n",
      "1             0        0       0       0              0   \n",
      "2             0        0       0       0              0   \n",
      "3             0        0       0       0              0   \n",
      "4             0        0       0       0              0   \n",
      "\n",
      "                                cleaned_comment_text  \\\n",
      "0  explanation why the edits made under my userna...   \n",
      "1  daww he matches this background colour im seem...   \n",
      "2  hey man im really not trying to edit war its j...   \n",
      "3   more i cant make any real suggestions on impr...   \n",
      "4  you sir are my hero any chance you remember wh...   \n",
      "\n",
      "                              processed_comment_text  \n",
      "0  explanation edits made username hardcore metal...  \n",
      "1  daww match background colour im seemingly stuc...  \n",
      "2  hey man im really trying edit war guy constant...  \n",
      "3  cant make real suggestion improvement wondered...  \n",
      "4                sir hero chance remember page thats  \n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 10 columns):\n",
      " #   Column                  Non-Null Count   Dtype \n",
      "---  ------                  --------------   ----- \n",
      " 0   id                      159571 non-null  object\n",
      " 1   comment_text            159571 non-null  object\n",
      " 2   toxic                   159571 non-null  int64 \n",
      " 3   severe_toxic            159571 non-null  int64 \n",
      " 4   obscene                 159571 non-null  int64 \n",
      " 5   threat                  159571 non-null  int64 \n",
      " 6   insult                  159571 non-null  int64 \n",
      " 7   identity_hate           159571 non-null  int64 \n",
      " 8   cleaned_comment_text    159567 non-null  object\n",
      " 9   processed_comment_text  159538 non-null  object\n",
      "dtypes: int64(6), object(4)\n",
      "memory usage: 12.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "file_path = \"cleaned_train.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows and information about the dataset\n",
    "print(\"Dataset Preview:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nDataset Info:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "370f52d3-13a1-49ab-b9b2-87174915f30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preview of processed_comment_text:\n",
      "0    explanation edits made username hardcore metal...\n",
      "1    daww match background colour im seemingly stuc...\n",
      "2    hey man im really trying edit war guy constant...\n",
      "3    cant make real suggestion improvement wondered...\n",
      "4                  sir hero chance remember page thats\n",
      "Name: processed_comment_text, dtype: object\n",
      "\n",
      "Sum of label columns (to confirm binary values):\n",
      "toxic            15294\n",
      "severe_toxic      1595\n",
      "obscene           8449\n",
      "threat             478\n",
      "insult            7877\n",
      "identity_hate     1405\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check if required columns exist\n",
    "required_columns = ['processed_comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "\n",
    "if missing_columns:\n",
    "    raise ValueError(f\"Missing columns in dataset: {missing_columns}\")\n",
    "\n",
    "# Check if 'processed_comment_text' contains valid tokenized data\n",
    "print(\"\\nPreview of processed_comment_text:\")\n",
    "print(df['processed_comment_text'].head())\n",
    "\n",
    "# Check if labels are binary\n",
    "print(\"\\nSum of label columns (to confirm binary values):\")\n",
    "print(df[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b25f1b4e-658b-4eb1-b927-ebb0c576d4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing text...\n",
      "Tokenization and padding complete!\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Tokenize and build vocabulary\n",
    "def tokenize(texts): \n",
    "    vocab = Counter(word for text in texts for word in text.split())\n",
    "    word_to_idx = {word: idx + 1 for idx, word in enumerate(vocab)}  # Reserve 0 for padding\n",
    "    return [[word_to_idx[word] for word in text.split()] for text in texts], word_to_idx\n",
    "\n",
    "# Tokenize the processed_comment_text\n",
    "print(\"Tokenizing text...\")\n",
    "df['processed_comment_text'] = df['processed_comment_text'].fillna(\"unknown\")\n",
    "df['cleaned_comment_text'] = df['cleaned_comment_text'].fillna(\"unknown\")\n",
    "tokenized_texts, word_to_idx = tokenize(df['processed_comment_text'])\n",
    "\n",
    "# Pad sequences to ensure equal length\n",
    "max_seq_length = 100  # Adjust this based on your dataset or task\n",
    "padded_texts = [seq[:max_seq_length] + [0] * max(0, max_seq_length - len(seq)) for seq in tokenized_texts]\n",
    "\n",
    "# Add tokenized and padded texts back to the dataframe\n",
    "df['tokenized_comment_text'] = padded_texts\n",
    "\n",
    "print(\"Tokenization and padding complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0746911a-79ef-41a5-bb60-5148e9d3f4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df['tokenized_comment_text'].tolist()\n",
    "labels = df[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].values.tolist()\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    texts, labels, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "222240bb-1c11-4830-b90f-5faefd133b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Baseline Logistic Regression Metrics:\n",
      "           Class  accuracy        f1  precision    recall\n",
      "0          toxic  0.957888  0.740240   0.904155  0.626636\n",
      "1   severe_toxic  0.990694  0.366738   0.581081  0.267913\n",
      "2        obscene  0.977283  0.751286   0.912500  0.638484\n",
      "3         threat  0.997807  0.186047   0.666667  0.108108\n",
      "4         insult  0.970359  0.644628   0.818702  0.531599\n",
      "5  identity_hate  0.991759  0.283379   0.712329  0.176871\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = vectorizer.fit_transform(train_data['processed_comment_text'])\n",
    "X_test_tfidf = vectorizer.transform(test_data['processed_comment_text'])\n",
    "\n",
    "labels = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "metrics_lr = {}\n",
    "\n",
    "# Train a Logistic Regression model for each label\n",
    "for label in labels:\n",
    "    y_train = train_data[label]\n",
    "    y_test = test_data[label]\n",
    "\n",
    "    model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "    metrics_lr[label] = {\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'f1': f1_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred),\n",
    "        'recall': recall_score(y_test, y_pred)\n",
    "    }\n",
    "\n",
    "# Display metrics for the baseline model\n",
    "metrics_df_lr = pd.DataFrame([\n",
    "    {'Class': label, **metrics_lr[label]} for label in labels\n",
    "])\n",
    "print(\"\\nBaseline Logistic Regression Metrics:\")\n",
    "print(metrics_df_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4319ad35-67ab-4409-a5ef-8aca16cb1b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoaders created successfully!\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "# Define PyTorch Dataset class\n",
    "class ToxicCommentDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = torch.tensor(texts, dtype=torch.long)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx], self.labels[idx]\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(ToxicCommentDataset(train_texts, train_labels), batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(ToxicCommentDataset(val_texts, val_labels), batch_size=64, shuffle=False)\n",
    "\n",
    "print(\"DataLoaders created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe402bd-114b-480b-8c91-5699177d35d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class IndependentProbabilitiesModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim, num_layers):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, num_layers=num_layers, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        output, _ = self.lstm(embedded)\n",
    "        output = self.dropout(output)\n",
    "        return torch.sigmoid(self.fc(output[:, -1, :]))  # Independent probabilities\n",
    "\n",
    "class JointProbabilitiesModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim, num_layers):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, num_layers=num_layers, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        output, _ = self.lstm(embedded)\n",
    "        output = self.dropout(output)\n",
    "        return torch.softmax(self.fc(output[:, -1, :]), dim=-1)  # Joint probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51b076a2-b90c-482b-81a1-6900dccbad26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models initialized and moved to device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "vocab_size = len(word_to_idx) + 1  # Vocabulary size + 1 for padding\n",
    "embed_dim = 128\n",
    "hidden_dim = 256\n",
    "num_layers = 2\n",
    "output_dim_independent = len(labels)  # Number of labels (6)\n",
    "output_dim_joint = 2 ** len(labels)  # Number of joint label configurations (64)\n",
    "\n",
    "# Initialize models\n",
    "independent_model = IndependentProbabilitiesModel(vocab_size, embed_dim, hidden_dim, output_dim_independent, num_layers)\n",
    "joint_model = JointProbabilitiesModel(vocab_size, embed_dim, hidden_dim, output_dim_joint, num_layers)\n",
    "\n",
    "# Move models to device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "independent_model.to(device)\n",
    "joint_model.to(device)\n",
    "\n",
    "print(\"Models initialized and moved to device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5e418b9-b890-4dc6-8882-285d4b9b79ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training function for the independent model\n",
    "def train_independent_model(model, data_loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for texts, labels in data_loader:\n",
    "        texts, labels = texts.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(texts)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "# Define training function for the joint model\n",
    "def train_joint_model(model, data_loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for texts, labels in data_loader:\n",
    "        texts, labels = texts.to(device), labels.to(device)\n",
    "        labels = torch.argmax(labels, dim=1)  # Convert multi-label to single index\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(texts)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9ad884d-7fd3-435e-a1fc-ea215cc31d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training function for the independent model\n",
    "def train_independent_model(model, data_loader, optimizer, criterion, device, epoch):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    print(f\"\\nTraining Independent Probabilities Model - Epoch {epoch+1}\")\n",
    "    for batch_idx, (texts, labels) in enumerate(data_loader, start=1):\n",
    "        texts, labels = texts.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(texts)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Print progress for every 10 batches\n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f\"Batch {batch_idx}/{len(data_loader)}, Loss: {loss.item():.4f}\")\n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "\n",
    "# Define training function for the joint model\n",
    "def train_joint_model(model, data_loader, optimizer, criterion, device, epoch):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    print(f\"\\nTraining Joint Probability Model - Epoch {epoch+1}\")\n",
    "    for batch_idx, (texts, labels) in enumerate(data_loader, start=1):\n",
    "        texts, labels = texts.to(device), labels.to(device)\n",
    "        labels = torch.argmax(labels, dim=1)  # Convert multi-label to single index\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(texts)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Print progress for every 10 batches\n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f\"Batch {batch_idx}/{len(data_loader)}, Loss: {loss.item():.4f}\")\n",
    "    return total_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1791b0c3-ef63-4e82-bc97-7cf1933f32d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Starting Epoch 1 of Training\n",
      "\n",
      "\n",
      "Training Independent Probabilities Model - Epoch 1\n",
      "Batch 10/1995, Loss: 0.1033\n",
      "Batch 20/1995, Loss: 0.0842\n",
      "Batch 30/1995, Loss: 0.1213\n",
      "Batch 40/1995, Loss: 0.1194\n",
      "Batch 50/1995, Loss: 0.1518\n",
      "Batch 60/1995, Loss: 0.0767\n",
      "Batch 70/1995, Loss: 0.1651\n",
      "Batch 80/1995, Loss: 0.1530\n",
      "Batch 90/1995, Loss: 0.0475\n",
      "Batch 100/1995, Loss: 0.1063\n",
      "Batch 110/1995, Loss: 0.1393\n",
      "Batch 120/1995, Loss: 0.1938\n",
      "Batch 130/1995, Loss: 0.2092\n",
      "Batch 140/1995, Loss: 0.1707\n",
      "Batch 150/1995, Loss: 0.1319\n",
      "Batch 160/1995, Loss: 0.1122\n",
      "Batch 170/1995, Loss: 0.1732\n",
      "Batch 180/1995, Loss: 0.1831\n",
      "Batch 190/1995, Loss: 0.0949\n",
      "Batch 200/1995, Loss: 0.1206\n",
      "Batch 210/1995, Loss: 0.1711\n",
      "Batch 220/1995, Loss: 0.0763\n",
      "Batch 230/1995, Loss: 0.1392\n",
      "Batch 240/1995, Loss: 0.0974\n",
      "Batch 250/1995, Loss: 0.1206\n",
      "Batch 260/1995, Loss: 0.1571\n",
      "Batch 270/1995, Loss: 0.1612\n",
      "Batch 280/1995, Loss: 0.1075\n",
      "Batch 290/1995, Loss: 0.1589\n",
      "Batch 300/1995, Loss: 0.0973\n",
      "Batch 310/1995, Loss: 0.0705\n",
      "Batch 320/1995, Loss: 0.1504\n",
      "Batch 330/1995, Loss: 0.2093\n",
      "Batch 340/1995, Loss: 0.0724\n",
      "Batch 350/1995, Loss: 0.0884\n",
      "Batch 360/1995, Loss: 0.1334\n",
      "Batch 370/1995, Loss: 0.0652\n",
      "Batch 380/1995, Loss: 0.1565\n",
      "Batch 390/1995, Loss: 0.1518\n",
      "Batch 400/1995, Loss: 0.1577\n",
      "Batch 410/1995, Loss: 0.0877\n",
      "Batch 420/1995, Loss: 0.1589\n",
      "Batch 430/1995, Loss: 0.1261\n",
      "Batch 440/1995, Loss: 0.1759\n",
      "Batch 450/1995, Loss: 0.1713\n",
      "Batch 460/1995, Loss: 0.2254\n",
      "Batch 470/1995, Loss: 0.1463\n",
      "Batch 480/1995, Loss: 0.1547\n",
      "Batch 490/1995, Loss: 0.1354\n",
      "Batch 500/1995, Loss: 0.1427\n",
      "Batch 510/1995, Loss: 0.0934\n",
      "Batch 520/1995, Loss: 0.1305\n",
      "Batch 530/1995, Loss: 0.1040\n",
      "Batch 540/1995, Loss: 0.1682\n",
      "Batch 550/1995, Loss: 0.1942\n",
      "Batch 560/1995, Loss: 0.1845\n",
      "Batch 570/1995, Loss: 0.1120\n",
      "Batch 580/1995, Loss: 0.1408\n",
      "Batch 590/1995, Loss: 0.1472\n",
      "Batch 600/1995, Loss: 0.1285\n",
      "Batch 610/1995, Loss: 0.1148\n",
      "Batch 620/1995, Loss: 0.1068\n",
      "Batch 630/1995, Loss: 0.1374\n",
      "Batch 640/1995, Loss: 0.1892\n",
      "Batch 650/1995, Loss: 0.1574\n",
      "Batch 660/1995, Loss: 0.0725\n",
      "Batch 670/1995, Loss: 0.1154\n",
      "Batch 680/1995, Loss: 0.0902\n",
      "Batch 690/1995, Loss: 0.1179\n",
      "Batch 700/1995, Loss: 0.1346\n",
      "Batch 710/1995, Loss: 0.0892\n",
      "Batch 720/1995, Loss: 0.2292\n",
      "Batch 730/1995, Loss: 0.1636\n",
      "Batch 740/1995, Loss: 0.1179\n",
      "Batch 750/1995, Loss: 0.0887\n",
      "Batch 760/1995, Loss: 0.1436\n",
      "Batch 770/1995, Loss: 0.2336\n",
      "Batch 780/1995, Loss: 0.1546\n",
      "Batch 790/1995, Loss: 0.1848\n",
      "Batch 800/1995, Loss: 0.1549\n",
      "Batch 810/1995, Loss: 0.1815\n",
      "Batch 820/1995, Loss: 0.1542\n",
      "Batch 830/1995, Loss: 0.1291\n",
      "Batch 840/1995, Loss: 0.1050\n",
      "Batch 850/1995, Loss: 0.1021\n",
      "Batch 860/1995, Loss: 0.1380\n",
      "Batch 870/1995, Loss: 0.1199\n",
      "Batch 880/1995, Loss: 0.1365\n",
      "Batch 890/1995, Loss: 0.0944\n",
      "Batch 900/1995, Loss: 0.0825\n",
      "Batch 910/1995, Loss: 0.1183\n",
      "Batch 920/1995, Loss: 0.2108\n",
      "Batch 930/1995, Loss: 0.1130\n",
      "Batch 940/1995, Loss: 0.0650\n",
      "Batch 950/1995, Loss: 0.2309\n",
      "Batch 960/1995, Loss: 0.2062\n",
      "Batch 970/1995, Loss: 0.1353\n",
      "Batch 980/1995, Loss: 0.0595\n",
      "Batch 990/1995, Loss: 0.1208\n",
      "Batch 1000/1995, Loss: 0.1241\n",
      "Batch 1010/1995, Loss: 0.1713\n",
      "Batch 1020/1995, Loss: 0.0760\n",
      "Batch 1030/1995, Loss: 0.2586\n",
      "Batch 1040/1995, Loss: 0.1399\n",
      "Batch 1050/1995, Loss: 0.1343\n",
      "Batch 1060/1995, Loss: 0.1084\n",
      "Batch 1070/1995, Loss: 0.0994\n",
      "Batch 1080/1995, Loss: 0.0835\n",
      "Batch 1090/1995, Loss: 0.1318\n",
      "Batch 1100/1995, Loss: 0.0635\n",
      "Batch 1110/1995, Loss: 0.1669\n",
      "Batch 1120/1995, Loss: 0.0791\n",
      "Batch 1130/1995, Loss: 0.1325\n",
      "Batch 1140/1995, Loss: 0.0606\n",
      "Batch 1150/1995, Loss: 0.1257\n",
      "Batch 1160/1995, Loss: 0.1548\n",
      "Batch 1170/1995, Loss: 0.0767\n",
      "Batch 1180/1995, Loss: 0.0626\n",
      "Batch 1190/1995, Loss: 0.1602\n",
      "Batch 1200/1995, Loss: 0.1351\n",
      "Batch 1210/1995, Loss: 0.1336\n",
      "Batch 1220/1995, Loss: 0.0888\n",
      "Batch 1230/1995, Loss: 0.1324\n",
      "Batch 1240/1995, Loss: 0.0323\n",
      "Batch 1250/1995, Loss: 0.1135\n",
      "Batch 1260/1995, Loss: 0.0840\n",
      "Batch 1270/1995, Loss: 0.0944\n",
      "Batch 1280/1995, Loss: 0.1182\n",
      "Batch 1290/1995, Loss: 0.0766\n",
      "Batch 1300/1995, Loss: 0.1164\n",
      "Batch 1310/1995, Loss: 0.1258\n",
      "Batch 1320/1995, Loss: 0.0574\n",
      "Batch 1330/1995, Loss: 0.0577\n",
      "Batch 1340/1995, Loss: 0.1135\n",
      "Batch 1350/1995, Loss: 0.0563\n",
      "Batch 1360/1995, Loss: 0.0753\n",
      "Batch 1370/1995, Loss: 0.0629\n",
      "Batch 1380/1995, Loss: 0.0694\n",
      "Batch 1390/1995, Loss: 0.0909\n",
      "Batch 1400/1995, Loss: 0.1070\n",
      "Batch 1410/1995, Loss: 0.1158\n",
      "Batch 1420/1995, Loss: 0.0835\n",
      "Batch 1430/1995, Loss: 0.0638\n",
      "Batch 1440/1995, Loss: 0.0902\n",
      "Batch 1450/1995, Loss: 0.0454\n",
      "Batch 1460/1995, Loss: 0.0790\n",
      "Batch 1470/1995, Loss: 0.0278\n",
      "Batch 1480/1995, Loss: 0.0396\n",
      "Batch 1490/1995, Loss: 0.0706\n",
      "Batch 1500/1995, Loss: 0.0588\n",
      "Batch 1510/1995, Loss: 0.0509\n",
      "Batch 1520/1995, Loss: 0.1121\n",
      "Batch 1530/1995, Loss: 0.0255\n",
      "Batch 1540/1995, Loss: 0.0900\n",
      "Batch 1550/1995, Loss: 0.1308\n",
      "Batch 1560/1995, Loss: 0.0602\n",
      "Batch 1570/1995, Loss: 0.0649\n",
      "Batch 1580/1995, Loss: 0.1266\n",
      "Batch 1590/1995, Loss: 0.0456\n",
      "Batch 1600/1995, Loss: 0.1025\n",
      "Batch 1610/1995, Loss: 0.1060\n",
      "Batch 1620/1995, Loss: 0.1426\n",
      "Batch 1630/1995, Loss: 0.0425\n",
      "Batch 1640/1995, Loss: 0.0504\n",
      "Batch 1650/1995, Loss: 0.0638\n",
      "Batch 1660/1995, Loss: 0.0349\n",
      "Batch 1670/1995, Loss: 0.0137\n",
      "Batch 1680/1995, Loss: 0.0774\n",
      "Batch 1690/1995, Loss: 0.0547\n",
      "Batch 1700/1995, Loss: 0.0800\n",
      "Batch 1710/1995, Loss: 0.0529\n",
      "Batch 1720/1995, Loss: 0.0522\n",
      "Batch 1730/1995, Loss: 0.0814\n",
      "Batch 1740/1995, Loss: 0.0571\n",
      "Batch 1750/1995, Loss: 0.0320\n",
      "Batch 1760/1995, Loss: 0.1372\n",
      "Batch 1770/1995, Loss: 0.1003\n",
      "Batch 1780/1995, Loss: 0.0359\n",
      "Batch 1790/1995, Loss: 0.0314\n",
      "Batch 1800/1995, Loss: 0.0647\n",
      "Batch 1810/1995, Loss: 0.0586\n",
      "Batch 1820/1995, Loss: 0.0361\n",
      "Batch 1830/1995, Loss: 0.0497\n",
      "Batch 1840/1995, Loss: 0.0470\n",
      "Batch 1850/1995, Loss: 0.0656\n",
      "Batch 1860/1995, Loss: 0.0560\n",
      "Batch 1870/1995, Loss: 0.0742\n",
      "Batch 1880/1995, Loss: 0.0822\n",
      "Batch 1890/1995, Loss: 0.0426\n",
      "Batch 1900/1995, Loss: 0.0528\n",
      "Batch 1910/1995, Loss: 0.0534\n",
      "Batch 1920/1995, Loss: 0.0695\n",
      "Batch 1930/1995, Loss: 0.0348\n",
      "Batch 1940/1995, Loss: 0.0392\n",
      "Batch 1950/1995, Loss: 0.0217\n",
      "Batch 1960/1995, Loss: 0.0654\n",
      "Batch 1970/1995, Loss: 0.0559\n",
      "Batch 1980/1995, Loss: 0.0976\n",
      "Batch 1990/1995, Loss: 0.1105\n",
      "\n",
      "Epoch 1 - Independent Model Training Complete. Loss: 0.1118\n",
      "\n",
      "Training Joint Probability Model - Epoch 1\n",
      "Batch 10/1995, Loss: 3.1922\n",
      "Batch 20/1995, Loss: 3.1856\n",
      "Batch 30/1995, Loss: 3.1854\n",
      "Batch 40/1995, Loss: 3.1854\n",
      "Batch 50/1995, Loss: 3.2008\n",
      "Batch 60/1995, Loss: 3.1854\n",
      "Batch 70/1995, Loss: 3.1854\n",
      "Batch 80/1995, Loss: 3.2010\n",
      "Batch 90/1995, Loss: 3.2010\n",
      "Batch 100/1995, Loss: 3.2167\n",
      "Batch 110/1995, Loss: 3.2010\n",
      "Batch 120/1995, Loss: 3.1854\n",
      "Batch 130/1995, Loss: 3.1854\n",
      "Batch 140/1995, Loss: 3.2010\n",
      "Batch 150/1995, Loss: 3.1854\n",
      "Batch 160/1995, Loss: 3.2010\n",
      "Batch 170/1995, Loss: 3.1854\n",
      "Batch 180/1995, Loss: 3.2167\n",
      "Batch 190/1995, Loss: 3.2010\n",
      "Batch 200/1995, Loss: 3.1854\n",
      "Batch 210/1995, Loss: 3.2010\n",
      "Batch 220/1995, Loss: 3.1854\n",
      "Batch 230/1995, Loss: 3.1854\n",
      "Batch 240/1995, Loss: 3.1854\n",
      "Batch 250/1995, Loss: 3.1854\n",
      "Batch 260/1995, Loss: 3.2010\n",
      "Batch 270/1995, Loss: 3.1854\n",
      "Batch 280/1995, Loss: 3.2010\n",
      "Batch 290/1995, Loss: 3.2010\n",
      "Batch 300/1995, Loss: 3.2166\n",
      "Batch 310/1995, Loss: 3.1854\n",
      "Batch 320/1995, Loss: 3.1854\n",
      "Batch 330/1995, Loss: 3.1854\n",
      "Batch 340/1995, Loss: 3.1854\n",
      "Batch 350/1995, Loss: 3.2166\n",
      "Batch 360/1995, Loss: 3.2010\n",
      "Batch 370/1995, Loss: 3.1854\n",
      "Batch 380/1995, Loss: 3.1854\n",
      "Batch 390/1995, Loss: 3.1854\n",
      "Batch 400/1995, Loss: 3.1854\n",
      "Batch 410/1995, Loss: 3.1854\n",
      "Batch 420/1995, Loss: 3.1854\n",
      "Batch 430/1995, Loss: 3.1854\n",
      "Batch 440/1995, Loss: 3.1854\n",
      "Batch 450/1995, Loss: 3.2010\n",
      "Batch 460/1995, Loss: 3.1854\n",
      "Batch 470/1995, Loss: 3.2010\n",
      "Batch 480/1995, Loss: 3.2166\n",
      "Batch 490/1995, Loss: 3.2166\n",
      "Batch 500/1995, Loss: 3.1854\n",
      "Batch 510/1995, Loss: 3.1854\n",
      "Batch 520/1995, Loss: 3.1854\n",
      "Batch 530/1995, Loss: 3.2166\n",
      "Batch 540/1995, Loss: 3.1854\n",
      "Batch 550/1995, Loss: 3.1854\n",
      "Batch 560/1995, Loss: 3.1854\n",
      "Batch 570/1995, Loss: 3.1854\n",
      "Batch 580/1995, Loss: 3.1854\n",
      "Batch 590/1995, Loss: 3.1854\n",
      "Batch 600/1995, Loss: 3.1854\n",
      "Batch 610/1995, Loss: 3.1854\n",
      "Batch 620/1995, Loss: 3.2166\n",
      "Batch 630/1995, Loss: 3.1854\n",
      "Batch 640/1995, Loss: 3.1854\n",
      "Batch 650/1995, Loss: 3.2010\n",
      "Batch 660/1995, Loss: 3.1854\n",
      "Batch 670/1995, Loss: 3.1854\n",
      "Batch 680/1995, Loss: 3.1854\n",
      "Batch 690/1995, Loss: 3.1854\n",
      "Batch 700/1995, Loss: 3.2010\n",
      "Batch 710/1995, Loss: 3.1854\n",
      "Batch 720/1995, Loss: 3.1854\n",
      "Batch 730/1995, Loss: 3.2010\n",
      "Batch 740/1995, Loss: 3.1854\n",
      "Batch 750/1995, Loss: 3.1854\n",
      "Batch 760/1995, Loss: 3.1854\n",
      "Batch 770/1995, Loss: 3.1854\n",
      "Batch 780/1995, Loss: 3.1854\n",
      "Batch 790/1995, Loss: 3.1854\n",
      "Batch 800/1995, Loss: 3.2010\n",
      "Batch 810/1995, Loss: 3.2010\n",
      "Batch 820/1995, Loss: 3.1854\n",
      "Batch 830/1995, Loss: 3.1854\n",
      "Batch 840/1995, Loss: 3.1854\n",
      "Batch 850/1995, Loss: 3.2010\n",
      "Batch 860/1995, Loss: 3.2010\n",
      "Batch 870/1995, Loss: 3.1854\n",
      "Batch 880/1995, Loss: 3.1854\n",
      "Batch 890/1995, Loss: 3.1854\n",
      "Batch 900/1995, Loss: 3.1854\n",
      "Batch 910/1995, Loss: 3.1854\n",
      "Batch 920/1995, Loss: 3.1854\n",
      "Batch 930/1995, Loss: 3.1854\n",
      "Batch 940/1995, Loss: 3.1854\n",
      "Batch 950/1995, Loss: 3.2010\n",
      "Batch 960/1995, Loss: 3.1854\n",
      "Batch 970/1995, Loss: 3.2010\n",
      "Batch 980/1995, Loss: 3.2010\n",
      "Batch 990/1995, Loss: 3.1854\n",
      "Batch 1000/1995, Loss: 3.2166\n",
      "Batch 1010/1995, Loss: 3.1854\n",
      "Batch 1020/1995, Loss: 3.1854\n",
      "Batch 1030/1995, Loss: 3.2166\n",
      "Batch 1040/1995, Loss: 3.1854\n",
      "Batch 1050/1995, Loss: 3.1854\n",
      "Batch 1060/1995, Loss: 3.2010\n",
      "Batch 1070/1995, Loss: 3.2010\n",
      "Batch 1080/1995, Loss: 3.2323\n",
      "Batch 1090/1995, Loss: 3.1854\n",
      "Batch 1100/1995, Loss: 3.2010\n",
      "Batch 1110/1995, Loss: 3.2010\n",
      "Batch 1120/1995, Loss: 3.1854\n",
      "Batch 1130/1995, Loss: 3.1854\n",
      "Batch 1140/1995, Loss: 3.1854\n",
      "Batch 1150/1995, Loss: 3.2010\n",
      "Batch 1160/1995, Loss: 3.1854\n",
      "Batch 1170/1995, Loss: 3.1854\n",
      "Batch 1180/1995, Loss: 3.1854\n",
      "Batch 1190/1995, Loss: 3.1854\n",
      "Batch 1200/1995, Loss: 3.1854\n",
      "Batch 1210/1995, Loss: 3.2010\n",
      "Batch 1220/1995, Loss: 3.2010\n",
      "Batch 1230/1995, Loss: 3.1854\n",
      "Batch 1240/1995, Loss: 3.2010\n",
      "Batch 1250/1995, Loss: 3.1854\n",
      "Batch 1260/1995, Loss: 3.2010\n",
      "Batch 1270/1995, Loss: 3.2010\n",
      "Batch 1280/1995, Loss: 3.2010\n",
      "Batch 1290/1995, Loss: 3.1854\n",
      "Batch 1300/1995, Loss: 3.2010\n",
      "Batch 1310/1995, Loss: 3.1854\n",
      "Batch 1320/1995, Loss: 3.2010\n",
      "Batch 1330/1995, Loss: 3.2010\n",
      "Batch 1340/1995, Loss: 3.2010\n",
      "Batch 1350/1995, Loss: 3.1854\n",
      "Batch 1360/1995, Loss: 3.1854\n",
      "Batch 1370/1995, Loss: 3.1854\n",
      "Batch 1380/1995, Loss: 3.1854\n",
      "Batch 1390/1995, Loss: 3.1854\n",
      "Batch 1400/1995, Loss: 3.1854\n",
      "Batch 1410/1995, Loss: 3.1854\n",
      "Batch 1420/1995, Loss: 3.1854\n",
      "Batch 1430/1995, Loss: 3.1854\n",
      "Batch 1440/1995, Loss: 3.1854\n",
      "Batch 1450/1995, Loss: 3.2010\n",
      "Batch 1460/1995, Loss: 3.1854\n",
      "Batch 1470/1995, Loss: 3.1854\n",
      "Batch 1480/1995, Loss: 3.1854\n",
      "Batch 1490/1995, Loss: 3.1854\n",
      "Batch 1500/1995, Loss: 3.1854\n",
      "Batch 1510/1995, Loss: 3.1854\n",
      "Batch 1520/1995, Loss: 3.2323\n",
      "Batch 1530/1995, Loss: 3.1854\n",
      "Batch 1540/1995, Loss: 3.2166\n",
      "Batch 1550/1995, Loss: 3.1854\n",
      "Batch 1560/1995, Loss: 3.1854\n",
      "Batch 1570/1995, Loss: 3.1854\n",
      "Batch 1580/1995, Loss: 3.2010\n",
      "Batch 1590/1995, Loss: 3.1854\n",
      "Batch 1600/1995, Loss: 3.1854\n",
      "Batch 1610/1995, Loss: 3.1854\n",
      "Batch 1620/1995, Loss: 3.1854\n",
      "Batch 1630/1995, Loss: 3.2010\n",
      "Batch 1640/1995, Loss: 3.1854\n",
      "Batch 1650/1995, Loss: 3.1854\n",
      "Batch 1660/1995, Loss: 3.2166\n",
      "Batch 1670/1995, Loss: 3.1854\n",
      "Batch 1680/1995, Loss: 3.2323\n",
      "Batch 1690/1995, Loss: 3.1854\n",
      "Batch 1700/1995, Loss: 3.1854\n",
      "Batch 1710/1995, Loss: 3.1854\n",
      "Batch 1720/1995, Loss: 3.2010\n",
      "Batch 1730/1995, Loss: 3.2010\n",
      "Batch 1740/1995, Loss: 3.1854\n",
      "Batch 1750/1995, Loss: 3.1854\n",
      "Batch 1760/1995, Loss: 3.1854\n",
      "Batch 1770/1995, Loss: 3.1854\n",
      "Batch 1780/1995, Loss: 3.1854\n",
      "Batch 1790/1995, Loss: 3.1854\n",
      "Batch 1800/1995, Loss: 3.1854\n",
      "Batch 1810/1995, Loss: 3.2010\n",
      "Batch 1820/1995, Loss: 3.1854\n",
      "Batch 1830/1995, Loss: 3.1854\n",
      "Batch 1840/1995, Loss: 3.1854\n",
      "Batch 1850/1995, Loss: 3.2010\n",
      "Batch 1860/1995, Loss: 3.2010\n",
      "Batch 1870/1995, Loss: 3.2010\n",
      "Batch 1880/1995, Loss: 3.1854\n",
      "Batch 1890/1995, Loss: 3.2010\n",
      "Batch 1900/1995, Loss: 3.1854\n",
      "Batch 1910/1995, Loss: 3.1854\n",
      "Batch 1920/1995, Loss: 3.1854\n",
      "Batch 1930/1995, Loss: 3.1854\n",
      "Batch 1940/1995, Loss: 3.1854\n",
      "Batch 1950/1995, Loss: 3.2010\n",
      "Batch 1960/1995, Loss: 3.1854\n",
      "Batch 1970/1995, Loss: 3.1854\n",
      "Batch 1980/1995, Loss: 3.2010\n",
      "Batch 1990/1995, Loss: 3.2010\n",
      "\n",
      "Epoch 1 - Joint Model Training Complete. Loss: 3.1940\n",
      "==================================================\n",
      "==================================================\n",
      "Starting Epoch 2 of Training\n",
      "\n",
      "\n",
      "Training Independent Probabilities Model - Epoch 2\n",
      "Batch 10/1995, Loss: 0.0595\n",
      "Batch 20/1995, Loss: 0.0378\n",
      "Batch 30/1995, Loss: 0.0546\n",
      "Batch 40/1995, Loss: 0.0895\n",
      "Batch 50/1995, Loss: 0.0820\n",
      "Batch 60/1995, Loss: 0.0324\n",
      "Batch 70/1995, Loss: 0.0534\n",
      "Batch 80/1995, Loss: 0.0641\n",
      "Batch 90/1995, Loss: 0.1026\n",
      "Batch 100/1995, Loss: 0.0543\n",
      "Batch 110/1995, Loss: 0.0450\n",
      "Batch 120/1995, Loss: 0.0321\n",
      "Batch 130/1995, Loss: 0.0963\n",
      "Batch 140/1995, Loss: 0.0484\n",
      "Batch 150/1995, Loss: 0.0445\n",
      "Batch 160/1995, Loss: 0.0693\n",
      "Batch 170/1995, Loss: 0.1716\n",
      "Batch 180/1995, Loss: 0.0563\n",
      "Batch 190/1995, Loss: 0.0890\n",
      "Batch 200/1995, Loss: 0.0653\n",
      "Batch 210/1995, Loss: 0.0476\n",
      "Batch 220/1995, Loss: 0.0411\n",
      "Batch 230/1995, Loss: 0.0314\n",
      "Batch 240/1995, Loss: 0.0831\n",
      "Batch 250/1995, Loss: 0.0610\n",
      "Batch 260/1995, Loss: 0.1165\n",
      "Batch 270/1995, Loss: 0.0568\n",
      "Batch 280/1995, Loss: 0.0270\n",
      "Batch 290/1995, Loss: 0.0698\n",
      "Batch 300/1995, Loss: 0.0648\n",
      "Batch 310/1995, Loss: 0.0783\n",
      "Batch 320/1995, Loss: 0.0887\n",
      "Batch 330/1995, Loss: 0.0539\n",
      "Batch 340/1995, Loss: 0.0099\n",
      "Batch 350/1995, Loss: 0.0208\n",
      "Batch 360/1995, Loss: 0.0230\n",
      "Batch 370/1995, Loss: 0.0374\n",
      "Batch 380/1995, Loss: 0.0508\n",
      "Batch 390/1995, Loss: 0.0474\n",
      "Batch 400/1995, Loss: 0.0134\n",
      "Batch 410/1995, Loss: 0.0306\n",
      "Batch 420/1995, Loss: 0.0407\n",
      "Batch 430/1995, Loss: 0.1312\n",
      "Batch 440/1995, Loss: 0.0373\n",
      "Batch 450/1995, Loss: 0.0669\n",
      "Batch 460/1995, Loss: 0.0379\n",
      "Batch 470/1995, Loss: 0.0255\n",
      "Batch 480/1995, Loss: 0.0612\n",
      "Batch 490/1995, Loss: 0.0400\n",
      "Batch 500/1995, Loss: 0.0449\n",
      "Batch 510/1995, Loss: 0.0840\n",
      "Batch 520/1995, Loss: 0.0328\n",
      "Batch 530/1995, Loss: 0.0755\n",
      "Batch 540/1995, Loss: 0.0775\n",
      "Batch 550/1995, Loss: 0.0222\n",
      "Batch 560/1995, Loss: 0.0588\n",
      "Batch 570/1995, Loss: 0.0326\n",
      "Batch 580/1995, Loss: 0.0270\n",
      "Batch 590/1995, Loss: 0.0423\n",
      "Batch 600/1995, Loss: 0.1352\n",
      "Batch 610/1995, Loss: 0.0578\n",
      "Batch 620/1995, Loss: 0.0491\n",
      "Batch 630/1995, Loss: 0.0228\n",
      "Batch 640/1995, Loss: 0.0731\n",
      "Batch 650/1995, Loss: 0.0674\n",
      "Batch 660/1995, Loss: 0.0343\n",
      "Batch 670/1995, Loss: 0.0533\n",
      "Batch 680/1995, Loss: 0.0369\n",
      "Batch 690/1995, Loss: 0.0829\n",
      "Batch 700/1995, Loss: 0.0341\n",
      "Batch 710/1995, Loss: 0.0836\n",
      "Batch 720/1995, Loss: 0.0446\n",
      "Batch 730/1995, Loss: 0.0453\n",
      "Batch 740/1995, Loss: 0.0290\n",
      "Batch 750/1995, Loss: 0.0627\n",
      "Batch 760/1995, Loss: 0.0669\n",
      "Batch 770/1995, Loss: 0.0773\n",
      "Batch 780/1995, Loss: 0.0719\n",
      "Batch 790/1995, Loss: 0.0610\n",
      "Batch 800/1995, Loss: 0.0311\n",
      "Batch 810/1995, Loss: 0.0422\n",
      "Batch 820/1995, Loss: 0.0407\n",
      "Batch 830/1995, Loss: 0.0541\n",
      "Batch 840/1995, Loss: 0.0254\n",
      "Batch 850/1995, Loss: 0.1065\n",
      "Batch 860/1995, Loss: 0.0505\n",
      "Batch 870/1995, Loss: 0.0612\n",
      "Batch 880/1995, Loss: 0.1045\n",
      "Batch 890/1995, Loss: 0.0391\n",
      "Batch 900/1995, Loss: 0.0493\n",
      "Batch 910/1995, Loss: 0.0678\n",
      "Batch 920/1995, Loss: 0.0454\n",
      "Batch 930/1995, Loss: 0.0541\n",
      "Batch 940/1995, Loss: 0.0410\n",
      "Batch 950/1995, Loss: 0.0529\n",
      "Batch 960/1995, Loss: 0.0767\n",
      "Batch 970/1995, Loss: 0.0561\n",
      "Batch 980/1995, Loss: 0.0657\n",
      "Batch 990/1995, Loss: 0.0426\n",
      "Batch 1000/1995, Loss: 0.0424\n",
      "Batch 1010/1995, Loss: 0.0594\n",
      "Batch 1020/1995, Loss: 0.0155\n",
      "Batch 1030/1995, Loss: 0.0482\n",
      "Batch 1040/1995, Loss: 0.0394\n",
      "Batch 1050/1995, Loss: 0.0543\n",
      "Batch 1060/1995, Loss: 0.0642\n",
      "Batch 1070/1995, Loss: 0.0728\n",
      "Batch 1080/1995, Loss: 0.0842\n",
      "Batch 1090/1995, Loss: 0.0623\n",
      "Batch 1100/1995, Loss: 0.0481\n",
      "Batch 1110/1995, Loss: 0.0908\n",
      "Batch 1120/1995, Loss: 0.0615\n",
      "Batch 1130/1995, Loss: 0.0391\n",
      "Batch 1140/1995, Loss: 0.0329\n",
      "Batch 1150/1995, Loss: 0.0273\n",
      "Batch 1160/1995, Loss: 0.0059\n",
      "Batch 1170/1995, Loss: 0.0547\n",
      "Batch 1180/1995, Loss: 0.0449\n",
      "Batch 1190/1995, Loss: 0.0245\n",
      "Batch 1200/1995, Loss: 0.0729\n",
      "Batch 1210/1995, Loss: 0.0703\n",
      "Batch 1220/1995, Loss: 0.0785\n",
      "Batch 1230/1995, Loss: 0.1064\n",
      "Batch 1240/1995, Loss: 0.0518\n",
      "Batch 1250/1995, Loss: 0.0406\n",
      "Batch 1260/1995, Loss: 0.0318\n",
      "Batch 1270/1995, Loss: 0.1118\n",
      "Batch 1280/1995, Loss: 0.0455\n",
      "Batch 1290/1995, Loss: 0.0532\n",
      "Batch 1300/1995, Loss: 0.0597\n",
      "Batch 1310/1995, Loss: 0.0486\n",
      "Batch 1320/1995, Loss: 0.0642\n",
      "Batch 1330/1995, Loss: 0.0670\n",
      "Batch 1340/1995, Loss: 0.0643\n",
      "Batch 1350/1995, Loss: 0.1089\n",
      "Batch 1360/1995, Loss: 0.0564\n",
      "Batch 1370/1995, Loss: 0.0392\n",
      "Batch 1380/1995, Loss: 0.0602\n",
      "Batch 1390/1995, Loss: 0.0223\n",
      "Batch 1400/1995, Loss: 0.0712\n",
      "Batch 1410/1995, Loss: 0.0639\n",
      "Batch 1420/1995, Loss: 0.0330\n",
      "Batch 1430/1995, Loss: 0.0697\n",
      "Batch 1440/1995, Loss: 0.0854\n",
      "Batch 1450/1995, Loss: 0.0358\n",
      "Batch 1460/1995, Loss: 0.0700\n",
      "Batch 1470/1995, Loss: 0.0545\n",
      "Batch 1480/1995, Loss: 0.0551\n",
      "Batch 1490/1995, Loss: 0.0261\n",
      "Batch 1500/1995, Loss: 0.0408\n",
      "Batch 1510/1995, Loss: 0.0480\n",
      "Batch 1520/1995, Loss: 0.0517\n",
      "Batch 1530/1995, Loss: 0.0254\n",
      "Batch 1540/1995, Loss: 0.0522\n",
      "Batch 1550/1995, Loss: 0.0323\n",
      "Batch 1560/1995, Loss: 0.0922\n",
      "Batch 1570/1995, Loss: 0.0640\n",
      "Batch 1580/1995, Loss: 0.0665\n",
      "Batch 1590/1995, Loss: 0.0891\n",
      "Batch 1600/1995, Loss: 0.0679\n",
      "Batch 1610/1995, Loss: 0.0690\n",
      "Batch 1620/1995, Loss: 0.0621\n",
      "Batch 1630/1995, Loss: 0.0547\n",
      "Batch 1640/1995, Loss: 0.0803\n",
      "Batch 1650/1995, Loss: 0.0458\n",
      "Batch 1660/1995, Loss: 0.0321\n",
      "Batch 1670/1995, Loss: 0.0388\n",
      "Batch 1680/1995, Loss: 0.0806\n",
      "Batch 1690/1995, Loss: 0.0524\n",
      "Batch 1700/1995, Loss: 0.0203\n",
      "Batch 1710/1995, Loss: 0.0736\n",
      "Batch 1720/1995, Loss: 0.0528\n",
      "Batch 1730/1995, Loss: 0.0306\n",
      "Batch 1740/1995, Loss: 0.0251\n",
      "Batch 1750/1995, Loss: 0.0538\n",
      "Batch 1760/1995, Loss: 0.0668\n",
      "Batch 1770/1995, Loss: 0.0583\n",
      "Batch 1780/1995, Loss: 0.0271\n",
      "Batch 1790/1995, Loss: 0.0756\n",
      "Batch 1800/1995, Loss: 0.0731\n",
      "Batch 1810/1995, Loss: 0.0536\n",
      "Batch 1820/1995, Loss: 0.0341\n",
      "Batch 1830/1995, Loss: 0.0512\n",
      "Batch 1840/1995, Loss: 0.0801\n",
      "Batch 1850/1995, Loss: 0.0233\n",
      "Batch 1860/1995, Loss: 0.0487\n",
      "Batch 1870/1995, Loss: 0.0609\n",
      "Batch 1880/1995, Loss: 0.0611\n",
      "Batch 1890/1995, Loss: 0.0371\n",
      "Batch 1900/1995, Loss: 0.0577\n",
      "Batch 1910/1995, Loss: 0.0471\n",
      "Batch 1920/1995, Loss: 0.0674\n",
      "Batch 1930/1995, Loss: 0.0583\n",
      "Batch 1940/1995, Loss: 0.0652\n",
      "Batch 1950/1995, Loss: 0.0290\n",
      "Batch 1960/1995, Loss: 0.0651\n",
      "Batch 1970/1995, Loss: 0.0957\n",
      "Batch 1980/1995, Loss: 0.0562\n",
      "Batch 1990/1995, Loss: 0.1094\n",
      "\n",
      "Epoch 2 - Independent Model Training Complete. Loss: 0.0575\n",
      "\n",
      "Training Joint Probability Model - Epoch 2\n",
      "Batch 10/1995, Loss: 3.1854\n",
      "Batch 20/1995, Loss: 3.1854\n",
      "Batch 30/1995, Loss: 3.1854\n",
      "Batch 40/1995, Loss: 3.2010\n",
      "Batch 50/1995, Loss: 3.2010\n",
      "Batch 60/1995, Loss: 3.1854\n",
      "Batch 70/1995, Loss: 3.2010\n",
      "Batch 80/1995, Loss: 3.1854\n",
      "Batch 90/1995, Loss: 3.1854\n",
      "Batch 100/1995, Loss: 3.1854\n",
      "Batch 110/1995, Loss: 3.2010\n",
      "Batch 120/1995, Loss: 3.1854\n",
      "Batch 130/1995, Loss: 3.1854\n",
      "Batch 140/1995, Loss: 3.1854\n",
      "Batch 150/1995, Loss: 3.2010\n",
      "Batch 160/1995, Loss: 3.1854\n",
      "Batch 170/1995, Loss: 3.1854\n",
      "Batch 180/1995, Loss: 3.2166\n",
      "Batch 190/1995, Loss: 3.1854\n",
      "Batch 200/1995, Loss: 3.2166\n",
      "Batch 210/1995, Loss: 3.2166\n",
      "Batch 220/1995, Loss: 3.2010\n",
      "Batch 230/1995, Loss: 3.1854\n",
      "Batch 240/1995, Loss: 3.1854\n",
      "Batch 250/1995, Loss: 3.2010\n",
      "Batch 260/1995, Loss: 3.2010\n",
      "Batch 270/1995, Loss: 3.1854\n",
      "Batch 280/1995, Loss: 3.1854\n",
      "Batch 290/1995, Loss: 3.1854\n",
      "Batch 300/1995, Loss: 3.2010\n",
      "Batch 310/1995, Loss: 3.1854\n",
      "Batch 320/1995, Loss: 3.1854\n",
      "Batch 330/1995, Loss: 3.1854\n",
      "Batch 340/1995, Loss: 3.1854\n",
      "Batch 350/1995, Loss: 3.2010\n",
      "Batch 360/1995, Loss: 3.1854\n",
      "Batch 370/1995, Loss: 3.2010\n",
      "Batch 380/1995, Loss: 3.1854\n",
      "Batch 390/1995, Loss: 3.1854\n",
      "Batch 400/1995, Loss: 3.1854\n",
      "Batch 410/1995, Loss: 3.1854\n",
      "Batch 420/1995, Loss: 3.1854\n",
      "Batch 430/1995, Loss: 3.2166\n",
      "Batch 440/1995, Loss: 3.1854\n",
      "Batch 450/1995, Loss: 3.1854\n",
      "Batch 460/1995, Loss: 3.2010\n",
      "Batch 470/1995, Loss: 3.2166\n",
      "Batch 480/1995, Loss: 3.2010\n",
      "Batch 490/1995, Loss: 3.1854\n",
      "Batch 500/1995, Loss: 3.1854\n",
      "Batch 510/1995, Loss: 3.2323\n",
      "Batch 520/1995, Loss: 3.2164\n",
      "Batch 530/1995, Loss: 3.1854\n",
      "Batch 540/1995, Loss: 3.1854\n",
      "Batch 550/1995, Loss: 3.1854\n",
      "Batch 560/1995, Loss: 3.1854\n",
      "Batch 570/1995, Loss: 3.2008\n",
      "Batch 580/1995, Loss: 3.2010\n",
      "Batch 590/1995, Loss: 3.1854\n",
      "Batch 600/1995, Loss: 3.1854\n",
      "Batch 610/1995, Loss: 3.2008\n",
      "Batch 620/1995, Loss: 3.1854\n",
      "Batch 630/1995, Loss: 3.2010\n",
      "Batch 640/1995, Loss: 3.1854\n",
      "Batch 650/1995, Loss: 3.1854\n",
      "Batch 660/1995, Loss: 3.2010\n",
      "Batch 670/1995, Loss: 3.1854\n",
      "Batch 680/1995, Loss: 3.1854\n",
      "Batch 690/1995, Loss: 3.2010\n",
      "Batch 700/1995, Loss: 3.2010\n",
      "Batch 710/1995, Loss: 3.1854\n",
      "Batch 720/1995, Loss: 3.2164\n",
      "Batch 730/1995, Loss: 3.2010\n",
      "Batch 740/1995, Loss: 3.2010\n",
      "Batch 750/1995, Loss: 3.2010\n",
      "Batch 760/1995, Loss: 3.1854\n",
      "Batch 770/1995, Loss: 3.1854\n",
      "Batch 780/1995, Loss: 3.1854\n",
      "Batch 790/1995, Loss: 3.1854\n",
      "Batch 800/1995, Loss: 3.2010\n",
      "Batch 810/1995, Loss: 3.2010\n",
      "Batch 820/1995, Loss: 3.1854\n",
      "Batch 830/1995, Loss: 3.2010\n",
      "Batch 840/1995, Loss: 3.1854\n",
      "Batch 850/1995, Loss: 3.1854\n",
      "Batch 860/1995, Loss: 3.1854\n",
      "Batch 870/1995, Loss: 3.1854\n",
      "Batch 880/1995, Loss: 3.1854\n",
      "Batch 890/1995, Loss: 3.1854\n",
      "Batch 900/1995, Loss: 3.1854\n",
      "Batch 910/1995, Loss: 3.1854\n",
      "Batch 920/1995, Loss: 3.1854\n",
      "Batch 930/1995, Loss: 3.1854\n",
      "Batch 940/1995, Loss: 3.1854\n",
      "Batch 950/1995, Loss: 3.2010\n",
      "Batch 960/1995, Loss: 3.1854\n",
      "Batch 970/1995, Loss: 3.2010\n",
      "Batch 980/1995, Loss: 3.1854\n",
      "Batch 990/1995, Loss: 3.1854\n",
      "Batch 1000/1995, Loss: 3.1854\n",
      "Batch 1010/1995, Loss: 3.1854\n",
      "Batch 1020/1995, Loss: 3.1854\n",
      "Batch 1030/1995, Loss: 3.2010\n",
      "Batch 1040/1995, Loss: 3.1854\n",
      "Batch 1050/1995, Loss: 3.2166\n",
      "Batch 1060/1995, Loss: 3.1854\n",
      "Batch 1070/1995, Loss: 3.1854\n",
      "Batch 1080/1995, Loss: 3.2010\n",
      "Batch 1090/1995, Loss: 3.2010\n",
      "Batch 1100/1995, Loss: 3.1854\n",
      "Batch 1110/1995, Loss: 3.1854\n",
      "Batch 1120/1995, Loss: 3.1854\n",
      "Batch 1130/1995, Loss: 3.1854\n",
      "Batch 1140/1995, Loss: 3.1854\n",
      "Batch 1150/1995, Loss: 3.1854\n",
      "Batch 1160/1995, Loss: 3.2166\n",
      "Batch 1170/1995, Loss: 3.2010\n",
      "Batch 1180/1995, Loss: 3.1854\n",
      "Batch 1190/1995, Loss: 3.2010\n",
      "Batch 1200/1995, Loss: 3.1854\n",
      "Batch 1210/1995, Loss: 3.1854\n",
      "Batch 1220/1995, Loss: 3.2010\n",
      "Batch 1230/1995, Loss: 3.1854\n",
      "Batch 1240/1995, Loss: 3.1854\n",
      "Batch 1250/1995, Loss: 3.1854\n",
      "Batch 1260/1995, Loss: 3.1854\n",
      "Batch 1270/1995, Loss: 3.1854\n",
      "Batch 1280/1995, Loss: 3.2010\n",
      "Batch 1290/1995, Loss: 3.1854\n",
      "Batch 1300/1995, Loss: 3.1854\n",
      "Batch 1310/1995, Loss: 3.1854\n",
      "Batch 1320/1995, Loss: 3.1854\n",
      "Batch 1330/1995, Loss: 3.1854\n",
      "Batch 1340/1995, Loss: 3.2010\n",
      "Batch 1350/1995, Loss: 3.1854\n",
      "Batch 1360/1995, Loss: 3.1854\n",
      "Batch 1370/1995, Loss: 3.1854\n",
      "Batch 1380/1995, Loss: 3.1854\n",
      "Batch 1390/1995, Loss: 3.1854\n",
      "Batch 1400/1995, Loss: 3.1854\n",
      "Batch 1410/1995, Loss: 3.2166\n",
      "Batch 1420/1995, Loss: 3.1854\n",
      "Batch 1430/1995, Loss: 3.1854\n",
      "Batch 1440/1995, Loss: 3.1854\n",
      "Batch 1450/1995, Loss: 3.1854\n",
      "Batch 1460/1995, Loss: 3.2010\n",
      "Batch 1470/1995, Loss: 3.2010\n",
      "Batch 1480/1995, Loss: 3.2010\n",
      "Batch 1490/1995, Loss: 3.1854\n",
      "Batch 1500/1995, Loss: 3.1854\n",
      "Batch 1510/1995, Loss: 3.2010\n",
      "Batch 1520/1995, Loss: 3.2010\n",
      "Batch 1530/1995, Loss: 3.1854\n",
      "Batch 1540/1995, Loss: 3.1854\n",
      "Batch 1550/1995, Loss: 3.1854\n",
      "Batch 1560/1995, Loss: 3.2323\n",
      "Batch 1570/1995, Loss: 3.2010\n",
      "Batch 1580/1995, Loss: 3.1854\n",
      "Batch 1590/1995, Loss: 3.2010\n",
      "Batch 1600/1995, Loss: 3.1854\n",
      "Batch 1610/1995, Loss: 3.1854\n",
      "Batch 1620/1995, Loss: 3.2010\n",
      "Batch 1630/1995, Loss: 3.1854\n",
      "Batch 1640/1995, Loss: 3.1854\n",
      "Batch 1650/1995, Loss: 3.1854\n",
      "Batch 1660/1995, Loss: 3.1854\n",
      "Batch 1670/1995, Loss: 3.2166\n",
      "Batch 1680/1995, Loss: 3.1854\n",
      "Batch 1690/1995, Loss: 3.1854\n",
      "Batch 1700/1995, Loss: 3.1854\n",
      "Batch 1710/1995, Loss: 3.1854\n",
      "Batch 1720/1995, Loss: 3.1854\n",
      "Batch 1730/1995, Loss: 3.2010\n",
      "Batch 1740/1995, Loss: 3.1854\n",
      "Batch 1750/1995, Loss: 3.1854\n",
      "Batch 1760/1995, Loss: 3.1854\n",
      "Batch 1770/1995, Loss: 3.1854\n",
      "Batch 1780/1995, Loss: 3.1854\n",
      "Batch 1790/1995, Loss: 3.2010\n",
      "Batch 1800/1995, Loss: 3.1854\n",
      "Batch 1810/1995, Loss: 3.1854\n",
      "Batch 1820/1995, Loss: 3.1854\n",
      "Batch 1830/1995, Loss: 3.1854\n",
      "Batch 1840/1995, Loss: 3.2010\n",
      "Batch 1850/1995, Loss: 3.2010\n",
      "Batch 1860/1995, Loss: 3.1854\n",
      "Batch 1870/1995, Loss: 3.2010\n",
      "Batch 1880/1995, Loss: 3.1854\n",
      "Batch 1890/1995, Loss: 3.1854\n",
      "Batch 1900/1995, Loss: 3.1854\n",
      "Batch 1910/1995, Loss: 3.1854\n",
      "Batch 1920/1995, Loss: 3.2010\n",
      "Batch 1930/1995, Loss: 3.1854\n",
      "Batch 1940/1995, Loss: 3.2010\n",
      "Batch 1950/1995, Loss: 3.1854\n",
      "Batch 1960/1995, Loss: 3.1854\n",
      "Batch 1970/1995, Loss: 3.2010\n",
      "Batch 1980/1995, Loss: 3.1854\n",
      "Batch 1990/1995, Loss: 3.1854\n",
      "\n",
      "Epoch 2 - Joint Model Training Complete. Loss: 3.1914\n",
      "==================================================\n",
      "==================================================\n",
      "Starting Epoch 3 of Training\n",
      "\n",
      "\n",
      "Training Independent Probabilities Model - Epoch 3\n",
      "Batch 10/1995, Loss: 0.0552\n",
      "Batch 20/1995, Loss: 0.1308\n",
      "Batch 30/1995, Loss: 0.0786\n",
      "Batch 40/1995, Loss: 0.0363\n",
      "Batch 50/1995, Loss: 0.0817\n",
      "Batch 60/1995, Loss: 0.0143\n",
      "Batch 70/1995, Loss: 0.0707\n",
      "Batch 80/1995, Loss: 0.0292\n",
      "Batch 90/1995, Loss: 0.0544\n",
      "Batch 100/1995, Loss: 0.0224\n",
      "Batch 110/1995, Loss: 0.0400\n",
      "Batch 120/1995, Loss: 0.0029\n",
      "Batch 130/1995, Loss: 0.0530\n",
      "Batch 140/1995, Loss: 0.0762\n",
      "Batch 150/1995, Loss: 0.0443\n",
      "Batch 160/1995, Loss: 0.0628\n",
      "Batch 170/1995, Loss: 0.0470\n",
      "Batch 180/1995, Loss: 0.0407\n",
      "Batch 190/1995, Loss: 0.0410\n",
      "Batch 200/1995, Loss: 0.0445\n",
      "Batch 210/1995, Loss: 0.0158\n",
      "Batch 220/1995, Loss: 0.0368\n",
      "Batch 230/1995, Loss: 0.0584\n",
      "Batch 240/1995, Loss: 0.0278\n",
      "Batch 250/1995, Loss: 0.0514\n",
      "Batch 260/1995, Loss: 0.0524\n",
      "Batch 270/1995, Loss: 0.0425\n",
      "Batch 280/1995, Loss: 0.0346\n",
      "Batch 290/1995, Loss: 0.0344\n",
      "Batch 300/1995, Loss: 0.0501\n",
      "Batch 310/1995, Loss: 0.0704\n",
      "Batch 320/1995, Loss: 0.0662\n",
      "Batch 330/1995, Loss: 0.0527\n",
      "Batch 340/1995, Loss: 0.0546\n",
      "Batch 350/1995, Loss: 0.0149\n",
      "Batch 360/1995, Loss: 0.0832\n",
      "Batch 370/1995, Loss: 0.0293\n",
      "Batch 380/1995, Loss: 0.0493\n",
      "Batch 390/1995, Loss: 0.0915\n",
      "Batch 400/1995, Loss: 0.0558\n",
      "Batch 410/1995, Loss: 0.0884\n",
      "Batch 420/1995, Loss: 0.0494\n",
      "Batch 430/1995, Loss: 0.0253\n",
      "Batch 440/1995, Loss: 0.0669\n",
      "Batch 450/1995, Loss: 0.0435\n",
      "Batch 460/1995, Loss: 0.0380\n",
      "Batch 470/1995, Loss: 0.0563\n",
      "Batch 480/1995, Loss: 0.0119\n",
      "Batch 490/1995, Loss: 0.0391\n",
      "Batch 500/1995, Loss: 0.0422\n",
      "Batch 510/1995, Loss: 0.0233\n",
      "Batch 520/1995, Loss: 0.0350\n",
      "Batch 530/1995, Loss: 0.0272\n",
      "Batch 540/1995, Loss: 0.0728\n",
      "Batch 550/1995, Loss: 0.0250\n",
      "Batch 560/1995, Loss: 0.0436\n",
      "Batch 570/1995, Loss: 0.0701\n",
      "Batch 580/1995, Loss: 0.0430\n",
      "Batch 590/1995, Loss: 0.0469\n",
      "Batch 600/1995, Loss: 0.0312\n",
      "Batch 610/1995, Loss: 0.0248\n",
      "Batch 620/1995, Loss: 0.0613\n",
      "Batch 630/1995, Loss: 0.0461\n",
      "Batch 640/1995, Loss: 0.0602\n",
      "Batch 650/1995, Loss: 0.0235\n",
      "Batch 660/1995, Loss: 0.0374\n",
      "Batch 670/1995, Loss: 0.0584\n",
      "Batch 680/1995, Loss: 0.0170\n",
      "Batch 690/1995, Loss: 0.0747\n",
      "Batch 700/1995, Loss: 0.0464\n",
      "Batch 710/1995, Loss: 0.0324\n",
      "Batch 720/1995, Loss: 0.0604\n",
      "Batch 730/1995, Loss: 0.0267\n",
      "Batch 740/1995, Loss: 0.0551\n",
      "Batch 750/1995, Loss: 0.0418\n",
      "Batch 760/1995, Loss: 0.0471\n",
      "Batch 770/1995, Loss: 0.0324\n",
      "Batch 780/1995, Loss: 0.0419\n",
      "Batch 790/1995, Loss: 0.0484\n",
      "Batch 800/1995, Loss: 0.0564\n",
      "Batch 810/1995, Loss: 0.0508\n",
      "Batch 820/1995, Loss: 0.0402\n",
      "Batch 830/1995, Loss: 0.0358\n",
      "Batch 840/1995, Loss: 0.0500\n",
      "Batch 850/1995, Loss: 0.0350\n",
      "Batch 860/1995, Loss: 0.0416\n",
      "Batch 870/1995, Loss: 0.0240\n",
      "Batch 880/1995, Loss: 0.0510\n",
      "Batch 890/1995, Loss: 0.0493\n",
      "Batch 900/1995, Loss: 0.0848\n",
      "Batch 910/1995, Loss: 0.0503\n",
      "Batch 920/1995, Loss: 0.0438\n",
      "Batch 930/1995, Loss: 0.0502\n",
      "Batch 940/1995, Loss: 0.0393\n",
      "Batch 950/1995, Loss: 0.0742\n",
      "Batch 960/1995, Loss: 0.0254\n",
      "Batch 970/1995, Loss: 0.0156\n",
      "Batch 980/1995, Loss: 0.0406\n",
      "Batch 990/1995, Loss: 0.0382\n",
      "Batch 1000/1995, Loss: 0.0337\n",
      "Batch 1010/1995, Loss: 0.0629\n",
      "Batch 1020/1995, Loss: 0.0386\n",
      "Batch 1030/1995, Loss: 0.0745\n",
      "Batch 1040/1995, Loss: 0.0889\n",
      "Batch 1050/1995, Loss: 0.0095\n",
      "Batch 1060/1995, Loss: 0.0398\n",
      "Batch 1070/1995, Loss: 0.0362\n",
      "Batch 1080/1995, Loss: 0.0322\n",
      "Batch 1090/1995, Loss: 0.0315\n",
      "Batch 1100/1995, Loss: 0.0327\n",
      "Batch 1110/1995, Loss: 0.0317\n",
      "Batch 1120/1995, Loss: 0.0605\n",
      "Batch 1130/1995, Loss: 0.0595\n",
      "Batch 1140/1995, Loss: 0.0437\n",
      "Batch 1150/1995, Loss: 0.0299\n",
      "Batch 1160/1995, Loss: 0.0322\n",
      "Batch 1170/1995, Loss: 0.0297\n",
      "Batch 1180/1995, Loss: 0.0324\n",
      "Batch 1190/1995, Loss: 0.0616\n",
      "Batch 1200/1995, Loss: 0.0255\n",
      "Batch 1210/1995, Loss: 0.0371\n",
      "Batch 1220/1995, Loss: 0.0439\n",
      "Batch 1230/1995, Loss: 0.0640\n",
      "Batch 1240/1995, Loss: 0.0470\n",
      "Batch 1250/1995, Loss: 0.0811\n",
      "Batch 1260/1995, Loss: 0.0722\n",
      "Batch 1270/1995, Loss: 0.0340\n",
      "Batch 1280/1995, Loss: 0.0357\n",
      "Batch 1290/1995, Loss: 0.0307\n",
      "Batch 1300/1995, Loss: 0.0468\n",
      "Batch 1310/1995, Loss: 0.0337\n",
      "Batch 1320/1995, Loss: 0.0464\n",
      "Batch 1330/1995, Loss: 0.0251\n",
      "Batch 1340/1995, Loss: 0.0226\n",
      "Batch 1350/1995, Loss: 0.0346\n",
      "Batch 1360/1995, Loss: 0.0439\n",
      "Batch 1370/1995, Loss: 0.0420\n",
      "Batch 1380/1995, Loss: 0.0438\n",
      "Batch 1390/1995, Loss: 0.0567\n",
      "Batch 1400/1995, Loss: 0.0576\n",
      "Batch 1410/1995, Loss: 0.0340\n",
      "Batch 1420/1995, Loss: 0.0357\n",
      "Batch 1430/1995, Loss: 0.0898\n",
      "Batch 1440/1995, Loss: 0.0532\n",
      "Batch 1450/1995, Loss: 0.0285\n",
      "Batch 1460/1995, Loss: 0.0184\n",
      "Batch 1470/1995, Loss: 0.0431\n",
      "Batch 1480/1995, Loss: 0.0256\n",
      "Batch 1490/1995, Loss: 0.0573\n",
      "Batch 1500/1995, Loss: 0.0549\n",
      "Batch 1510/1995, Loss: 0.0743\n",
      "Batch 1520/1995, Loss: 0.0262\n",
      "Batch 1530/1995, Loss: 0.1007\n",
      "Batch 1540/1995, Loss: 0.0316\n",
      "Batch 1550/1995, Loss: 0.0151\n",
      "Batch 1560/1995, Loss: 0.0405\n",
      "Batch 1570/1995, Loss: 0.0392\n",
      "Batch 1580/1995, Loss: 0.0507\n",
      "Batch 1590/1995, Loss: 0.0647\n",
      "Batch 1600/1995, Loss: 0.0646\n",
      "Batch 1610/1995, Loss: 0.0188\n",
      "Batch 1620/1995, Loss: 0.0512\n",
      "Batch 1630/1995, Loss: 0.0322\n",
      "Batch 1640/1995, Loss: 0.0711\n",
      "Batch 1650/1995, Loss: 0.0845\n",
      "Batch 1660/1995, Loss: 0.0849\n",
      "Batch 1670/1995, Loss: 0.0459\n",
      "Batch 1680/1995, Loss: 0.0330\n",
      "Batch 1690/1995, Loss: 0.0578\n",
      "Batch 1700/1995, Loss: 0.0317\n",
      "Batch 1710/1995, Loss: 0.0620\n",
      "Batch 1720/1995, Loss: 0.0442\n",
      "Batch 1730/1995, Loss: 0.0089\n",
      "Batch 1740/1995, Loss: 0.0531\n",
      "Batch 1750/1995, Loss: 0.0468\n",
      "Batch 1760/1995, Loss: 0.0779\n",
      "Batch 1770/1995, Loss: 0.0828\n",
      "Batch 1780/1995, Loss: 0.0272\n",
      "Batch 1790/1995, Loss: 0.0672\n",
      "Batch 1800/1995, Loss: 0.0304\n",
      "Batch 1810/1995, Loss: 0.0467\n",
      "Batch 1820/1995, Loss: 0.0372\n",
      "Batch 1830/1995, Loss: 0.0408\n",
      "Batch 1840/1995, Loss: 0.0507\n",
      "Batch 1850/1995, Loss: 0.0211\n",
      "Batch 1860/1995, Loss: 0.0517\n",
      "Batch 1870/1995, Loss: 0.0417\n",
      "Batch 1880/1995, Loss: 0.0591\n",
      "Batch 1890/1995, Loss: 0.0386\n",
      "Batch 1900/1995, Loss: 0.0682\n",
      "Batch 1910/1995, Loss: 0.0654\n",
      "Batch 1920/1995, Loss: 0.0564\n",
      "Batch 1930/1995, Loss: 0.0467\n",
      "Batch 1940/1995, Loss: 0.0579\n",
      "Batch 1950/1995, Loss: 0.0391\n",
      "Batch 1960/1995, Loss: 0.0495\n",
      "Batch 1970/1995, Loss: 0.0435\n",
      "Batch 1980/1995, Loss: 0.0564\n",
      "Batch 1990/1995, Loss: 0.0599\n",
      "\n",
      "Epoch 3 - Independent Model Training Complete. Loss: 0.0469\n",
      "\n",
      "Training Joint Probability Model - Epoch 3\n",
      "Batch 10/1995, Loss: 3.1854\n",
      "Batch 20/1995, Loss: 3.1854\n",
      "Batch 30/1995, Loss: 3.2010\n",
      "Batch 40/1995, Loss: 3.1854\n",
      "Batch 50/1995, Loss: 3.1854\n",
      "Batch 60/1995, Loss: 3.1854\n",
      "Batch 70/1995, Loss: 3.2010\n",
      "Batch 80/1995, Loss: 3.1854\n",
      "Batch 90/1995, Loss: 3.2010\n",
      "Batch 100/1995, Loss: 3.2010\n",
      "Batch 110/1995, Loss: 3.1854\n",
      "Batch 120/1995, Loss: 3.1854\n",
      "Batch 130/1995, Loss: 3.1854\n",
      "Batch 140/1995, Loss: 3.2010\n",
      "Batch 150/1995, Loss: 3.2010\n",
      "Batch 160/1995, Loss: 3.2010\n",
      "Batch 170/1995, Loss: 3.2010\n",
      "Batch 180/1995, Loss: 3.1854\n",
      "Batch 190/1995, Loss: 3.1854\n",
      "Batch 200/1995, Loss: 3.1854\n",
      "Batch 210/1995, Loss: 3.1854\n",
      "Batch 220/1995, Loss: 3.1854\n",
      "Batch 230/1995, Loss: 3.1854\n",
      "Batch 240/1995, Loss: 3.2010\n",
      "Batch 250/1995, Loss: 3.1854\n",
      "Batch 260/1995, Loss: 3.1854\n",
      "Batch 270/1995, Loss: 3.2010\n",
      "Batch 280/1995, Loss: 3.1854\n",
      "Batch 290/1995, Loss: 3.1854\n",
      "Batch 300/1995, Loss: 3.1854\n",
      "Batch 310/1995, Loss: 3.1854\n",
      "Batch 320/1995, Loss: 3.1854\n",
      "Batch 330/1995, Loss: 3.1854\n",
      "Batch 340/1995, Loss: 3.1854\n",
      "Batch 350/1995, Loss: 3.1854\n",
      "Batch 360/1995, Loss: 3.2010\n",
      "Batch 370/1995, Loss: 3.2010\n",
      "Batch 380/1995, Loss: 3.1854\n",
      "Batch 390/1995, Loss: 3.1854\n",
      "Batch 400/1995, Loss: 3.1854\n",
      "Batch 410/1995, Loss: 3.2010\n",
      "Batch 420/1995, Loss: 3.1854\n",
      "Batch 430/1995, Loss: 3.1854\n",
      "Batch 440/1995, Loss: 3.2010\n",
      "Batch 450/1995, Loss: 3.1854\n",
      "Batch 460/1995, Loss: 3.1854\n",
      "Batch 470/1995, Loss: 3.1854\n",
      "Batch 480/1995, Loss: 3.1854\n",
      "Batch 490/1995, Loss: 3.1854\n",
      "Batch 500/1995, Loss: 3.2010\n",
      "Batch 510/1995, Loss: 3.2010\n",
      "Batch 520/1995, Loss: 3.2010\n",
      "Batch 530/1995, Loss: 3.2010\n",
      "Batch 540/1995, Loss: 3.2010\n",
      "Batch 550/1995, Loss: 3.1854\n",
      "Batch 560/1995, Loss: 3.1854\n",
      "Batch 570/1995, Loss: 3.2010\n",
      "Batch 580/1995, Loss: 3.2010\n",
      "Batch 590/1995, Loss: 3.2166\n",
      "Batch 600/1995, Loss: 3.2010\n",
      "Batch 610/1995, Loss: 3.1854\n",
      "Batch 620/1995, Loss: 3.2010\n",
      "Batch 630/1995, Loss: 3.1854\n",
      "Batch 640/1995, Loss: 3.2010\n",
      "Batch 650/1995, Loss: 3.1854\n",
      "Batch 660/1995, Loss: 3.1854\n",
      "Batch 670/1995, Loss: 3.1854\n",
      "Batch 680/1995, Loss: 3.1854\n",
      "Batch 690/1995, Loss: 3.2010\n",
      "Batch 700/1995, Loss: 3.1854\n",
      "Batch 710/1995, Loss: 3.1854\n",
      "Batch 720/1995, Loss: 3.2010\n",
      "Batch 730/1995, Loss: 3.1854\n",
      "Batch 740/1995, Loss: 3.1854\n",
      "Batch 750/1995, Loss: 3.1854\n",
      "Batch 760/1995, Loss: 3.1854\n",
      "Batch 770/1995, Loss: 3.2010\n",
      "Batch 780/1995, Loss: 3.2010\n",
      "Batch 790/1995, Loss: 3.1854\n",
      "Batch 800/1995, Loss: 3.1854\n",
      "Batch 810/1995, Loss: 3.1854\n",
      "Batch 820/1995, Loss: 3.1854\n",
      "Batch 830/1995, Loss: 3.1854\n",
      "Batch 840/1995, Loss: 3.1854\n",
      "Batch 850/1995, Loss: 3.1854\n",
      "Batch 860/1995, Loss: 3.1854\n",
      "Batch 870/1995, Loss: 3.2166\n",
      "Batch 880/1995, Loss: 3.1854\n",
      "Batch 890/1995, Loss: 3.1854\n",
      "Batch 900/1995, Loss: 3.1854\n",
      "Batch 910/1995, Loss: 3.1854\n",
      "Batch 920/1995, Loss: 3.1854\n",
      "Batch 930/1995, Loss: 3.1854\n",
      "Batch 940/1995, Loss: 3.1854\n",
      "Batch 950/1995, Loss: 3.1854\n",
      "Batch 960/1995, Loss: 3.1854\n",
      "Batch 970/1995, Loss: 3.2010\n",
      "Batch 980/1995, Loss: 3.2010\n",
      "Batch 990/1995, Loss: 3.1854\n",
      "Batch 1000/1995, Loss: 3.1854\n",
      "Batch 1010/1995, Loss: 3.1854\n",
      "Batch 1020/1995, Loss: 3.1854\n",
      "Batch 1030/1995, Loss: 3.2010\n",
      "Batch 1040/1995, Loss: 3.1854\n",
      "Batch 1050/1995, Loss: 3.1854\n",
      "Batch 1060/1995, Loss: 3.2010\n",
      "Batch 1070/1995, Loss: 3.1854\n",
      "Batch 1080/1995, Loss: 3.1854\n",
      "Batch 1090/1995, Loss: 3.1854\n",
      "Batch 1100/1995, Loss: 3.1854\n",
      "Batch 1110/1995, Loss: 3.1854\n",
      "Batch 1120/1995, Loss: 3.1854\n",
      "Batch 1130/1995, Loss: 3.1854\n",
      "Batch 1140/1995, Loss: 3.1854\n",
      "Batch 1150/1995, Loss: 3.1854\n",
      "Batch 1160/1995, Loss: 3.1854\n",
      "Batch 1170/1995, Loss: 3.2166\n",
      "Batch 1180/1995, Loss: 3.1854\n",
      "Batch 1190/1995, Loss: 3.2010\n",
      "Batch 1200/1995, Loss: 3.2010\n",
      "Batch 1210/1995, Loss: 3.2010\n",
      "Batch 1220/1995, Loss: 3.2166\n",
      "Batch 1230/1995, Loss: 3.2010\n",
      "Batch 1240/1995, Loss: 3.2010\n",
      "Batch 1250/1995, Loss: 3.1854\n",
      "Batch 1260/1995, Loss: 3.1854\n",
      "Batch 1270/1995, Loss: 3.1854\n",
      "Batch 1280/1995, Loss: 3.1854\n",
      "Batch 1290/1995, Loss: 3.1854\n",
      "Batch 1300/1995, Loss: 3.2010\n",
      "Batch 1310/1995, Loss: 3.1854\n",
      "Batch 1320/1995, Loss: 3.1854\n",
      "Batch 1330/1995, Loss: 3.1854\n",
      "Batch 1340/1995, Loss: 3.1854\n",
      "Batch 1350/1995, Loss: 3.1854\n",
      "Batch 1360/1995, Loss: 3.1854\n",
      "Batch 1370/1995, Loss: 3.2010\n",
      "Batch 1380/1995, Loss: 3.1854\n",
      "Batch 1390/1995, Loss: 3.1854\n",
      "Batch 1400/1995, Loss: 3.2010\n",
      "Batch 1410/1995, Loss: 3.2010\n",
      "Batch 1420/1995, Loss: 3.1854\n",
      "Batch 1430/1995, Loss: 3.1854\n",
      "Batch 1440/1995, Loss: 3.1854\n",
      "Batch 1450/1995, Loss: 3.2166\n",
      "Batch 1460/1995, Loss: 3.1854\n",
      "Batch 1470/1995, Loss: 3.1854\n",
      "Batch 1480/1995, Loss: 3.1854\n",
      "Batch 1490/1995, Loss: 3.1854\n",
      "Batch 1500/1995, Loss: 3.1854\n",
      "Batch 1510/1995, Loss: 3.1854\n",
      "Batch 1520/1995, Loss: 3.1854\n",
      "Batch 1530/1995, Loss: 3.1854\n",
      "Batch 1540/1995, Loss: 3.2010\n",
      "Batch 1550/1995, Loss: 3.2010\n",
      "Batch 1560/1995, Loss: 3.1854\n",
      "Batch 1570/1995, Loss: 3.1854\n",
      "Batch 1580/1995, Loss: 3.1854\n",
      "Batch 1590/1995, Loss: 3.1854\n",
      "Batch 1600/1995, Loss: 3.1854\n",
      "Batch 1610/1995, Loss: 3.1854\n",
      "Batch 1620/1995, Loss: 3.1854\n",
      "Batch 1630/1995, Loss: 3.1854\n",
      "Batch 1640/1995, Loss: 3.1854\n",
      "Batch 1650/1995, Loss: 3.1854\n",
      "Batch 1660/1995, Loss: 3.1854\n",
      "Batch 1670/1995, Loss: 3.1854\n",
      "Batch 1680/1995, Loss: 3.1854\n",
      "Batch 1690/1995, Loss: 3.1854\n",
      "Batch 1700/1995, Loss: 3.2010\n",
      "Batch 1710/1995, Loss: 3.1854\n",
      "Batch 1720/1995, Loss: 3.2010\n",
      "Batch 1730/1995, Loss: 3.1854\n",
      "Batch 1740/1995, Loss: 3.2010\n",
      "Batch 1750/1995, Loss: 3.1854\n",
      "Batch 1760/1995, Loss: 3.1854\n",
      "Batch 1770/1995, Loss: 3.1854\n",
      "Batch 1780/1995, Loss: 3.1854\n",
      "Batch 1790/1995, Loss: 3.2010\n",
      "Batch 1800/1995, Loss: 3.1854\n",
      "Batch 1810/1995, Loss: 3.2010\n",
      "Batch 1820/1995, Loss: 3.1854\n",
      "Batch 1830/1995, Loss: 3.2010\n",
      "Batch 1840/1995, Loss: 3.2010\n",
      "Batch 1850/1995, Loss: 3.2010\n",
      "Batch 1860/1995, Loss: 3.2010\n",
      "Batch 1870/1995, Loss: 3.1854\n",
      "Batch 1880/1995, Loss: 3.2010\n",
      "Batch 1890/1995, Loss: 3.2010\n",
      "Batch 1900/1995, Loss: 3.1854\n",
      "Batch 1910/1995, Loss: 3.1854\n",
      "Batch 1920/1995, Loss: 3.2010\n",
      "Batch 1930/1995, Loss: 3.1854\n",
      "Batch 1940/1995, Loss: 3.2010\n",
      "Batch 1950/1995, Loss: 3.1854\n",
      "Batch 1960/1995, Loss: 3.1854\n",
      "Batch 1970/1995, Loss: 3.2166\n",
      "Batch 1980/1995, Loss: 3.1854\n",
      "Batch 1990/1995, Loss: 3.2010\n",
      "\n",
      "Epoch 3 - Joint Model Training Complete. Loss: 3.1912\n",
      "==================================================\n",
      "==================================================\n",
      "Starting Epoch 4 of Training\n",
      "\n",
      "\n",
      "Training Independent Probabilities Model - Epoch 4\n",
      "Batch 10/1995, Loss: 0.0227\n",
      "Batch 20/1995, Loss: 0.0497\n",
      "Batch 30/1995, Loss: 0.0103\n",
      "Batch 40/1995, Loss: 0.0264\n",
      "Batch 50/1995, Loss: 0.0476\n",
      "Batch 60/1995, Loss: 0.0265\n",
      "Batch 70/1995, Loss: 0.0339\n",
      "Batch 80/1995, Loss: 0.0388\n",
      "Batch 90/1995, Loss: 0.0566\n",
      "Batch 100/1995, Loss: 0.0636\n",
      "Batch 110/1995, Loss: 0.0218\n",
      "Batch 120/1995, Loss: 0.0255\n",
      "Batch 130/1995, Loss: 0.0450\n",
      "Batch 140/1995, Loss: 0.0494\n",
      "Batch 150/1995, Loss: 0.0711\n",
      "Batch 160/1995, Loss: 0.0217\n",
      "Batch 170/1995, Loss: 0.0380\n",
      "Batch 180/1995, Loss: 0.0367\n",
      "Batch 190/1995, Loss: 0.0391\n",
      "Batch 200/1995, Loss: 0.0277\n",
      "Batch 210/1995, Loss: 0.0424\n",
      "Batch 220/1995, Loss: 0.0217\n",
      "Batch 230/1995, Loss: 0.0676\n",
      "Batch 240/1995, Loss: 0.0473\n",
      "Batch 250/1995, Loss: 0.0559\n",
      "Batch 260/1995, Loss: 0.0242\n",
      "Batch 270/1995, Loss: 0.0203\n",
      "Batch 280/1995, Loss: 0.0378\n",
      "Batch 290/1995, Loss: 0.0400\n",
      "Batch 300/1995, Loss: 0.0288\n",
      "Batch 310/1995, Loss: 0.0222\n",
      "Batch 320/1995, Loss: 0.0291\n",
      "Batch 330/1995, Loss: 0.0636\n",
      "Batch 340/1995, Loss: 0.0364\n",
      "Batch 350/1995, Loss: 0.0435\n",
      "Batch 360/1995, Loss: 0.0172\n",
      "Batch 370/1995, Loss: 0.0107\n",
      "Batch 380/1995, Loss: 0.0220\n",
      "Batch 390/1995, Loss: 0.0378\n",
      "Batch 400/1995, Loss: 0.0126\n",
      "Batch 410/1995, Loss: 0.0157\n",
      "Batch 420/1995, Loss: 0.0186\n",
      "Batch 430/1995, Loss: 0.0363\n",
      "Batch 440/1995, Loss: 0.0159\n",
      "Batch 450/1995, Loss: 0.0312\n",
      "Batch 460/1995, Loss: 0.0467\n",
      "Batch 470/1995, Loss: 0.0262\n",
      "Batch 480/1995, Loss: 0.0468\n",
      "Batch 490/1995, Loss: 0.0300\n",
      "Batch 500/1995, Loss: 0.0159\n",
      "Batch 510/1995, Loss: 0.0562\n",
      "Batch 520/1995, Loss: 0.0320\n",
      "Batch 530/1995, Loss: 0.0350\n",
      "Batch 540/1995, Loss: 0.0163\n",
      "Batch 550/1995, Loss: 0.0279\n",
      "Batch 560/1995, Loss: 0.0741\n",
      "Batch 570/1995, Loss: 0.0172\n",
      "Batch 580/1995, Loss: 0.0544\n",
      "Batch 590/1995, Loss: 0.0377\n",
      "Batch 600/1995, Loss: 0.0474\n",
      "Batch 610/1995, Loss: 0.0390\n",
      "Batch 620/1995, Loss: 0.0605\n",
      "Batch 630/1995, Loss: 0.0601\n",
      "Batch 640/1995, Loss: 0.0443\n",
      "Batch 650/1995, Loss: 0.0265\n",
      "Batch 660/1995, Loss: 0.0256\n",
      "Batch 670/1995, Loss: 0.0276\n",
      "Batch 680/1995, Loss: 0.0242\n",
      "Batch 690/1995, Loss: 0.0133\n",
      "Batch 700/1995, Loss: 0.0644\n",
      "Batch 710/1995, Loss: 0.0492\n",
      "Batch 720/1995, Loss: 0.0141\n",
      "Batch 730/1995, Loss: 0.0446\n",
      "Batch 740/1995, Loss: 0.0280\n",
      "Batch 750/1995, Loss: 0.0324\n",
      "Batch 760/1995, Loss: 0.0333\n",
      "Batch 770/1995, Loss: 0.0341\n",
      "Batch 780/1995, Loss: 0.0567\n",
      "Batch 790/1995, Loss: 0.0352\n",
      "Batch 800/1995, Loss: 0.0340\n",
      "Batch 810/1995, Loss: 0.0491\n",
      "Batch 820/1995, Loss: 0.0395\n",
      "Batch 830/1995, Loss: 0.0414\n",
      "Batch 840/1995, Loss: 0.0421\n",
      "Batch 850/1995, Loss: 0.0761\n",
      "Batch 860/1995, Loss: 0.0311\n",
      "Batch 870/1995, Loss: 0.0203\n",
      "Batch 880/1995, Loss: 0.0361\n",
      "Batch 890/1995, Loss: 0.0321\n",
      "Batch 900/1995, Loss: 0.0346\n",
      "Batch 910/1995, Loss: 0.0231\n",
      "Batch 920/1995, Loss: 0.0793\n",
      "Batch 930/1995, Loss: 0.0354\n",
      "Batch 940/1995, Loss: 0.0386\n",
      "Batch 950/1995, Loss: 0.0520\n",
      "Batch 960/1995, Loss: 0.0462\n",
      "Batch 970/1995, Loss: 0.0468\n",
      "Batch 980/1995, Loss: 0.0445\n",
      "Batch 990/1995, Loss: 0.0399\n",
      "Batch 1000/1995, Loss: 0.0585\n",
      "Batch 1010/1995, Loss: 0.0324\n",
      "Batch 1020/1995, Loss: 0.0522\n",
      "Batch 1030/1995, Loss: 0.0424\n",
      "Batch 1040/1995, Loss: 0.0070\n",
      "Batch 1050/1995, Loss: 0.0439\n",
      "Batch 1060/1995, Loss: 0.0393\n",
      "Batch 1070/1995, Loss: 0.0486\n",
      "Batch 1080/1995, Loss: 0.0623\n",
      "Batch 1090/1995, Loss: 0.0544\n",
      "Batch 1100/1995, Loss: 0.0090\n",
      "Batch 1110/1995, Loss: 0.0708\n",
      "Batch 1120/1995, Loss: 0.0357\n",
      "Batch 1130/1995, Loss: 0.0606\n",
      "Batch 1140/1995, Loss: 0.0379\n",
      "Batch 1150/1995, Loss: 0.0717\n",
      "Batch 1160/1995, Loss: 0.0355\n",
      "Batch 1170/1995, Loss: 0.0185\n",
      "Batch 1180/1995, Loss: 0.0454\n",
      "Batch 1190/1995, Loss: 0.0289\n",
      "Batch 1200/1995, Loss: 0.0396\n",
      "Batch 1210/1995, Loss: 0.0953\n",
      "Batch 1220/1995, Loss: 0.0357\n",
      "Batch 1230/1995, Loss: 0.0158\n",
      "Batch 1240/1995, Loss: 0.0478\n",
      "Batch 1250/1995, Loss: 0.0484\n",
      "Batch 1260/1995, Loss: 0.0661\n",
      "Batch 1270/1995, Loss: 0.0213\n",
      "Batch 1280/1995, Loss: 0.0224\n",
      "Batch 1290/1995, Loss: 0.0287\n",
      "Batch 1300/1995, Loss: 0.0802\n",
      "Batch 1310/1995, Loss: 0.0491\n",
      "Batch 1320/1995, Loss: 0.0271\n",
      "Batch 1330/1995, Loss: 0.0548\n",
      "Batch 1340/1995, Loss: 0.0191\n",
      "Batch 1350/1995, Loss: 0.0487\n",
      "Batch 1360/1995, Loss: 0.0309\n",
      "Batch 1370/1995, Loss: 0.0335\n",
      "Batch 1380/1995, Loss: 0.0255\n",
      "Batch 1390/1995, Loss: 0.0206\n",
      "Batch 1400/1995, Loss: 0.0311\n",
      "Batch 1410/1995, Loss: 0.0484\n",
      "Batch 1420/1995, Loss: 0.0624\n",
      "Batch 1430/1995, Loss: 0.0304\n",
      "Batch 1440/1995, Loss: 0.0221\n",
      "Batch 1450/1995, Loss: 0.0252\n",
      "Batch 1460/1995, Loss: 0.0185\n",
      "Batch 1470/1995, Loss: 0.0725\n",
      "Batch 1480/1995, Loss: 0.0205\n",
      "Batch 1490/1995, Loss: 0.0744\n",
      "Batch 1500/1995, Loss: 0.0541\n",
      "Batch 1510/1995, Loss: 0.0195\n",
      "Batch 1520/1995, Loss: 0.0245\n",
      "Batch 1530/1995, Loss: 0.0415\n",
      "Batch 1540/1995, Loss: 0.0503\n",
      "Batch 1550/1995, Loss: 0.0426\n",
      "Batch 1560/1995, Loss: 0.0257\n",
      "Batch 1570/1995, Loss: 0.0555\n",
      "Batch 1580/1995, Loss: 0.0556\n",
      "Batch 1590/1995, Loss: 0.0165\n",
      "Batch 1600/1995, Loss: 0.0299\n",
      "Batch 1610/1995, Loss: 0.0206\n",
      "Batch 1620/1995, Loss: 0.0385\n",
      "Batch 1630/1995, Loss: 0.0054\n",
      "Batch 1640/1995, Loss: 0.0469\n",
      "Batch 1650/1995, Loss: 0.0385\n",
      "Batch 1660/1995, Loss: 0.0284\n",
      "Batch 1670/1995, Loss: 0.0404\n",
      "Batch 1680/1995, Loss: 0.0759\n",
      "Batch 1690/1995, Loss: 0.0668\n",
      "Batch 1700/1995, Loss: 0.0340\n",
      "Batch 1710/1995, Loss: 0.0065\n",
      "Batch 1720/1995, Loss: 0.0338\n",
      "Batch 1730/1995, Loss: 0.0604\n",
      "Batch 1740/1995, Loss: 0.0089\n",
      "Batch 1750/1995, Loss: 0.0688\n",
      "Batch 1760/1995, Loss: 0.0644\n",
      "Batch 1770/1995, Loss: 0.0207\n",
      "Batch 1780/1995, Loss: 0.0486\n",
      "Batch 1790/1995, Loss: 0.0404\n",
      "Batch 1800/1995, Loss: 0.0299\n",
      "Batch 1810/1995, Loss: 0.0283\n",
      "Batch 1820/1995, Loss: 0.0639\n",
      "Batch 1830/1995, Loss: 0.0359\n",
      "Batch 1840/1995, Loss: 0.0312\n",
      "Batch 1850/1995, Loss: 0.0354\n",
      "Batch 1860/1995, Loss: 0.0275\n",
      "Batch 1870/1995, Loss: 0.0346\n",
      "Batch 1880/1995, Loss: 0.0150\n",
      "Batch 1890/1995, Loss: 0.0222\n",
      "Batch 1900/1995, Loss: 0.0544\n",
      "Batch 1910/1995, Loss: 0.0563\n",
      "Batch 1920/1995, Loss: 0.0162\n",
      "Batch 1930/1995, Loss: 0.0142\n",
      "Batch 1940/1995, Loss: 0.0593\n",
      "Batch 1950/1995, Loss: 0.0572\n",
      "Batch 1960/1995, Loss: 0.0276\n",
      "Batch 1970/1995, Loss: 0.0387\n",
      "Batch 1980/1995, Loss: 0.0655\n",
      "Batch 1990/1995, Loss: 0.0269\n",
      "\n",
      "Epoch 4 - Independent Model Training Complete. Loss: 0.0392\n",
      "\n",
      "Training Joint Probability Model - Epoch 4\n",
      "Batch 10/1995, Loss: 3.1854\n",
      "Batch 20/1995, Loss: 3.1854\n",
      "Batch 30/1995, Loss: 3.1854\n",
      "Batch 40/1995, Loss: 3.1854\n",
      "Batch 50/1995, Loss: 3.1854\n",
      "Batch 60/1995, Loss: 3.2010\n",
      "Batch 70/1995, Loss: 3.1854\n",
      "Batch 80/1995, Loss: 3.2010\n",
      "Batch 90/1995, Loss: 3.1854\n",
      "Batch 100/1995, Loss: 3.1854\n",
      "Batch 110/1995, Loss: 3.2010\n",
      "Batch 120/1995, Loss: 3.1854\n",
      "Batch 130/1995, Loss: 3.2010\n",
      "Batch 140/1995, Loss: 3.1854\n",
      "Batch 150/1995, Loss: 3.2010\n",
      "Batch 160/1995, Loss: 3.2010\n",
      "Batch 170/1995, Loss: 3.1854\n",
      "Batch 180/1995, Loss: 3.1854\n",
      "Batch 190/1995, Loss: 3.2166\n",
      "Batch 200/1995, Loss: 3.1854\n",
      "Batch 210/1995, Loss: 3.1854\n",
      "Batch 220/1995, Loss: 3.1854\n",
      "Batch 230/1995, Loss: 3.1854\n",
      "Batch 240/1995, Loss: 3.1854\n",
      "Batch 250/1995, Loss: 3.1854\n",
      "Batch 260/1995, Loss: 3.2010\n",
      "Batch 270/1995, Loss: 3.1854\n",
      "Batch 280/1995, Loss: 3.2010\n",
      "Batch 290/1995, Loss: 3.2010\n",
      "Batch 300/1995, Loss: 3.2010\n",
      "Batch 310/1995, Loss: 3.1854\n",
      "Batch 320/1995, Loss: 3.2010\n",
      "Batch 330/1995, Loss: 3.1854\n",
      "Batch 340/1995, Loss: 3.1854\n",
      "Batch 350/1995, Loss: 3.1854\n",
      "Batch 360/1995, Loss: 3.1854\n",
      "Batch 370/1995, Loss: 3.2166\n",
      "Batch 380/1995, Loss: 3.1854\n",
      "Batch 390/1995, Loss: 3.2010\n",
      "Batch 400/1995, Loss: 3.2010\n",
      "Batch 410/1995, Loss: 3.1854\n",
      "Batch 420/1995, Loss: 3.1854\n",
      "Batch 430/1995, Loss: 3.1854\n",
      "Batch 440/1995, Loss: 3.2010\n",
      "Batch 450/1995, Loss: 3.1854\n",
      "Batch 460/1995, Loss: 3.2010\n",
      "Batch 470/1995, Loss: 3.1854\n",
      "Batch 480/1995, Loss: 3.2010\n",
      "Batch 490/1995, Loss: 3.1854\n",
      "Batch 500/1995, Loss: 3.2010\n",
      "Batch 510/1995, Loss: 3.1854\n",
      "Batch 520/1995, Loss: 3.2010\n",
      "Batch 530/1995, Loss: 3.1854\n",
      "Batch 540/1995, Loss: 3.1854\n",
      "Batch 550/1995, Loss: 3.1854\n",
      "Batch 560/1995, Loss: 3.1854\n",
      "Batch 570/1995, Loss: 3.1854\n",
      "Batch 580/1995, Loss: 3.1854\n",
      "Batch 590/1995, Loss: 3.1854\n",
      "Batch 600/1995, Loss: 3.1854\n",
      "Batch 610/1995, Loss: 3.1854\n",
      "Batch 620/1995, Loss: 3.1854\n",
      "Batch 630/1995, Loss: 3.1854\n",
      "Batch 640/1995, Loss: 3.2010\n",
      "Batch 650/1995, Loss: 3.1854\n",
      "Batch 660/1995, Loss: 3.1854\n",
      "Batch 670/1995, Loss: 3.2010\n",
      "Batch 680/1995, Loss: 3.2010\n",
      "Batch 690/1995, Loss: 3.1854\n",
      "Batch 700/1995, Loss: 3.1854\n",
      "Batch 710/1995, Loss: 3.2010\n",
      "Batch 720/1995, Loss: 3.1854\n",
      "Batch 730/1995, Loss: 3.1854\n",
      "Batch 740/1995, Loss: 3.1854\n",
      "Batch 750/1995, Loss: 3.1854\n",
      "Batch 760/1995, Loss: 3.2010\n",
      "Batch 770/1995, Loss: 3.2010\n",
      "Batch 780/1995, Loss: 3.1854\n",
      "Batch 790/1995, Loss: 3.2166\n",
      "Batch 800/1995, Loss: 3.2010\n",
      "Batch 810/1995, Loss: 3.1854\n",
      "Batch 820/1995, Loss: 3.2010\n",
      "Batch 830/1995, Loss: 3.1854\n",
      "Batch 840/1995, Loss: 3.1854\n",
      "Batch 850/1995, Loss: 3.1854\n",
      "Batch 860/1995, Loss: 3.2010\n",
      "Batch 870/1995, Loss: 3.1854\n",
      "Batch 880/1995, Loss: 3.1854\n",
      "Batch 890/1995, Loss: 3.2010\n",
      "Batch 900/1995, Loss: 3.1854\n",
      "Batch 910/1995, Loss: 3.2010\n",
      "Batch 920/1995, Loss: 3.1854\n",
      "Batch 930/1995, Loss: 3.1854\n",
      "Batch 940/1995, Loss: 3.2010\n",
      "Batch 950/1995, Loss: 3.2010\n",
      "Batch 960/1995, Loss: 3.2010\n",
      "Batch 970/1995, Loss: 3.1854\n",
      "Batch 980/1995, Loss: 3.1854\n",
      "Batch 990/1995, Loss: 3.2010\n",
      "Batch 1000/1995, Loss: 3.1854\n",
      "Batch 1010/1995, Loss: 3.1854\n",
      "Batch 1020/1995, Loss: 3.2010\n",
      "Batch 1030/1995, Loss: 3.2010\n",
      "Batch 1040/1995, Loss: 3.1854\n",
      "Batch 1050/1995, Loss: 3.1854\n",
      "Batch 1060/1995, Loss: 3.2010\n",
      "Batch 1070/1995, Loss: 3.1854\n",
      "Batch 1080/1995, Loss: 3.1854\n",
      "Batch 1090/1995, Loss: 3.2010\n",
      "Batch 1100/1995, Loss: 3.1854\n",
      "Batch 1110/1995, Loss: 3.1854\n",
      "Batch 1120/1995, Loss: 3.1854\n",
      "Batch 1130/1995, Loss: 3.1854\n",
      "Batch 1140/1995, Loss: 3.2010\n",
      "Batch 1150/1995, Loss: 3.2166\n",
      "Batch 1160/1995, Loss: 3.1854\n",
      "Batch 1170/1995, Loss: 3.1854\n",
      "Batch 1180/1995, Loss: 3.1854\n",
      "Batch 1190/1995, Loss: 3.2010\n",
      "Batch 1200/1995, Loss: 3.1854\n",
      "Batch 1210/1995, Loss: 3.1854\n",
      "Batch 1220/1995, Loss: 3.1854\n",
      "Batch 1230/1995, Loss: 3.2010\n",
      "Batch 1240/1995, Loss: 3.2010\n",
      "Batch 1250/1995, Loss: 3.2010\n",
      "Batch 1260/1995, Loss: 3.1854\n",
      "Batch 1270/1995, Loss: 3.1854\n",
      "Batch 1280/1995, Loss: 3.1854\n",
      "Batch 1290/1995, Loss: 3.2166\n",
      "Batch 1300/1995, Loss: 3.2010\n",
      "Batch 1310/1995, Loss: 3.1854\n",
      "Batch 1320/1995, Loss: 3.1854\n",
      "Batch 1330/1995, Loss: 3.1854\n",
      "Batch 1340/1995, Loss: 3.1854\n",
      "Batch 1350/1995, Loss: 3.1854\n",
      "Batch 1360/1995, Loss: 3.1854\n",
      "Batch 1370/1995, Loss: 3.1854\n",
      "Batch 1380/1995, Loss: 3.1854\n",
      "Batch 1390/1995, Loss: 3.1854\n",
      "Batch 1400/1995, Loss: 3.1854\n",
      "Batch 1410/1995, Loss: 3.2010\n",
      "Batch 1420/1995, Loss: 3.2166\n",
      "Batch 1430/1995, Loss: 3.2010\n",
      "Batch 1440/1995, Loss: 3.1854\n",
      "Batch 1450/1995, Loss: 3.1854\n",
      "Batch 1460/1995, Loss: 3.1854\n",
      "Batch 1470/1995, Loss: 3.2010\n",
      "Batch 1480/1995, Loss: 3.1854\n",
      "Batch 1490/1995, Loss: 3.1854\n",
      "Batch 1500/1995, Loss: 3.1854\n",
      "Batch 1510/1995, Loss: 3.1854\n",
      "Batch 1520/1995, Loss: 3.1854\n",
      "Batch 1530/1995, Loss: 3.2323\n",
      "Batch 1540/1995, Loss: 3.1854\n",
      "Batch 1550/1995, Loss: 3.2010\n",
      "Batch 1560/1995, Loss: 3.2166\n",
      "Batch 1570/1995, Loss: 3.1854\n",
      "Batch 1580/1995, Loss: 3.1854\n",
      "Batch 1590/1995, Loss: 3.1854\n",
      "Batch 1600/1995, Loss: 3.1854\n",
      "Batch 1610/1995, Loss: 3.1854\n",
      "Batch 1620/1995, Loss: 3.1854\n",
      "Batch 1630/1995, Loss: 3.1854\n",
      "Batch 1640/1995, Loss: 3.1854\n",
      "Batch 1650/1995, Loss: 3.1854\n",
      "Batch 1660/1995, Loss: 3.2010\n",
      "Batch 1670/1995, Loss: 3.1854\n",
      "Batch 1680/1995, Loss: 3.1854\n",
      "Batch 1690/1995, Loss: 3.1854\n",
      "Batch 1700/1995, Loss: 3.1854\n",
      "Batch 1710/1995, Loss: 3.2010\n",
      "Batch 1720/1995, Loss: 3.1854\n",
      "Batch 1730/1995, Loss: 3.1854\n",
      "Batch 1740/1995, Loss: 3.2010\n",
      "Batch 1750/1995, Loss: 3.2010\n",
      "Batch 1760/1995, Loss: 3.1854\n",
      "Batch 1770/1995, Loss: 3.1854\n",
      "Batch 1780/1995, Loss: 3.1854\n",
      "Batch 1790/1995, Loss: 3.1854\n",
      "Batch 1800/1995, Loss: 3.1854\n",
      "Batch 1810/1995, Loss: 3.1854\n",
      "Batch 1820/1995, Loss: 3.1854\n",
      "Batch 1830/1995, Loss: 3.1854\n",
      "Batch 1840/1995, Loss: 3.2010\n",
      "Batch 1850/1995, Loss: 3.1854\n",
      "Batch 1860/1995, Loss: 3.1854\n",
      "Batch 1870/1995, Loss: 3.1854\n",
      "Batch 1880/1995, Loss: 3.1854\n",
      "Batch 1890/1995, Loss: 3.2010\n",
      "Batch 1900/1995, Loss: 3.1854\n",
      "Batch 1910/1995, Loss: 3.1854\n",
      "Batch 1920/1995, Loss: 3.2010\n",
      "Batch 1930/1995, Loss: 3.1854\n",
      "Batch 1940/1995, Loss: 3.1854\n",
      "Batch 1950/1995, Loss: 3.1854\n",
      "Batch 1960/1995, Loss: 3.1854\n",
      "Batch 1970/1995, Loss: 3.1854\n",
      "Batch 1980/1995, Loss: 3.1854\n",
      "Batch 1990/1995, Loss: 3.1854\n",
      "\n",
      "Epoch 4 - Joint Model Training Complete. Loss: 3.1912\n",
      "==================================================\n",
      "==================================================\n",
      "Starting Epoch 5 of Training\n",
      "\n",
      "\n",
      "Training Independent Probabilities Model - Epoch 5\n",
      "Batch 10/1995, Loss: 0.0754\n",
      "Batch 20/1995, Loss: 0.0123\n",
      "Batch 30/1995, Loss: 0.0475\n",
      "Batch 40/1995, Loss: 0.0363\n",
      "Batch 50/1995, Loss: 0.0341\n",
      "Batch 60/1995, Loss: 0.0160\n",
      "Batch 70/1995, Loss: 0.0344\n",
      "Batch 80/1995, Loss: 0.0439\n",
      "Batch 90/1995, Loss: 0.0194\n",
      "Batch 100/1995, Loss: 0.0564\n",
      "Batch 110/1995, Loss: 0.0642\n",
      "Batch 120/1995, Loss: 0.0823\n",
      "Batch 130/1995, Loss: 0.0293\n",
      "Batch 140/1995, Loss: 0.0402\n",
      "Batch 150/1995, Loss: 0.0359\n",
      "Batch 160/1995, Loss: 0.0656\n",
      "Batch 170/1995, Loss: 0.0321\n",
      "Batch 180/1995, Loss: 0.0189\n",
      "Batch 190/1995, Loss: 0.0148\n",
      "Batch 200/1995, Loss: 0.0083\n",
      "Batch 210/1995, Loss: 0.0283\n",
      "Batch 220/1995, Loss: 0.0375\n",
      "Batch 230/1995, Loss: 0.0214\n",
      "Batch 240/1995, Loss: 0.0206\n",
      "Batch 250/1995, Loss: 0.0323\n",
      "Batch 260/1995, Loss: 0.0494\n",
      "Batch 270/1995, Loss: 0.0163\n",
      "Batch 280/1995, Loss: 0.0484\n",
      "Batch 290/1995, Loss: 0.0387\n",
      "Batch 300/1995, Loss: 0.0406\n",
      "Batch 310/1995, Loss: 0.0326\n",
      "Batch 320/1995, Loss: 0.0349\n",
      "Batch 330/1995, Loss: 0.0331\n",
      "Batch 340/1995, Loss: 0.0513\n",
      "Batch 350/1995, Loss: 0.0355\n",
      "Batch 360/1995, Loss: 0.0227\n",
      "Batch 370/1995, Loss: 0.0553\n",
      "Batch 380/1995, Loss: 0.0491\n",
      "Batch 390/1995, Loss: 0.0197\n",
      "Batch 400/1995, Loss: 0.0159\n",
      "Batch 410/1995, Loss: 0.0326\n",
      "Batch 420/1995, Loss: 0.0351\n",
      "Batch 430/1995, Loss: 0.0243\n",
      "Batch 440/1995, Loss: 0.0170\n",
      "Batch 450/1995, Loss: 0.0830\n",
      "Batch 460/1995, Loss: 0.0236\n",
      "Batch 470/1995, Loss: 0.0581\n",
      "Batch 480/1995, Loss: 0.0125\n",
      "Batch 490/1995, Loss: 0.0418\n",
      "Batch 500/1995, Loss: 0.0627\n",
      "Batch 510/1995, Loss: 0.0388\n",
      "Batch 520/1995, Loss: 0.0213\n",
      "Batch 530/1995, Loss: 0.0327\n",
      "Batch 540/1995, Loss: 0.0262\n",
      "Batch 550/1995, Loss: 0.0354\n",
      "Batch 560/1995, Loss: 0.0364\n",
      "Batch 570/1995, Loss: 0.0323\n",
      "Batch 580/1995, Loss: 0.0219\n",
      "Batch 590/1995, Loss: 0.0198\n",
      "Batch 600/1995, Loss: 0.0619\n",
      "Batch 610/1995, Loss: 0.0590\n",
      "Batch 620/1995, Loss: 0.0384\n",
      "Batch 630/1995, Loss: 0.0208\n",
      "Batch 640/1995, Loss: 0.0452\n",
      "Batch 650/1995, Loss: 0.0366\n",
      "Batch 660/1995, Loss: 0.0444\n",
      "Batch 670/1995, Loss: 0.0192\n",
      "Batch 680/1995, Loss: 0.0241\n",
      "Batch 690/1995, Loss: 0.0475\n",
      "Batch 700/1995, Loss: 0.0444\n",
      "Batch 710/1995, Loss: 0.0334\n",
      "Batch 720/1995, Loss: 0.0226\n",
      "Batch 730/1995, Loss: 0.0365\n",
      "Batch 740/1995, Loss: 0.0307\n",
      "Batch 750/1995, Loss: 0.0340\n",
      "Batch 760/1995, Loss: 0.0871\n",
      "Batch 770/1995, Loss: 0.0637\n",
      "Batch 780/1995, Loss: 0.0302\n",
      "Batch 790/1995, Loss: 0.0227\n",
      "Batch 800/1995, Loss: 0.0172\n",
      "Batch 810/1995, Loss: 0.0438\n",
      "Batch 820/1995, Loss: 0.0153\n",
      "Batch 830/1995, Loss: 0.0516\n",
      "Batch 840/1995, Loss: 0.0573\n",
      "Batch 850/1995, Loss: 0.0320\n",
      "Batch 860/1995, Loss: 0.0111\n",
      "Batch 870/1995, Loss: 0.0485\n",
      "Batch 880/1995, Loss: 0.0582\n",
      "Batch 890/1995, Loss: 0.0112\n",
      "Batch 900/1995, Loss: 0.0141\n",
      "Batch 910/1995, Loss: 0.0156\n",
      "Batch 920/1995, Loss: 0.0309\n",
      "Batch 930/1995, Loss: 0.0151\n",
      "Batch 940/1995, Loss: 0.0489\n",
      "Batch 950/1995, Loss: 0.0132\n",
      "Batch 960/1995, Loss: 0.0075\n",
      "Batch 970/1995, Loss: 0.0269\n",
      "Batch 980/1995, Loss: 0.0452\n",
      "Batch 990/1995, Loss: 0.0230\n",
      "Batch 1000/1995, Loss: 0.0657\n",
      "Batch 1010/1995, Loss: 0.0282\n",
      "Batch 1020/1995, Loss: 0.0287\n",
      "Batch 1030/1995, Loss: 0.0322\n",
      "Batch 1040/1995, Loss: 0.0524\n",
      "Batch 1050/1995, Loss: 0.0262\n",
      "Batch 1060/1995, Loss: 0.0575\n",
      "Batch 1070/1995, Loss: 0.0117\n",
      "Batch 1080/1995, Loss: 0.0233\n",
      "Batch 1090/1995, Loss: 0.0866\n",
      "Batch 1100/1995, Loss: 0.0444\n",
      "Batch 1110/1995, Loss: 0.0235\n",
      "Batch 1120/1995, Loss: 0.0262\n",
      "Batch 1130/1995, Loss: 0.0714\n",
      "Batch 1140/1995, Loss: 0.0611\n",
      "Batch 1150/1995, Loss: 0.0652\n",
      "Batch 1160/1995, Loss: 0.0532\n",
      "Batch 1170/1995, Loss: 0.0362\n",
      "Batch 1180/1995, Loss: 0.0367\n",
      "Batch 1190/1995, Loss: 0.0143\n",
      "Batch 1200/1995, Loss: 0.0181\n",
      "Batch 1210/1995, Loss: 0.0361\n",
      "Batch 1220/1995, Loss: 0.0378\n",
      "Batch 1230/1995, Loss: 0.0606\n",
      "Batch 1240/1995, Loss: 0.0591\n",
      "Batch 1250/1995, Loss: 0.0676\n",
      "Batch 1260/1995, Loss: 0.0267\n",
      "Batch 1270/1995, Loss: 0.0535\n",
      "Batch 1280/1995, Loss: 0.0408\n",
      "Batch 1290/1995, Loss: 0.0349\n",
      "Batch 1300/1995, Loss: 0.0411\n",
      "Batch 1310/1995, Loss: 0.0119\n",
      "Batch 1320/1995, Loss: 0.0311\n",
      "Batch 1330/1995, Loss: 0.0682\n",
      "Batch 1340/1995, Loss: 0.0449\n",
      "Batch 1350/1995, Loss: 0.0300\n",
      "Batch 1360/1995, Loss: 0.0552\n",
      "Batch 1370/1995, Loss: 0.0504\n",
      "Batch 1380/1995, Loss: 0.0248\n",
      "Batch 1390/1995, Loss: 0.0335\n",
      "Batch 1400/1995, Loss: 0.0291\n",
      "Batch 1410/1995, Loss: 0.0388\n",
      "Batch 1420/1995, Loss: 0.0355\n",
      "Batch 1430/1995, Loss: 0.0513\n",
      "Batch 1440/1995, Loss: 0.0515\n",
      "Batch 1450/1995, Loss: 0.0396\n",
      "Batch 1460/1995, Loss: 0.0220\n",
      "Batch 1470/1995, Loss: 0.0203\n",
      "Batch 1480/1995, Loss: 0.0431\n",
      "Batch 1490/1995, Loss: 0.0154\n",
      "Batch 1500/1995, Loss: 0.0364\n",
      "Batch 1510/1995, Loss: 0.0267\n",
      "Batch 1520/1995, Loss: 0.0507\n",
      "Batch 1530/1995, Loss: 0.0166\n",
      "Batch 1540/1995, Loss: 0.0464\n",
      "Batch 1550/1995, Loss: 0.0212\n",
      "Batch 1560/1995, Loss: 0.0314\n",
      "Batch 1570/1995, Loss: 0.0378\n",
      "Batch 1580/1995, Loss: 0.0470\n",
      "Batch 1590/1995, Loss: 0.0048\n",
      "Batch 1600/1995, Loss: 0.0307\n",
      "Batch 1610/1995, Loss: 0.0647\n",
      "Batch 1620/1995, Loss: 0.0270\n",
      "Batch 1630/1995, Loss: 0.0247\n",
      "Batch 1640/1995, Loss: 0.0510\n",
      "Batch 1650/1995, Loss: 0.0377\n",
      "Batch 1660/1995, Loss: 0.0549\n",
      "Batch 1670/1995, Loss: 0.0429\n",
      "Batch 1680/1995, Loss: 0.0462\n",
      "Batch 1690/1995, Loss: 0.0598\n",
      "Batch 1700/1995, Loss: 0.0317\n",
      "Batch 1710/1995, Loss: 0.0279\n",
      "Batch 1720/1995, Loss: 0.0528\n",
      "Batch 1730/1995, Loss: 0.0273\n",
      "Batch 1740/1995, Loss: 0.0563\n",
      "Batch 1750/1995, Loss: 0.0534\n",
      "Batch 1760/1995, Loss: 0.0619\n",
      "Batch 1770/1995, Loss: 0.0322\n",
      "Batch 1780/1995, Loss: 0.0447\n",
      "Batch 1790/1995, Loss: 0.0378\n",
      "Batch 1800/1995, Loss: 0.0220\n",
      "Batch 1810/1995, Loss: 0.0299\n",
      "Batch 1820/1995, Loss: 0.0548\n",
      "Batch 1830/1995, Loss: 0.0461\n",
      "Batch 1840/1995, Loss: 0.0283\n",
      "Batch 1850/1995, Loss: 0.0845\n",
      "Batch 1860/1995, Loss: 0.0301\n",
      "Batch 1870/1995, Loss: 0.0354\n",
      "Batch 1880/1995, Loss: 0.0195\n",
      "Batch 1890/1995, Loss: 0.0206\n",
      "Batch 1900/1995, Loss: 0.0451\n",
      "Batch 1910/1995, Loss: 0.0248\n",
      "Batch 1920/1995, Loss: 0.0328\n",
      "Batch 1930/1995, Loss: 0.0315\n",
      "Batch 1940/1995, Loss: 0.0275\n",
      "Batch 1950/1995, Loss: 0.0236\n",
      "Batch 1960/1995, Loss: 0.0400\n",
      "Batch 1970/1995, Loss: 0.0426\n",
      "Batch 1980/1995, Loss: 0.0326\n",
      "Batch 1990/1995, Loss: 0.0551\n",
      "\n",
      "Epoch 5 - Independent Model Training Complete. Loss: 0.0337\n",
      "\n",
      "Training Joint Probability Model - Epoch 5\n",
      "Batch 10/1995, Loss: 3.1854\n",
      "Batch 20/1995, Loss: 3.1854\n",
      "Batch 30/1995, Loss: 3.1854\n",
      "Batch 40/1995, Loss: 3.2166\n",
      "Batch 50/1995, Loss: 3.2010\n",
      "Batch 60/1995, Loss: 3.2010\n",
      "Batch 70/1995, Loss: 3.1854\n",
      "Batch 80/1995, Loss: 3.1854\n",
      "Batch 90/1995, Loss: 3.1854\n",
      "Batch 100/1995, Loss: 3.1854\n",
      "Batch 110/1995, Loss: 3.1854\n",
      "Batch 120/1995, Loss: 3.1854\n",
      "Batch 130/1995, Loss: 3.1854\n",
      "Batch 140/1995, Loss: 3.1854\n",
      "Batch 150/1995, Loss: 3.2010\n",
      "Batch 160/1995, Loss: 3.2010\n",
      "Batch 170/1995, Loss: 3.2010\n",
      "Batch 180/1995, Loss: 3.1854\n",
      "Batch 190/1995, Loss: 3.1854\n",
      "Batch 200/1995, Loss: 3.2010\n",
      "Batch 210/1995, Loss: 3.1854\n",
      "Batch 220/1995, Loss: 3.1854\n",
      "Batch 230/1995, Loss: 3.2010\n",
      "Batch 240/1995, Loss: 3.1854\n",
      "Batch 250/1995, Loss: 3.2166\n",
      "Batch 260/1995, Loss: 3.1854\n",
      "Batch 270/1995, Loss: 3.1854\n",
      "Batch 280/1995, Loss: 3.2010\n",
      "Batch 290/1995, Loss: 3.1854\n",
      "Batch 300/1995, Loss: 3.1854\n",
      "Batch 310/1995, Loss: 3.2166\n",
      "Batch 320/1995, Loss: 3.1854\n",
      "Batch 330/1995, Loss: 3.1854\n",
      "Batch 340/1995, Loss: 3.1854\n",
      "Batch 350/1995, Loss: 3.1854\n",
      "Batch 360/1995, Loss: 3.1854\n",
      "Batch 370/1995, Loss: 3.1854\n",
      "Batch 380/1995, Loss: 3.2010\n",
      "Batch 390/1995, Loss: 3.1854\n",
      "Batch 400/1995, Loss: 3.2010\n",
      "Batch 410/1995, Loss: 3.1854\n",
      "Batch 420/1995, Loss: 3.2010\n",
      "Batch 430/1995, Loss: 3.2010\n",
      "Batch 440/1995, Loss: 3.1854\n",
      "Batch 450/1995, Loss: 3.1854\n",
      "Batch 460/1995, Loss: 3.2010\n",
      "Batch 470/1995, Loss: 3.1854\n",
      "Batch 480/1995, Loss: 3.2010\n",
      "Batch 490/1995, Loss: 3.1854\n",
      "Batch 500/1995, Loss: 3.1854\n",
      "Batch 510/1995, Loss: 3.2010\n",
      "Batch 520/1995, Loss: 3.2010\n",
      "Batch 530/1995, Loss: 3.1854\n",
      "Batch 540/1995, Loss: 3.2010\n",
      "Batch 550/1995, Loss: 3.1854\n",
      "Batch 560/1995, Loss: 3.1854\n",
      "Batch 570/1995, Loss: 3.2010\n",
      "Batch 580/1995, Loss: 3.2010\n",
      "Batch 590/1995, Loss: 3.2010\n",
      "Batch 600/1995, Loss: 3.1854\n",
      "Batch 610/1995, Loss: 3.2010\n",
      "Batch 620/1995, Loss: 3.1854\n",
      "Batch 630/1995, Loss: 3.1854\n",
      "Batch 640/1995, Loss: 3.1854\n",
      "Batch 650/1995, Loss: 3.2166\n",
      "Batch 660/1995, Loss: 3.1854\n",
      "Batch 670/1995, Loss: 3.1854\n",
      "Batch 680/1995, Loss: 3.1854\n",
      "Batch 690/1995, Loss: 3.1854\n",
      "Batch 700/1995, Loss: 3.1854\n",
      "Batch 710/1995, Loss: 3.1854\n",
      "Batch 720/1995, Loss: 3.2010\n",
      "Batch 730/1995, Loss: 3.1854\n",
      "Batch 740/1995, Loss: 3.1854\n",
      "Batch 750/1995, Loss: 3.1854\n",
      "Batch 760/1995, Loss: 3.1854\n",
      "Batch 770/1995, Loss: 3.1854\n",
      "Batch 780/1995, Loss: 3.1854\n",
      "Batch 790/1995, Loss: 3.2166\n",
      "Batch 800/1995, Loss: 3.1854\n",
      "Batch 810/1995, Loss: 3.1854\n",
      "Batch 820/1995, Loss: 3.2010\n",
      "Batch 830/1995, Loss: 3.1854\n",
      "Batch 840/1995, Loss: 3.2010\n",
      "Batch 850/1995, Loss: 3.1854\n",
      "Batch 860/1995, Loss: 3.1854\n",
      "Batch 870/1995, Loss: 3.2010\n",
      "Batch 880/1995, Loss: 3.2010\n",
      "Batch 890/1995, Loss: 3.2010\n",
      "Batch 900/1995, Loss: 3.1854\n",
      "Batch 910/1995, Loss: 3.1854\n",
      "Batch 920/1995, Loss: 3.1854\n",
      "Batch 930/1995, Loss: 3.1854\n",
      "Batch 940/1995, Loss: 3.2010\n",
      "Batch 950/1995, Loss: 3.1854\n",
      "Batch 960/1995, Loss: 3.1854\n",
      "Batch 970/1995, Loss: 3.1854\n",
      "Batch 980/1995, Loss: 3.1854\n",
      "Batch 990/1995, Loss: 3.2010\n",
      "Batch 1000/1995, Loss: 3.1854\n",
      "Batch 1010/1995, Loss: 3.1854\n",
      "Batch 1020/1995, Loss: 3.1854\n",
      "Batch 1030/1995, Loss: 3.1854\n",
      "Batch 1040/1995, Loss: 3.1854\n",
      "Batch 1050/1995, Loss: 3.1854\n",
      "Batch 1060/1995, Loss: 3.2010\n",
      "Batch 1070/1995, Loss: 3.2010\n",
      "Batch 1080/1995, Loss: 3.1854\n",
      "Batch 1090/1995, Loss: 3.2010\n",
      "Batch 1100/1995, Loss: 3.1854\n",
      "Batch 1110/1995, Loss: 3.2166\n",
      "Batch 1120/1995, Loss: 3.1854\n",
      "Batch 1130/1995, Loss: 3.2010\n",
      "Batch 1140/1995, Loss: 3.1854\n",
      "Batch 1150/1995, Loss: 3.1854\n",
      "Batch 1160/1995, Loss: 3.2010\n",
      "Batch 1170/1995, Loss: 3.1854\n",
      "Batch 1180/1995, Loss: 3.2010\n",
      "Batch 1190/1995, Loss: 3.2010\n",
      "Batch 1200/1995, Loss: 3.2166\n",
      "Batch 1210/1995, Loss: 3.2010\n",
      "Batch 1220/1995, Loss: 3.1854\n",
      "Batch 1230/1995, Loss: 3.1854\n",
      "Batch 1240/1995, Loss: 3.1854\n",
      "Batch 1250/1995, Loss: 3.1854\n",
      "Batch 1260/1995, Loss: 3.1854\n",
      "Batch 1270/1995, Loss: 3.1854\n",
      "Batch 1280/1995, Loss: 3.1854\n",
      "Batch 1290/1995, Loss: 3.1854\n",
      "Batch 1300/1995, Loss: 3.2010\n",
      "Batch 1310/1995, Loss: 3.1854\n",
      "Batch 1320/1995, Loss: 3.2166\n",
      "Batch 1330/1995, Loss: 3.1854\n",
      "Batch 1340/1995, Loss: 3.1854\n",
      "Batch 1350/1995, Loss: 3.2010\n",
      "Batch 1360/1995, Loss: 3.1854\n",
      "Batch 1370/1995, Loss: 3.1854\n",
      "Batch 1380/1995, Loss: 3.1854\n",
      "Batch 1390/1995, Loss: 3.2010\n",
      "Batch 1400/1995, Loss: 3.1854\n",
      "Batch 1410/1995, Loss: 3.1854\n",
      "Batch 1420/1995, Loss: 3.2166\n",
      "Batch 1430/1995, Loss: 3.1854\n",
      "Batch 1440/1995, Loss: 3.2166\n",
      "Batch 1450/1995, Loss: 3.1854\n",
      "Batch 1460/1995, Loss: 3.1854\n",
      "Batch 1470/1995, Loss: 3.2010\n",
      "Batch 1480/1995, Loss: 3.2010\n",
      "Batch 1490/1995, Loss: 3.2010\n",
      "Batch 1500/1995, Loss: 3.1854\n",
      "Batch 1510/1995, Loss: 3.1854\n",
      "Batch 1520/1995, Loss: 3.1854\n",
      "Batch 1530/1995, Loss: 3.2010\n",
      "Batch 1540/1995, Loss: 3.1854\n",
      "Batch 1550/1995, Loss: 3.1854\n",
      "Batch 1560/1995, Loss: 3.1854\n",
      "Batch 1570/1995, Loss: 3.2010\n",
      "Batch 1580/1995, Loss: 3.1854\n",
      "Batch 1590/1995, Loss: 3.1854\n",
      "Batch 1600/1995, Loss: 3.2010\n",
      "Batch 1610/1995, Loss: 3.2010\n",
      "Batch 1620/1995, Loss: 3.1854\n",
      "Batch 1630/1995, Loss: 3.2010\n",
      "Batch 1640/1995, Loss: 3.1854\n",
      "Batch 1650/1995, Loss: 3.2010\n",
      "Batch 1660/1995, Loss: 3.2166\n",
      "Batch 1670/1995, Loss: 3.1854\n",
      "Batch 1680/1995, Loss: 3.1854\n",
      "Batch 1690/1995, Loss: 3.1854\n",
      "Batch 1700/1995, Loss: 3.2010\n",
      "Batch 1710/1995, Loss: 3.1854\n",
      "Batch 1720/1995, Loss: 3.2010\n",
      "Batch 1730/1995, Loss: 3.1854\n",
      "Batch 1740/1995, Loss: 3.1854\n",
      "Batch 1750/1995, Loss: 3.2010\n",
      "Batch 1760/1995, Loss: 3.1854\n",
      "Batch 1770/1995, Loss: 3.1854\n",
      "Batch 1780/1995, Loss: 3.2010\n",
      "Batch 1790/1995, Loss: 3.1854\n",
      "Batch 1800/1995, Loss: 3.1854\n",
      "Batch 1810/1995, Loss: 3.1854\n",
      "Batch 1820/1995, Loss: 3.2010\n",
      "Batch 1830/1995, Loss: 3.1854\n",
      "Batch 1840/1995, Loss: 3.1854\n",
      "Batch 1850/1995, Loss: 3.1854\n",
      "Batch 1860/1995, Loss: 3.2010\n",
      "Batch 1870/1995, Loss: 3.1854\n",
      "Batch 1880/1995, Loss: 3.1854\n",
      "Batch 1890/1995, Loss: 3.1854\n",
      "Batch 1900/1995, Loss: 3.1854\n",
      "Batch 1910/1995, Loss: 3.2010\n",
      "Batch 1920/1995, Loss: 3.1854\n",
      "Batch 1930/1995, Loss: 3.1854\n",
      "Batch 1940/1995, Loss: 3.2010\n",
      "Batch 1950/1995, Loss: 3.1854\n",
      "Batch 1960/1995, Loss: 3.1854\n",
      "Batch 1970/1995, Loss: 3.1854\n",
      "Batch 1980/1995, Loss: 3.1854\n",
      "Batch 1990/1995, Loss: 3.1854\n",
      "\n",
      "Epoch 5 - Joint Model Training Complete. Loss: 3.1912\n",
      "==================================================\n",
      "==================================================\n",
      "Starting Epoch 6 of Training\n",
      "\n",
      "\n",
      "Training Independent Probabilities Model - Epoch 6\n",
      "Batch 10/1995, Loss: 0.0706\n",
      "Batch 20/1995, Loss: 0.0172\n",
      "Batch 30/1995, Loss: 0.0206\n",
      "Batch 40/1995, Loss: 0.0293\n",
      "Batch 50/1995, Loss: 0.0282\n",
      "Batch 60/1995, Loss: 0.0436\n",
      "Batch 70/1995, Loss: 0.0619\n",
      "Batch 80/1995, Loss: 0.0173\n",
      "Batch 90/1995, Loss: 0.0175\n",
      "Batch 100/1995, Loss: 0.0146\n",
      "Batch 110/1995, Loss: 0.0507\n",
      "Batch 120/1995, Loss: 0.0249\n",
      "Batch 130/1995, Loss: 0.0350\n",
      "Batch 140/1995, Loss: 0.0647\n",
      "Batch 150/1995, Loss: 0.0326\n",
      "Batch 160/1995, Loss: 0.0255\n",
      "Batch 170/1995, Loss: 0.0315\n",
      "Batch 180/1995, Loss: 0.0174\n",
      "Batch 190/1995, Loss: 0.0435\n",
      "Batch 200/1995, Loss: 0.0252\n",
      "Batch 210/1995, Loss: 0.0087\n",
      "Batch 220/1995, Loss: 0.0251\n",
      "Batch 230/1995, Loss: 0.0708\n",
      "Batch 240/1995, Loss: 0.0126\n",
      "Batch 250/1995, Loss: 0.0286\n",
      "Batch 260/1995, Loss: 0.0233\n",
      "Batch 270/1995, Loss: 0.0480\n",
      "Batch 280/1995, Loss: 0.0267\n",
      "Batch 290/1995, Loss: 0.0278\n",
      "Batch 300/1995, Loss: 0.0363\n",
      "Batch 310/1995, Loss: 0.0079\n",
      "Batch 320/1995, Loss: 0.0128\n",
      "Batch 330/1995, Loss: 0.0297\n",
      "Batch 340/1995, Loss: 0.0367\n",
      "Batch 350/1995, Loss: 0.0167\n",
      "Batch 360/1995, Loss: 0.0406\n",
      "Batch 370/1995, Loss: 0.0306\n",
      "Batch 380/1995, Loss: 0.0212\n",
      "Batch 390/1995, Loss: 0.0258\n",
      "Batch 400/1995, Loss: 0.0179\n",
      "Batch 410/1995, Loss: 0.0245\n",
      "Batch 420/1995, Loss: 0.0673\n",
      "Batch 430/1995, Loss: 0.0370\n",
      "Batch 440/1995, Loss: 0.0252\n",
      "Batch 450/1995, Loss: 0.0084\n",
      "Batch 460/1995, Loss: 0.0398\n",
      "Batch 470/1995, Loss: 0.0339\n",
      "Batch 480/1995, Loss: 0.0300\n",
      "Batch 490/1995, Loss: 0.0213\n",
      "Batch 500/1995, Loss: 0.0546\n",
      "Batch 510/1995, Loss: 0.0327\n",
      "Batch 520/1995, Loss: 0.0164\n",
      "Batch 530/1995, Loss: 0.0209\n",
      "Batch 540/1995, Loss: 0.0310\n",
      "Batch 550/1995, Loss: 0.0279\n",
      "Batch 560/1995, Loss: 0.0343\n",
      "Batch 570/1995, Loss: 0.0229\n",
      "Batch 580/1995, Loss: 0.0344\n",
      "Batch 590/1995, Loss: 0.0051\n",
      "Batch 600/1995, Loss: 0.0318\n",
      "Batch 610/1995, Loss: 0.0221\n",
      "Batch 620/1995, Loss: 0.0063\n",
      "Batch 630/1995, Loss: 0.0438\n",
      "Batch 640/1995, Loss: 0.0481\n",
      "Batch 650/1995, Loss: 0.0401\n",
      "Batch 660/1995, Loss: 0.0307\n",
      "Batch 670/1995, Loss: 0.0177\n",
      "Batch 680/1995, Loss: 0.0344\n",
      "Batch 690/1995, Loss: 0.0495\n",
      "Batch 700/1995, Loss: 0.0301\n",
      "Batch 710/1995, Loss: 0.0353\n",
      "Batch 720/1995, Loss: 0.0238\n",
      "Batch 730/1995, Loss: 0.0228\n",
      "Batch 740/1995, Loss: 0.0395\n",
      "Batch 750/1995, Loss: 0.0142\n",
      "Batch 760/1995, Loss: 0.0181\n",
      "Batch 770/1995, Loss: 0.0177\n",
      "Batch 780/1995, Loss: 0.0407\n",
      "Batch 790/1995, Loss: 0.0226\n",
      "Batch 800/1995, Loss: 0.0424\n",
      "Batch 810/1995, Loss: 0.0217\n",
      "Batch 820/1995, Loss: 0.0290\n",
      "Batch 830/1995, Loss: 0.0390\n",
      "Batch 840/1995, Loss: 0.0208\n",
      "Batch 850/1995, Loss: 0.0406\n",
      "Batch 860/1995, Loss: 0.0066\n",
      "Batch 870/1995, Loss: 0.0141\n",
      "Batch 880/1995, Loss: 0.0362\n",
      "Batch 890/1995, Loss: 0.0113\n",
      "Batch 900/1995, Loss: 0.0160\n",
      "Batch 910/1995, Loss: 0.0210\n",
      "Batch 920/1995, Loss: 0.0164\n",
      "Batch 930/1995, Loss: 0.0157\n",
      "Batch 940/1995, Loss: 0.0200\n",
      "Batch 950/1995, Loss: 0.0425\n",
      "Batch 960/1995, Loss: 0.0181\n",
      "Batch 970/1995, Loss: 0.0346\n",
      "Batch 980/1995, Loss: 0.0415\n",
      "Batch 990/1995, Loss: 0.0182\n",
      "Batch 1000/1995, Loss: 0.0366\n",
      "Batch 1010/1995, Loss: 0.0267\n",
      "Batch 1020/1995, Loss: 0.0286\n",
      "Batch 1030/1995, Loss: 0.0030\n",
      "Batch 1040/1995, Loss: 0.0375\n",
      "Batch 1050/1995, Loss: 0.0619\n",
      "Batch 1060/1995, Loss: 0.0400\n",
      "Batch 1070/1995, Loss: 0.0105\n",
      "Batch 1080/1995, Loss: 0.0438\n",
      "Batch 1090/1995, Loss: 0.0287\n",
      "Batch 1100/1995, Loss: 0.0430\n",
      "Batch 1110/1995, Loss: 0.0180\n",
      "Batch 1120/1995, Loss: 0.0299\n",
      "Batch 1130/1995, Loss: 0.0429\n",
      "Batch 1140/1995, Loss: 0.0127\n",
      "Batch 1150/1995, Loss: 0.0338\n",
      "Batch 1160/1995, Loss: 0.0164\n",
      "Batch 1170/1995, Loss: 0.0302\n",
      "Batch 1180/1995, Loss: 0.0098\n",
      "Batch 1190/1995, Loss: 0.0171\n",
      "Batch 1200/1995, Loss: 0.0362\n",
      "Batch 1210/1995, Loss: 0.0447\n",
      "Batch 1220/1995, Loss: 0.0611\n",
      "Batch 1230/1995, Loss: 0.0385\n",
      "Batch 1240/1995, Loss: 0.0377\n",
      "Batch 1250/1995, Loss: 0.0228\n",
      "Batch 1260/1995, Loss: 0.0192\n",
      "Batch 1270/1995, Loss: 0.0400\n",
      "Batch 1280/1995, Loss: 0.0404\n",
      "Batch 1290/1995, Loss: 0.0355\n",
      "Batch 1300/1995, Loss: 0.0396\n",
      "Batch 1310/1995, Loss: 0.0287\n",
      "Batch 1320/1995, Loss: 0.0381\n",
      "Batch 1330/1995, Loss: 0.0247\n",
      "Batch 1340/1995, Loss: 0.0168\n",
      "Batch 1350/1995, Loss: 0.0456\n",
      "Batch 1360/1995, Loss: 0.0299\n",
      "Batch 1370/1995, Loss: 0.0074\n",
      "Batch 1380/1995, Loss: 0.0269\n",
      "Batch 1390/1995, Loss: 0.0376\n",
      "Batch 1400/1995, Loss: 0.0124\n",
      "Batch 1410/1995, Loss: 0.0094\n",
      "Batch 1420/1995, Loss: 0.0226\n",
      "Batch 1430/1995, Loss: 0.0029\n",
      "Batch 1440/1995, Loss: 0.0595\n",
      "Batch 1450/1995, Loss: 0.0501\n",
      "Batch 1460/1995, Loss: 0.0254\n",
      "Batch 1470/1995, Loss: 0.0440\n",
      "Batch 1480/1995, Loss: 0.0212\n",
      "Batch 1490/1995, Loss: 0.0246\n",
      "Batch 1500/1995, Loss: 0.0209\n",
      "Batch 1510/1995, Loss: 0.0209\n",
      "Batch 1520/1995, Loss: 0.0226\n",
      "Batch 1530/1995, Loss: 0.0163\n",
      "Batch 1540/1995, Loss: 0.0426\n",
      "Batch 1550/1995, Loss: 0.0223\n",
      "Batch 1560/1995, Loss: 0.0161\n",
      "Batch 1570/1995, Loss: 0.0330\n",
      "Batch 1580/1995, Loss: 0.0647\n",
      "Batch 1590/1995, Loss: 0.0342\n",
      "Batch 1600/1995, Loss: 0.0335\n",
      "Batch 1610/1995, Loss: 0.0331\n",
      "Batch 1620/1995, Loss: 0.0355\n",
      "Batch 1630/1995, Loss: 0.0190\n",
      "Batch 1640/1995, Loss: 0.0342\n",
      "Batch 1650/1995, Loss: 0.0338\n",
      "Batch 1660/1995, Loss: 0.0094\n",
      "Batch 1670/1995, Loss: 0.0331\n",
      "Batch 1680/1995, Loss: 0.0417\n",
      "Batch 1690/1995, Loss: 0.0224\n",
      "Batch 1700/1995, Loss: 0.0165\n",
      "Batch 1710/1995, Loss: 0.0084\n",
      "Batch 1720/1995, Loss: 0.0235\n",
      "Batch 1730/1995, Loss: 0.0341\n",
      "Batch 1740/1995, Loss: 0.0210\n",
      "Batch 1750/1995, Loss: 0.0350\n",
      "Batch 1760/1995, Loss: 0.0254\n",
      "Batch 1770/1995, Loss: 0.0406\n",
      "Batch 1780/1995, Loss: 0.0248\n",
      "Batch 1790/1995, Loss: 0.0066\n",
      "Batch 1800/1995, Loss: 0.0222\n",
      "Batch 1810/1995, Loss: 0.0268\n",
      "Batch 1820/1995, Loss: 0.0472\n",
      "Batch 1830/1995, Loss: 0.0309\n",
      "Batch 1840/1995, Loss: 0.0362\n",
      "Batch 1850/1995, Loss: 0.0159\n",
      "Batch 1860/1995, Loss: 0.0294\n",
      "Batch 1870/1995, Loss: 0.0124\n",
      "Batch 1880/1995, Loss: 0.0201\n",
      "Batch 1890/1995, Loss: 0.0271\n",
      "Batch 1900/1995, Loss: 0.0267\n",
      "Batch 1910/1995, Loss: 0.0227\n",
      "Batch 1920/1995, Loss: 0.0456\n",
      "Batch 1930/1995, Loss: 0.0311\n",
      "Batch 1940/1995, Loss: 0.0118\n",
      "Batch 1950/1995, Loss: 0.0123\n",
      "Batch 1960/1995, Loss: 0.0430\n",
      "Batch 1970/1995, Loss: 0.0309\n",
      "Batch 1980/1995, Loss: 0.0272\n",
      "Batch 1990/1995, Loss: 0.0098\n",
      "\n",
      "Epoch 6 - Independent Model Training Complete. Loss: 0.0299\n",
      "\n",
      "Training Joint Probability Model - Epoch 6\n",
      "Batch 10/1995, Loss: 3.1854\n",
      "Batch 20/1995, Loss: 3.1854\n",
      "Batch 30/1995, Loss: 3.1854\n",
      "Batch 40/1995, Loss: 3.1854\n",
      "Batch 50/1995, Loss: 3.2166\n",
      "Batch 60/1995, Loss: 3.1854\n",
      "Batch 70/1995, Loss: 3.1854\n",
      "Batch 80/1995, Loss: 3.2010\n",
      "Batch 90/1995, Loss: 3.1854\n",
      "Batch 100/1995, Loss: 3.2166\n",
      "Batch 110/1995, Loss: 3.2166\n",
      "Batch 120/1995, Loss: 3.2010\n",
      "Batch 130/1995, Loss: 3.1854\n",
      "Batch 140/1995, Loss: 3.2010\n",
      "Batch 150/1995, Loss: 3.1854\n",
      "Batch 160/1995, Loss: 3.1854\n",
      "Batch 170/1995, Loss: 3.1854\n",
      "Batch 180/1995, Loss: 3.1854\n",
      "Batch 190/1995, Loss: 3.1854\n",
      "Batch 200/1995, Loss: 3.1854\n",
      "Batch 210/1995, Loss: 3.2166\n",
      "Batch 220/1995, Loss: 3.2323\n",
      "Batch 230/1995, Loss: 3.1854\n",
      "Batch 240/1995, Loss: 3.1854\n",
      "Batch 250/1995, Loss: 3.1854\n",
      "Batch 260/1995, Loss: 3.1854\n",
      "Batch 270/1995, Loss: 3.1854\n",
      "Batch 280/1995, Loss: 3.2010\n",
      "Batch 290/1995, Loss: 3.1854\n",
      "Batch 300/1995, Loss: 3.1854\n",
      "Batch 310/1995, Loss: 3.2010\n",
      "Batch 320/1995, Loss: 3.1854\n",
      "Batch 330/1995, Loss: 3.1854\n",
      "Batch 340/1995, Loss: 3.2010\n",
      "Batch 350/1995, Loss: 3.1854\n",
      "Batch 360/1995, Loss: 3.1854\n",
      "Batch 370/1995, Loss: 3.1854\n",
      "Batch 380/1995, Loss: 3.1854\n",
      "Batch 390/1995, Loss: 3.1854\n",
      "Batch 400/1995, Loss: 3.2010\n",
      "Batch 410/1995, Loss: 3.1854\n",
      "Batch 420/1995, Loss: 3.1854\n",
      "Batch 430/1995, Loss: 3.1854\n",
      "Batch 440/1995, Loss: 3.1854\n",
      "Batch 450/1995, Loss: 3.1854\n",
      "Batch 460/1995, Loss: 3.1854\n",
      "Batch 470/1995, Loss: 3.1854\n",
      "Batch 480/1995, Loss: 3.1854\n",
      "Batch 490/1995, Loss: 3.1854\n",
      "Batch 500/1995, Loss: 3.1854\n",
      "Batch 510/1995, Loss: 3.1854\n",
      "Batch 520/1995, Loss: 3.1854\n",
      "Batch 530/1995, Loss: 3.1854\n",
      "Batch 540/1995, Loss: 3.1854\n",
      "Batch 550/1995, Loss: 3.1854\n",
      "Batch 560/1995, Loss: 3.1854\n",
      "Batch 570/1995, Loss: 3.1854\n",
      "Batch 580/1995, Loss: 3.1854\n",
      "Batch 590/1995, Loss: 3.1854\n",
      "Batch 600/1995, Loss: 3.1854\n",
      "Batch 610/1995, Loss: 3.2010\n",
      "Batch 620/1995, Loss: 3.1854\n",
      "Batch 630/1995, Loss: 3.2010\n",
      "Batch 640/1995, Loss: 3.1854\n",
      "Batch 650/1995, Loss: 3.2010\n",
      "Batch 660/1995, Loss: 3.2010\n",
      "Batch 670/1995, Loss: 3.1854\n",
      "Batch 680/1995, Loss: 3.2166\n",
      "Batch 690/1995, Loss: 3.1854\n",
      "Batch 700/1995, Loss: 3.1854\n",
      "Batch 710/1995, Loss: 3.1854\n",
      "Batch 720/1995, Loss: 3.1854\n",
      "Batch 730/1995, Loss: 3.1854\n",
      "Batch 740/1995, Loss: 3.1854\n",
      "Batch 750/1995, Loss: 3.1854\n",
      "Batch 760/1995, Loss: 3.1854\n",
      "Batch 770/1995, Loss: 3.1854\n",
      "Batch 780/1995, Loss: 3.1854\n",
      "Batch 790/1995, Loss: 3.1854\n",
      "Batch 800/1995, Loss: 3.1854\n",
      "Batch 810/1995, Loss: 3.1854\n",
      "Batch 820/1995, Loss: 3.1854\n",
      "Batch 830/1995, Loss: 3.1854\n",
      "Batch 840/1995, Loss: 3.1854\n",
      "Batch 850/1995, Loss: 3.1854\n",
      "Batch 860/1995, Loss: 3.1854\n",
      "Batch 870/1995, Loss: 3.1854\n",
      "Batch 880/1995, Loss: 3.1854\n",
      "Batch 890/1995, Loss: 3.1854\n",
      "Batch 900/1995, Loss: 3.1854\n",
      "Batch 910/1995, Loss: 3.1854\n",
      "Batch 920/1995, Loss: 3.1854\n",
      "Batch 930/1995, Loss: 3.2010\n",
      "Batch 940/1995, Loss: 3.1854\n",
      "Batch 950/1995, Loss: 3.2166\n",
      "Batch 960/1995, Loss: 3.1854\n",
      "Batch 970/1995, Loss: 3.1854\n",
      "Batch 980/1995, Loss: 3.1854\n",
      "Batch 990/1995, Loss: 3.2010\n",
      "Batch 1000/1995, Loss: 3.1854\n",
      "Batch 1010/1995, Loss: 3.1854\n",
      "Batch 1020/1995, Loss: 3.2010\n",
      "Batch 1030/1995, Loss: 3.1854\n",
      "Batch 1040/1995, Loss: 3.2010\n",
      "Batch 1050/1995, Loss: 3.2166\n",
      "Batch 1060/1995, Loss: 3.1854\n",
      "Batch 1070/1995, Loss: 3.1854\n",
      "Batch 1080/1995, Loss: 3.1854\n",
      "Batch 1090/1995, Loss: 3.1854\n",
      "Batch 1100/1995, Loss: 3.1854\n",
      "Batch 1110/1995, Loss: 3.1854\n",
      "Batch 1120/1995, Loss: 3.1854\n",
      "Batch 1130/1995, Loss: 3.1854\n",
      "Batch 1140/1995, Loss: 3.2010\n",
      "Batch 1150/1995, Loss: 3.1854\n",
      "Batch 1160/1995, Loss: 3.2010\n",
      "Batch 1170/1995, Loss: 3.1854\n",
      "Batch 1180/1995, Loss: 3.2166\n",
      "Batch 1190/1995, Loss: 3.2166\n",
      "Batch 1200/1995, Loss: 3.2010\n",
      "Batch 1210/1995, Loss: 3.2166\n",
      "Batch 1220/1995, Loss: 3.2010\n",
      "Batch 1230/1995, Loss: 3.2166\n",
      "Batch 1240/1995, Loss: 3.1854\n",
      "Batch 1250/1995, Loss: 3.1854\n",
      "Batch 1260/1995, Loss: 3.1854\n",
      "Batch 1270/1995, Loss: 3.2010\n",
      "Batch 1280/1995, Loss: 3.1854\n",
      "Batch 1290/1995, Loss: 3.1854\n",
      "Batch 1300/1995, Loss: 3.2166\n",
      "Batch 1310/1995, Loss: 3.2010\n",
      "Batch 1320/1995, Loss: 3.2010\n",
      "Batch 1330/1995, Loss: 3.1854\n",
      "Batch 1340/1995, Loss: 3.1854\n",
      "Batch 1350/1995, Loss: 3.2010\n",
      "Batch 1360/1995, Loss: 3.1854\n",
      "Batch 1370/1995, Loss: 3.1854\n",
      "Batch 1380/1995, Loss: 3.2010\n",
      "Batch 1390/1995, Loss: 3.2010\n",
      "Batch 1400/1995, Loss: 3.1854\n",
      "Batch 1410/1995, Loss: 3.1854\n",
      "Batch 1420/1995, Loss: 3.1854\n",
      "Batch 1430/1995, Loss: 3.1854\n",
      "Batch 1440/1995, Loss: 3.1854\n",
      "Batch 1450/1995, Loss: 3.1854\n",
      "Batch 1460/1995, Loss: 3.1854\n",
      "Batch 1470/1995, Loss: 3.1854\n",
      "Batch 1480/1995, Loss: 3.1854\n",
      "Batch 1490/1995, Loss: 3.2010\n",
      "Batch 1500/1995, Loss: 3.1854\n",
      "Batch 1510/1995, Loss: 3.1854\n",
      "Batch 1520/1995, Loss: 3.1854\n",
      "Batch 1530/1995, Loss: 3.1854\n",
      "Batch 1540/1995, Loss: 3.1854\n",
      "Batch 1550/1995, Loss: 3.1854\n",
      "Batch 1560/1995, Loss: 3.1854\n",
      "Batch 1570/1995, Loss: 3.1854\n",
      "Batch 1580/1995, Loss: 3.2010\n",
      "Batch 1590/1995, Loss: 3.1854\n",
      "Batch 1600/1995, Loss: 3.1854\n",
      "Batch 1610/1995, Loss: 3.1854\n",
      "Batch 1620/1995, Loss: 3.2010\n",
      "Batch 1630/1995, Loss: 3.1854\n",
      "Batch 1640/1995, Loss: 3.1854\n",
      "Batch 1650/1995, Loss: 3.2010\n",
      "Batch 1660/1995, Loss: 3.1854\n",
      "Batch 1670/1995, Loss: 3.1854\n",
      "Batch 1680/1995, Loss: 3.1854\n",
      "Batch 1690/1995, Loss: 3.2010\n",
      "Batch 1700/1995, Loss: 3.1854\n",
      "Batch 1710/1995, Loss: 3.1854\n",
      "Batch 1720/1995, Loss: 3.2010\n",
      "Batch 1730/1995, Loss: 3.1854\n",
      "Batch 1740/1995, Loss: 3.1854\n",
      "Batch 1750/1995, Loss: 3.2010\n",
      "Batch 1760/1995, Loss: 3.1854\n",
      "Batch 1770/1995, Loss: 3.2010\n",
      "Batch 1780/1995, Loss: 3.2010\n",
      "Batch 1790/1995, Loss: 3.1854\n",
      "Batch 1800/1995, Loss: 3.2010\n",
      "Batch 1810/1995, Loss: 3.1854\n",
      "Batch 1820/1995, Loss: 3.2010\n",
      "Batch 1830/1995, Loss: 3.2010\n",
      "Batch 1840/1995, Loss: 3.2010\n",
      "Batch 1850/1995, Loss: 3.1854\n",
      "Batch 1860/1995, Loss: 3.2010\n",
      "Batch 1870/1995, Loss: 3.1854\n",
      "Batch 1880/1995, Loss: 3.1854\n",
      "Batch 1890/1995, Loss: 3.2010\n",
      "Batch 1900/1995, Loss: 3.1854\n",
      "Batch 1910/1995, Loss: 3.2010\n",
      "Batch 1920/1995, Loss: 3.1854\n",
      "Batch 1930/1995, Loss: 3.1854\n",
      "Batch 1940/1995, Loss: 3.1854\n",
      "Batch 1950/1995, Loss: 3.1854\n",
      "Batch 1960/1995, Loss: 3.1854\n",
      "Batch 1970/1995, Loss: 3.1854\n",
      "Batch 1980/1995, Loss: 3.1854\n",
      "Batch 1990/1995, Loss: 3.2010\n",
      "\n",
      "Epoch 6 - Joint Model Training Complete. Loss: 3.1912\n",
      "==================================================\n",
      "==================================================\n",
      "Starting Epoch 7 of Training\n",
      "\n",
      "\n",
      "Training Independent Probabilities Model - Epoch 7\n",
      "Batch 10/1995, Loss: 0.0308\n",
      "Batch 20/1995, Loss: 0.0179\n",
      "Batch 30/1995, Loss: 0.0131\n",
      "Batch 40/1995, Loss: 0.0301\n",
      "Batch 50/1995, Loss: 0.0435\n",
      "Batch 60/1995, Loss: 0.0281\n",
      "Batch 70/1995, Loss: 0.0454\n",
      "Batch 80/1995, Loss: 0.0144\n",
      "Batch 90/1995, Loss: 0.0074\n",
      "Batch 100/1995, Loss: 0.0119\n",
      "Batch 110/1995, Loss: 0.0058\n",
      "Batch 120/1995, Loss: 0.0340\n",
      "Batch 130/1995, Loss: 0.0181\n",
      "Batch 140/1995, Loss: 0.0331\n",
      "Batch 150/1995, Loss: 0.0243\n",
      "Batch 160/1995, Loss: 0.0104\n",
      "Batch 170/1995, Loss: 0.0156\n",
      "Batch 180/1995, Loss: 0.0442\n",
      "Batch 190/1995, Loss: 0.0054\n",
      "Batch 200/1995, Loss: 0.0138\n",
      "Batch 210/1995, Loss: 0.0265\n",
      "Batch 220/1995, Loss: 0.0072\n",
      "Batch 230/1995, Loss: 0.0155\n",
      "Batch 240/1995, Loss: 0.0415\n",
      "Batch 250/1995, Loss: 0.0529\n",
      "Batch 260/1995, Loss: 0.0498\n",
      "Batch 270/1995, Loss: 0.0257\n",
      "Batch 280/1995, Loss: 0.0249\n",
      "Batch 290/1995, Loss: 0.0295\n",
      "Batch 300/1995, Loss: 0.0251\n",
      "Batch 310/1995, Loss: 0.0390\n",
      "Batch 320/1995, Loss: 0.0164\n",
      "Batch 330/1995, Loss: 0.0236\n",
      "Batch 340/1995, Loss: 0.0233\n",
      "Batch 350/1995, Loss: 0.0554\n",
      "Batch 360/1995, Loss: 0.0323\n",
      "Batch 370/1995, Loss: 0.0142\n",
      "Batch 380/1995, Loss: 0.0221\n",
      "Batch 390/1995, Loss: 0.0263\n",
      "Batch 400/1995, Loss: 0.0347\n",
      "Batch 410/1995, Loss: 0.0555\n",
      "Batch 420/1995, Loss: 0.0308\n",
      "Batch 430/1995, Loss: 0.0147\n",
      "Batch 440/1995, Loss: 0.0324\n",
      "Batch 450/1995, Loss: 0.0106\n",
      "Batch 460/1995, Loss: 0.0238\n",
      "Batch 470/1995, Loss: 0.0308\n",
      "Batch 480/1995, Loss: 0.0251\n",
      "Batch 490/1995, Loss: 0.0238\n",
      "Batch 500/1995, Loss: 0.0421\n",
      "Batch 510/1995, Loss: 0.0263\n",
      "Batch 520/1995, Loss: 0.0113\n",
      "Batch 530/1995, Loss: 0.0251\n",
      "Batch 540/1995, Loss: 0.0257\n",
      "Batch 550/1995, Loss: 0.0239\n",
      "Batch 560/1995, Loss: 0.0145\n",
      "Batch 570/1995, Loss: 0.0160\n",
      "Batch 580/1995, Loss: 0.0102\n",
      "Batch 590/1995, Loss: 0.0171\n",
      "Batch 600/1995, Loss: 0.0134\n",
      "Batch 610/1995, Loss: 0.0304\n",
      "Batch 620/1995, Loss: 0.0292\n",
      "Batch 630/1995, Loss: 0.0198\n",
      "Batch 640/1995, Loss: 0.0284\n",
      "Batch 650/1995, Loss: 0.0129\n",
      "Batch 660/1995, Loss: 0.0114\n",
      "Batch 670/1995, Loss: 0.0254\n",
      "Batch 680/1995, Loss: 0.0242\n",
      "Batch 690/1995, Loss: 0.0278\n",
      "Batch 700/1995, Loss: 0.0136\n",
      "Batch 710/1995, Loss: 0.0400\n",
      "Batch 720/1995, Loss: 0.0381\n",
      "Batch 730/1995, Loss: 0.0325\n",
      "Batch 740/1995, Loss: 0.0139\n",
      "Batch 750/1995, Loss: 0.0195\n",
      "Batch 760/1995, Loss: 0.0142\n",
      "Batch 770/1995, Loss: 0.0288\n",
      "Batch 780/1995, Loss: 0.0223\n",
      "Batch 790/1995, Loss: 0.0230\n",
      "Batch 800/1995, Loss: 0.0310\n",
      "Batch 810/1995, Loss: 0.0210\n",
      "Batch 820/1995, Loss: 0.0143\n",
      "Batch 830/1995, Loss: 0.0011\n",
      "Batch 840/1995, Loss: 0.0161\n",
      "Batch 850/1995, Loss: 0.0391\n",
      "Batch 860/1995, Loss: 0.0283\n",
      "Batch 870/1995, Loss: 0.0192\n",
      "Batch 880/1995, Loss: 0.0318\n",
      "Batch 890/1995, Loss: 0.0216\n",
      "Batch 900/1995, Loss: 0.0442\n",
      "Batch 910/1995, Loss: 0.0314\n",
      "Batch 920/1995, Loss: 0.0287\n",
      "Batch 930/1995, Loss: 0.0466\n",
      "Batch 940/1995, Loss: 0.0156\n",
      "Batch 950/1995, Loss: 0.0292\n",
      "Batch 960/1995, Loss: 0.0270\n",
      "Batch 970/1995, Loss: 0.0050\n",
      "Batch 980/1995, Loss: 0.0202\n",
      "Batch 990/1995, Loss: 0.0258\n",
      "Batch 1000/1995, Loss: 0.0238\n",
      "Batch 1010/1995, Loss: 0.0373\n",
      "Batch 1020/1995, Loss: 0.0214\n",
      "Batch 1030/1995, Loss: 0.0218\n",
      "Batch 1040/1995, Loss: 0.0247\n",
      "Batch 1050/1995, Loss: 0.0394\n",
      "Batch 1060/1995, Loss: 0.0238\n",
      "Batch 1070/1995, Loss: 0.0120\n",
      "Batch 1080/1995, Loss: 0.0442\n",
      "Batch 1090/1995, Loss: 0.0549\n",
      "Batch 1100/1995, Loss: 0.0230\n",
      "Batch 1110/1995, Loss: 0.0118\n",
      "Batch 1120/1995, Loss: 0.0346\n",
      "Batch 1130/1995, Loss: 0.0237\n",
      "Batch 1140/1995, Loss: 0.0337\n",
      "Batch 1150/1995, Loss: 0.0029\n",
      "Batch 1160/1995, Loss: 0.0420\n",
      "Batch 1170/1995, Loss: 0.0111\n",
      "Batch 1180/1995, Loss: 0.0277\n",
      "Batch 1190/1995, Loss: 0.0414\n",
      "Batch 1200/1995, Loss: 0.0234\n",
      "Batch 1210/1995, Loss: 0.0090\n",
      "Batch 1220/1995, Loss: 0.0190\n",
      "Batch 1230/1995, Loss: 0.0277\n",
      "Batch 1240/1995, Loss: 0.0209\n",
      "Batch 1250/1995, Loss: 0.0318\n",
      "Batch 1260/1995, Loss: 0.0328\n",
      "Batch 1270/1995, Loss: 0.0097\n",
      "Batch 1280/1995, Loss: 0.0290\n",
      "Batch 1290/1995, Loss: 0.0315\n",
      "Batch 1300/1995, Loss: 0.0237\n",
      "Batch 1310/1995, Loss: 0.0236\n",
      "Batch 1320/1995, Loss: 0.0158\n",
      "Batch 1330/1995, Loss: 0.0657\n",
      "Batch 1340/1995, Loss: 0.0340\n",
      "Batch 1350/1995, Loss: 0.0273\n",
      "Batch 1360/1995, Loss: 0.0039\n",
      "Batch 1370/1995, Loss: 0.0305\n",
      "Batch 1380/1995, Loss: 0.0183\n",
      "Batch 1390/1995, Loss: 0.0309\n",
      "Batch 1400/1995, Loss: 0.0293\n",
      "Batch 1410/1995, Loss: 0.0169\n",
      "Batch 1420/1995, Loss: 0.0303\n",
      "Batch 1430/1995, Loss: 0.0160\n",
      "Batch 1440/1995, Loss: 0.0193\n",
      "Batch 1450/1995, Loss: 0.0547\n",
      "Batch 1460/1995, Loss: 0.0291\n",
      "Batch 1470/1995, Loss: 0.0512\n",
      "Batch 1480/1995, Loss: 0.0390\n",
      "Batch 1490/1995, Loss: 0.0079\n",
      "Batch 1500/1995, Loss: 0.0311\n",
      "Batch 1510/1995, Loss: 0.0555\n",
      "Batch 1520/1995, Loss: 0.0145\n",
      "Batch 1530/1995, Loss: 0.0433\n",
      "Batch 1540/1995, Loss: 0.0530\n",
      "Batch 1550/1995, Loss: 0.0173\n",
      "Batch 1560/1995, Loss: 0.0212\n",
      "Batch 1570/1995, Loss: 0.0135\n",
      "Batch 1580/1995, Loss: 0.0370\n",
      "Batch 1590/1995, Loss: 0.0152\n",
      "Batch 1600/1995, Loss: 0.0340\n",
      "Batch 1610/1995, Loss: 0.0200\n",
      "Batch 1620/1995, Loss: 0.0232\n",
      "Batch 1630/1995, Loss: 0.0214\n",
      "Batch 1640/1995, Loss: 0.0369\n",
      "Batch 1650/1995, Loss: 0.0382\n",
      "Batch 1660/1995, Loss: 0.0611\n",
      "Batch 1670/1995, Loss: 0.0219\n",
      "Batch 1680/1995, Loss: 0.0327\n",
      "Batch 1690/1995, Loss: 0.0069\n",
      "Batch 1700/1995, Loss: 0.0516\n",
      "Batch 1710/1995, Loss: 0.0180\n",
      "Batch 1720/1995, Loss: 0.0128\n",
      "Batch 1730/1995, Loss: 0.0268\n",
      "Batch 1740/1995, Loss: 0.0128\n",
      "Batch 1750/1995, Loss: 0.0102\n",
      "Batch 1760/1995, Loss: 0.0168\n",
      "Batch 1770/1995, Loss: 0.0219\n",
      "Batch 1780/1995, Loss: 0.0285\n",
      "Batch 1790/1995, Loss: 0.0309\n",
      "Batch 1800/1995, Loss: 0.0170\n",
      "Batch 1810/1995, Loss: 0.0192\n",
      "Batch 1820/1995, Loss: 0.0047\n",
      "Batch 1830/1995, Loss: 0.0210\n",
      "Batch 1840/1995, Loss: 0.0297\n",
      "Batch 1850/1995, Loss: 0.0338\n",
      "Batch 1860/1995, Loss: 0.0342\n",
      "Batch 1870/1995, Loss: 0.0501\n",
      "Batch 1880/1995, Loss: 0.0377\n",
      "Batch 1890/1995, Loss: 0.0138\n",
      "Batch 1900/1995, Loss: 0.0380\n",
      "Batch 1910/1995, Loss: 0.0076\n",
      "Batch 1920/1995, Loss: 0.0679\n",
      "Batch 1930/1995, Loss: 0.0150\n",
      "Batch 1940/1995, Loss: 0.0196\n",
      "Batch 1950/1995, Loss: 0.0390\n",
      "Batch 1960/1995, Loss: 0.0138\n",
      "Batch 1970/1995, Loss: 0.0268\n",
      "Batch 1980/1995, Loss: 0.0391\n",
      "Batch 1990/1995, Loss: 0.0395\n",
      "\n",
      "Epoch 7 - Independent Model Training Complete. Loss: 0.0272\n",
      "\n",
      "Training Joint Probability Model - Epoch 7\n",
      "Batch 10/1995, Loss: 3.1854\n",
      "Batch 20/1995, Loss: 3.1854\n",
      "Batch 30/1995, Loss: 3.1854\n",
      "Batch 40/1995, Loss: 3.2010\n",
      "Batch 50/1995, Loss: 3.1854\n",
      "Batch 60/1995, Loss: 3.1854\n",
      "Batch 70/1995, Loss: 3.1854\n",
      "Batch 80/1995, Loss: 3.1854\n",
      "Batch 90/1995, Loss: 3.1854\n",
      "Batch 100/1995, Loss: 3.1854\n",
      "Batch 110/1995, Loss: 3.1854\n",
      "Batch 120/1995, Loss: 3.2166\n",
      "Batch 130/1995, Loss: 3.2010\n",
      "Batch 140/1995, Loss: 3.2010\n",
      "Batch 150/1995, Loss: 3.1854\n",
      "Batch 160/1995, Loss: 3.2010\n",
      "Batch 170/1995, Loss: 3.2010\n",
      "Batch 180/1995, Loss: 3.1854\n",
      "Batch 190/1995, Loss: 3.1854\n",
      "Batch 200/1995, Loss: 3.1854\n",
      "Batch 210/1995, Loss: 3.1854\n",
      "Batch 220/1995, Loss: 3.1854\n",
      "Batch 230/1995, Loss: 3.1854\n",
      "Batch 240/1995, Loss: 3.1854\n",
      "Batch 250/1995, Loss: 3.1854\n",
      "Batch 260/1995, Loss: 3.1854\n",
      "Batch 270/1995, Loss: 3.1854\n",
      "Batch 280/1995, Loss: 3.1854\n",
      "Batch 290/1995, Loss: 3.2010\n",
      "Batch 300/1995, Loss: 3.2010\n",
      "Batch 310/1995, Loss: 3.1854\n",
      "Batch 320/1995, Loss: 3.1854\n",
      "Batch 330/1995, Loss: 3.1854\n",
      "Batch 340/1995, Loss: 3.1854\n",
      "Batch 350/1995, Loss: 3.2010\n",
      "Batch 360/1995, Loss: 3.1854\n",
      "Batch 370/1995, Loss: 3.1854\n",
      "Batch 380/1995, Loss: 3.2010\n",
      "Batch 390/1995, Loss: 3.1854\n",
      "Batch 400/1995, Loss: 3.1854\n",
      "Batch 410/1995, Loss: 3.2166\n",
      "Batch 420/1995, Loss: 3.1854\n",
      "Batch 430/1995, Loss: 3.1854\n",
      "Batch 440/1995, Loss: 3.1854\n",
      "Batch 450/1995, Loss: 3.2010\n",
      "Batch 460/1995, Loss: 3.1854\n",
      "Batch 470/1995, Loss: 3.2010\n",
      "Batch 480/1995, Loss: 3.1854\n",
      "Batch 490/1995, Loss: 3.2010\n",
      "Batch 500/1995, Loss: 3.1854\n",
      "Batch 510/1995, Loss: 3.1854\n",
      "Batch 520/1995, Loss: 3.1854\n",
      "Batch 530/1995, Loss: 3.2010\n",
      "Batch 540/1995, Loss: 3.1854\n",
      "Batch 550/1995, Loss: 3.2010\n",
      "Batch 560/1995, Loss: 3.1854\n",
      "Batch 570/1995, Loss: 3.1854\n",
      "Batch 580/1995, Loss: 3.1854\n",
      "Batch 590/1995, Loss: 3.1854\n",
      "Batch 600/1995, Loss: 3.1854\n",
      "Batch 610/1995, Loss: 3.1854\n",
      "Batch 620/1995, Loss: 3.2166\n",
      "Batch 630/1995, Loss: 3.1854\n",
      "Batch 640/1995, Loss: 3.1854\n",
      "Batch 650/1995, Loss: 3.1854\n",
      "Batch 660/1995, Loss: 3.2010\n",
      "Batch 670/1995, Loss: 3.1854\n",
      "Batch 680/1995, Loss: 3.2010\n",
      "Batch 690/1995, Loss: 3.1854\n",
      "Batch 700/1995, Loss: 3.1854\n",
      "Batch 710/1995, Loss: 3.2010\n",
      "Batch 720/1995, Loss: 3.2010\n",
      "Batch 730/1995, Loss: 3.1854\n",
      "Batch 740/1995, Loss: 3.1854\n",
      "Batch 750/1995, Loss: 3.1854\n",
      "Batch 760/1995, Loss: 3.1854\n",
      "Batch 770/1995, Loss: 3.1854\n",
      "Batch 780/1995, Loss: 3.2010\n",
      "Batch 790/1995, Loss: 3.1854\n",
      "Batch 800/1995, Loss: 3.2010\n",
      "Batch 810/1995, Loss: 3.1854\n",
      "Batch 820/1995, Loss: 3.2010\n",
      "Batch 830/1995, Loss: 3.2010\n",
      "Batch 840/1995, Loss: 3.1854\n",
      "Batch 850/1995, Loss: 3.2166\n",
      "Batch 860/1995, Loss: 3.1854\n",
      "Batch 870/1995, Loss: 3.1854\n",
      "Batch 880/1995, Loss: 3.1854\n",
      "Batch 890/1995, Loss: 3.2166\n",
      "Batch 900/1995, Loss: 3.1854\n",
      "Batch 910/1995, Loss: 3.1854\n",
      "Batch 920/1995, Loss: 3.2010\n",
      "Batch 930/1995, Loss: 3.1854\n",
      "Batch 940/1995, Loss: 3.2010\n",
      "Batch 950/1995, Loss: 3.1854\n",
      "Batch 960/1995, Loss: 3.1854\n",
      "Batch 970/1995, Loss: 3.1854\n",
      "Batch 980/1995, Loss: 3.1854\n",
      "Batch 990/1995, Loss: 3.1854\n",
      "Batch 1000/1995, Loss: 3.2010\n",
      "Batch 1010/1995, Loss: 3.1854\n",
      "Batch 1020/1995, Loss: 3.1854\n",
      "Batch 1030/1995, Loss: 3.1854\n",
      "Batch 1040/1995, Loss: 3.1854\n",
      "Batch 1050/1995, Loss: 3.2010\n",
      "Batch 1060/1995, Loss: 3.1854\n",
      "Batch 1070/1995, Loss: 3.1854\n",
      "Batch 1080/1995, Loss: 3.1854\n",
      "Batch 1090/1995, Loss: 3.1854\n",
      "Batch 1100/1995, Loss: 3.2010\n",
      "Batch 1110/1995, Loss: 3.1854\n",
      "Batch 1120/1995, Loss: 3.1854\n",
      "Batch 1130/1995, Loss: 3.1854\n",
      "Batch 1140/1995, Loss: 3.1854\n",
      "Batch 1150/1995, Loss: 3.2166\n",
      "Batch 1160/1995, Loss: 3.1854\n",
      "Batch 1170/1995, Loss: 3.1854\n",
      "Batch 1180/1995, Loss: 3.1854\n",
      "Batch 1190/1995, Loss: 3.1854\n",
      "Batch 1200/1995, Loss: 3.2010\n",
      "Batch 1210/1995, Loss: 3.2010\n",
      "Batch 1220/1995, Loss: 3.2010\n",
      "Batch 1230/1995, Loss: 3.2010\n",
      "Batch 1240/1995, Loss: 3.1854\n",
      "Batch 1250/1995, Loss: 3.1854\n",
      "Batch 1260/1995, Loss: 3.1854\n",
      "Batch 1270/1995, Loss: 3.1854\n",
      "Batch 1280/1995, Loss: 3.2010\n",
      "Batch 1290/1995, Loss: 3.2323\n",
      "Batch 1300/1995, Loss: 3.1854\n",
      "Batch 1310/1995, Loss: 3.2010\n",
      "Batch 1320/1995, Loss: 3.1854\n",
      "Batch 1330/1995, Loss: 3.1854\n",
      "Batch 1340/1995, Loss: 3.2010\n",
      "Batch 1350/1995, Loss: 3.1854\n",
      "Batch 1360/1995, Loss: 3.1854\n",
      "Batch 1370/1995, Loss: 3.1854\n",
      "Batch 1380/1995, Loss: 3.1854\n",
      "Batch 1390/1995, Loss: 3.1854\n",
      "Batch 1400/1995, Loss: 3.2010\n",
      "Batch 1410/1995, Loss: 3.2010\n",
      "Batch 1420/1995, Loss: 3.1854\n",
      "Batch 1430/1995, Loss: 3.1854\n",
      "Batch 1440/1995, Loss: 3.2010\n",
      "Batch 1450/1995, Loss: 3.2010\n",
      "Batch 1460/1995, Loss: 3.1854\n",
      "Batch 1470/1995, Loss: 3.1854\n",
      "Batch 1480/1995, Loss: 3.2166\n",
      "Batch 1490/1995, Loss: 3.1854\n",
      "Batch 1500/1995, Loss: 3.1854\n",
      "Batch 1510/1995, Loss: 3.1854\n",
      "Batch 1520/1995, Loss: 3.1854\n",
      "Batch 1530/1995, Loss: 3.1854\n",
      "Batch 1540/1995, Loss: 3.1854\n",
      "Batch 1550/1995, Loss: 3.1854\n",
      "Batch 1560/1995, Loss: 3.1854\n",
      "Batch 1570/1995, Loss: 3.1854\n",
      "Batch 1580/1995, Loss: 3.1854\n",
      "Batch 1590/1995, Loss: 3.1854\n",
      "Batch 1600/1995, Loss: 3.1854\n",
      "Batch 1610/1995, Loss: 3.1854\n",
      "Batch 1620/1995, Loss: 3.1854\n",
      "Batch 1630/1995, Loss: 3.1854\n",
      "Batch 1640/1995, Loss: 3.1854\n",
      "Batch 1650/1995, Loss: 3.1854\n",
      "Batch 1660/1995, Loss: 3.1854\n",
      "Batch 1670/1995, Loss: 3.1854\n",
      "Batch 1680/1995, Loss: 3.2010\n",
      "Batch 1690/1995, Loss: 3.1854\n",
      "Batch 1700/1995, Loss: 3.1854\n",
      "Batch 1710/1995, Loss: 3.1854\n",
      "Batch 1720/1995, Loss: 3.2323\n",
      "Batch 1730/1995, Loss: 3.2010\n",
      "Batch 1740/1995, Loss: 3.2010\n",
      "Batch 1750/1995, Loss: 3.1854\n",
      "Batch 1760/1995, Loss: 3.1854\n",
      "Batch 1770/1995, Loss: 3.1854\n",
      "Batch 1780/1995, Loss: 3.1854\n",
      "Batch 1790/1995, Loss: 3.2010\n",
      "Batch 1800/1995, Loss: 3.2010\n",
      "Batch 1810/1995, Loss: 3.1854\n",
      "Batch 1820/1995, Loss: 3.1854\n",
      "Batch 1830/1995, Loss: 3.1854\n",
      "Batch 1840/1995, Loss: 3.1854\n",
      "Batch 1850/1995, Loss: 3.2010\n",
      "Batch 1860/1995, Loss: 3.1854\n",
      "Batch 1870/1995, Loss: 3.2010\n",
      "Batch 1880/1995, Loss: 3.1854\n",
      "Batch 1890/1995, Loss: 3.1854\n",
      "Batch 1900/1995, Loss: 3.1854\n",
      "Batch 1910/1995, Loss: 3.2010\n",
      "Batch 1920/1995, Loss: 3.2010\n",
      "Batch 1930/1995, Loss: 3.1854\n",
      "Batch 1940/1995, Loss: 3.2166\n",
      "Batch 1950/1995, Loss: 3.1854\n",
      "Batch 1960/1995, Loss: 3.1854\n",
      "Batch 1970/1995, Loss: 3.1854\n",
      "Batch 1980/1995, Loss: 3.1854\n",
      "Batch 1990/1995, Loss: 3.2010\n",
      "\n",
      "Epoch 7 - Joint Model Training Complete. Loss: 3.1912\n",
      "==================================================\n",
      "==================================================\n",
      "Starting Epoch 8 of Training\n",
      "\n",
      "\n",
      "Training Independent Probabilities Model - Epoch 8\n",
      "Batch 10/1995, Loss: 0.0163\n",
      "Batch 20/1995, Loss: 0.0144\n",
      "Batch 30/1995, Loss: 0.0103\n",
      "Batch 40/1995, Loss: 0.0104\n",
      "Batch 50/1995, Loss: 0.0197\n",
      "Batch 60/1995, Loss: 0.0194\n",
      "Batch 70/1995, Loss: 0.0569\n",
      "Batch 80/1995, Loss: 0.0254\n",
      "Batch 90/1995, Loss: 0.0363\n",
      "Batch 100/1995, Loss: 0.0143\n",
      "Batch 110/1995, Loss: 0.0107\n",
      "Batch 120/1995, Loss: 0.0426\n",
      "Batch 130/1995, Loss: 0.0265\n",
      "Batch 140/1995, Loss: 0.0190\n",
      "Batch 150/1995, Loss: 0.0357\n",
      "Batch 160/1995, Loss: 0.0158\n",
      "Batch 170/1995, Loss: 0.0459\n",
      "Batch 180/1995, Loss: 0.0193\n",
      "Batch 190/1995, Loss: 0.0191\n",
      "Batch 200/1995, Loss: 0.0159\n",
      "Batch 210/1995, Loss: 0.0465\n",
      "Batch 220/1995, Loss: 0.0269\n",
      "Batch 230/1995, Loss: 0.0349\n",
      "Batch 240/1995, Loss: 0.0313\n",
      "Batch 250/1995, Loss: 0.0200\n",
      "Batch 260/1995, Loss: 0.0158\n",
      "Batch 270/1995, Loss: 0.0278\n",
      "Batch 280/1995, Loss: 0.0291\n",
      "Batch 290/1995, Loss: 0.0287\n",
      "Batch 300/1995, Loss: 0.0147\n",
      "Batch 310/1995, Loss: 0.0102\n",
      "Batch 320/1995, Loss: 0.0322\n",
      "Batch 330/1995, Loss: 0.0390\n",
      "Batch 340/1995, Loss: 0.0332\n",
      "Batch 350/1995, Loss: 0.0165\n",
      "Batch 360/1995, Loss: 0.0201\n",
      "Batch 370/1995, Loss: 0.0477\n",
      "Batch 380/1995, Loss: 0.0148\n",
      "Batch 390/1995, Loss: 0.0180\n",
      "Batch 400/1995, Loss: 0.0133\n",
      "Batch 410/1995, Loss: 0.0293\n",
      "Batch 420/1995, Loss: 0.0435\n",
      "Batch 430/1995, Loss: 0.0185\n",
      "Batch 440/1995, Loss: 0.0247\n",
      "Batch 450/1995, Loss: 0.0161\n",
      "Batch 460/1995, Loss: 0.0139\n",
      "Batch 470/1995, Loss: 0.0155\n",
      "Batch 480/1995, Loss: 0.0123\n",
      "Batch 490/1995, Loss: 0.0529\n",
      "Batch 500/1995, Loss: 0.0286\n",
      "Batch 510/1995, Loss: 0.0354\n",
      "Batch 520/1995, Loss: 0.0224\n",
      "Batch 530/1995, Loss: 0.0127\n",
      "Batch 540/1995, Loss: 0.0111\n",
      "Batch 550/1995, Loss: 0.0244\n",
      "Batch 560/1995, Loss: 0.0403\n",
      "Batch 570/1995, Loss: 0.0202\n",
      "Batch 580/1995, Loss: 0.0358\n",
      "Batch 590/1995, Loss: 0.0522\n",
      "Batch 600/1995, Loss: 0.0272\n",
      "Batch 610/1995, Loss: 0.0192\n",
      "Batch 620/1995, Loss: 0.0290\n",
      "Batch 630/1995, Loss: 0.0419\n",
      "Batch 640/1995, Loss: 0.0142\n",
      "Batch 650/1995, Loss: 0.0175\n",
      "Batch 660/1995, Loss: 0.0097\n",
      "Batch 670/1995, Loss: 0.0077\n",
      "Batch 680/1995, Loss: 0.0253\n",
      "Batch 690/1995, Loss: 0.0155\n",
      "Batch 700/1995, Loss: 0.0175\n",
      "Batch 710/1995, Loss: 0.0259\n",
      "Batch 720/1995, Loss: 0.0245\n",
      "Batch 730/1995, Loss: 0.0480\n",
      "Batch 740/1995, Loss: 0.0494\n",
      "Batch 750/1995, Loss: 0.0331\n",
      "Batch 760/1995, Loss: 0.0081\n",
      "Batch 770/1995, Loss: 0.0304\n",
      "Batch 780/1995, Loss: 0.0198\n",
      "Batch 790/1995, Loss: 0.0395\n",
      "Batch 800/1995, Loss: 0.0177\n",
      "Batch 810/1995, Loss: 0.0328\n",
      "Batch 820/1995, Loss: 0.0347\n",
      "Batch 830/1995, Loss: 0.0346\n",
      "Batch 840/1995, Loss: 0.0396\n",
      "Batch 850/1995, Loss: 0.0163\n",
      "Batch 860/1995, Loss: 0.0142\n",
      "Batch 870/1995, Loss: 0.0423\n",
      "Batch 880/1995, Loss: 0.0147\n",
      "Batch 890/1995, Loss: 0.0147\n",
      "Batch 900/1995, Loss: 0.0241\n",
      "Batch 910/1995, Loss: 0.0238\n",
      "Batch 920/1995, Loss: 0.0116\n",
      "Batch 930/1995, Loss: 0.0372\n",
      "Batch 940/1995, Loss: 0.0140\n",
      "Batch 950/1995, Loss: 0.0138\n",
      "Batch 960/1995, Loss: 0.0091\n",
      "Batch 970/1995, Loss: 0.0108\n",
      "Batch 980/1995, Loss: 0.0118\n",
      "Batch 990/1995, Loss: 0.0279\n",
      "Batch 1000/1995, Loss: 0.0182\n",
      "Batch 1010/1995, Loss: 0.0035\n",
      "Batch 1020/1995, Loss: 0.0084\n",
      "Batch 1030/1995, Loss: 0.0113\n",
      "Batch 1040/1995, Loss: 0.0600\n",
      "Batch 1050/1995, Loss: 0.0162\n",
      "Batch 1060/1995, Loss: 0.0317\n",
      "Batch 1070/1995, Loss: 0.0287\n",
      "Batch 1080/1995, Loss: 0.0296\n",
      "Batch 1090/1995, Loss: 0.0055\n",
      "Batch 1100/1995, Loss: 0.0233\n",
      "Batch 1110/1995, Loss: 0.0076\n",
      "Batch 1120/1995, Loss: 0.0150\n",
      "Batch 1130/1995, Loss: 0.0227\n",
      "Batch 1140/1995, Loss: 0.0451\n",
      "Batch 1150/1995, Loss: 0.0275\n",
      "Batch 1160/1995, Loss: 0.0148\n",
      "Batch 1170/1995, Loss: 0.0085\n",
      "Batch 1180/1995, Loss: 0.0058\n",
      "Batch 1190/1995, Loss: 0.0170\n",
      "Batch 1200/1995, Loss: 0.0246\n",
      "Batch 1210/1995, Loss: 0.0398\n",
      "Batch 1220/1995, Loss: 0.0273\n",
      "Batch 1230/1995, Loss: 0.0225\n",
      "Batch 1240/1995, Loss: 0.0425\n",
      "Batch 1250/1995, Loss: 0.0239\n",
      "Batch 1260/1995, Loss: 0.0430\n",
      "Batch 1270/1995, Loss: 0.0197\n",
      "Batch 1280/1995, Loss: 0.0292\n",
      "Batch 1290/1995, Loss: 0.0240\n",
      "Batch 1300/1995, Loss: 0.0363\n",
      "Batch 1310/1995, Loss: 0.0103\n",
      "Batch 1320/1995, Loss: 0.0327\n",
      "Batch 1330/1995, Loss: 0.0057\n",
      "Batch 1340/1995, Loss: 0.0226\n",
      "Batch 1350/1995, Loss: 0.0050\n",
      "Batch 1360/1995, Loss: 0.0188\n",
      "Batch 1370/1995, Loss: 0.0372\n",
      "Batch 1380/1995, Loss: 0.0384\n",
      "Batch 1390/1995, Loss: 0.0273\n",
      "Batch 1400/1995, Loss: 0.0328\n",
      "Batch 1410/1995, Loss: 0.0112\n",
      "Batch 1420/1995, Loss: 0.0305\n",
      "Batch 1430/1995, Loss: 0.0136\n",
      "Batch 1440/1995, Loss: 0.0204\n",
      "Batch 1450/1995, Loss: 0.0347\n",
      "Batch 1460/1995, Loss: 0.0375\n",
      "Batch 1470/1995, Loss: 0.0366\n",
      "Batch 1480/1995, Loss: 0.0210\n",
      "Batch 1490/1995, Loss: 0.0383\n",
      "Batch 1500/1995, Loss: 0.0247\n",
      "Batch 1510/1995, Loss: 0.0476\n",
      "Batch 1520/1995, Loss: 0.0298\n",
      "Batch 1530/1995, Loss: 0.0224\n",
      "Batch 1540/1995, Loss: 0.0196\n",
      "Batch 1550/1995, Loss: 0.0385\n",
      "Batch 1560/1995, Loss: 0.0257\n",
      "Batch 1570/1995, Loss: 0.0017\n",
      "Batch 1580/1995, Loss: 0.0609\n",
      "Batch 1590/1995, Loss: 0.0235\n",
      "Batch 1600/1995, Loss: 0.0127\n",
      "Batch 1610/1995, Loss: 0.0401\n",
      "Batch 1620/1995, Loss: 0.0356\n",
      "Batch 1630/1995, Loss: 0.0109\n",
      "Batch 1640/1995, Loss: 0.0280\n",
      "Batch 1650/1995, Loss: 0.0479\n",
      "Batch 1660/1995, Loss: 0.0132\n",
      "Batch 1670/1995, Loss: 0.0288\n",
      "Batch 1680/1995, Loss: 0.0080\n",
      "Batch 1690/1995, Loss: 0.0217\n",
      "Batch 1700/1995, Loss: 0.0222\n",
      "Batch 1710/1995, Loss: 0.0320\n",
      "Batch 1720/1995, Loss: 0.0142\n",
      "Batch 1730/1995, Loss: 0.0240\n",
      "Batch 1740/1995, Loss: 0.0309\n",
      "Batch 1750/1995, Loss: 0.0238\n",
      "Batch 1760/1995, Loss: 0.0347\n",
      "Batch 1770/1995, Loss: 0.0197\n",
      "Batch 1780/1995, Loss: 0.0099\n",
      "Batch 1790/1995, Loss: 0.0172\n",
      "Batch 1800/1995, Loss: 0.0488\n",
      "Batch 1810/1995, Loss: 0.0409\n",
      "Batch 1820/1995, Loss: 0.0063\n",
      "Batch 1830/1995, Loss: 0.0193\n",
      "Batch 1840/1995, Loss: 0.0410\n",
      "Batch 1850/1995, Loss: 0.0193\n",
      "Batch 1860/1995, Loss: 0.0239\n",
      "Batch 1870/1995, Loss: 0.0292\n",
      "Batch 1880/1995, Loss: 0.0333\n",
      "Batch 1890/1995, Loss: 0.0195\n",
      "Batch 1900/1995, Loss: 0.0427\n",
      "Batch 1910/1995, Loss: 0.0124\n",
      "Batch 1920/1995, Loss: 0.0191\n",
      "Batch 1930/1995, Loss: 0.0338\n",
      "Batch 1940/1995, Loss: 0.0050\n",
      "Batch 1950/1995, Loss: 0.0116\n",
      "Batch 1960/1995, Loss: 0.0147\n",
      "Batch 1970/1995, Loss: 0.0472\n",
      "Batch 1980/1995, Loss: 0.0355\n",
      "Batch 1990/1995, Loss: 0.0223\n",
      "\n",
      "Epoch 8 - Independent Model Training Complete. Loss: 0.0247\n",
      "\n",
      "Training Joint Probability Model - Epoch 8\n",
      "Batch 10/1995, Loss: 3.1854\n",
      "Batch 20/1995, Loss: 3.1854\n",
      "Batch 30/1995, Loss: 3.2010\n",
      "Batch 40/1995, Loss: 3.2166\n",
      "Batch 50/1995, Loss: 3.2010\n",
      "Batch 60/1995, Loss: 3.2323\n",
      "Batch 70/1995, Loss: 3.2010\n",
      "Batch 80/1995, Loss: 3.2010\n",
      "Batch 90/1995, Loss: 3.1854\n",
      "Batch 100/1995, Loss: 3.2010\n",
      "Batch 110/1995, Loss: 3.1854\n",
      "Batch 120/1995, Loss: 3.2010\n",
      "Batch 130/1995, Loss: 3.2010\n",
      "Batch 140/1995, Loss: 3.2010\n",
      "Batch 150/1995, Loss: 3.2010\n",
      "Batch 160/1995, Loss: 3.2010\n",
      "Batch 170/1995, Loss: 3.2010\n",
      "Batch 180/1995, Loss: 3.2010\n",
      "Batch 190/1995, Loss: 3.2166\n",
      "Batch 200/1995, Loss: 3.2166\n",
      "Batch 210/1995, Loss: 3.1854\n",
      "Batch 220/1995, Loss: 3.1854\n",
      "Batch 230/1995, Loss: 3.1854\n",
      "Batch 240/1995, Loss: 3.2010\n",
      "Batch 250/1995, Loss: 3.1854\n",
      "Batch 260/1995, Loss: 3.1854\n",
      "Batch 270/1995, Loss: 3.1854\n",
      "Batch 280/1995, Loss: 3.1854\n",
      "Batch 290/1995, Loss: 3.1854\n",
      "Batch 300/1995, Loss: 3.2010\n",
      "Batch 310/1995, Loss: 3.1854\n",
      "Batch 320/1995, Loss: 3.1854\n",
      "Batch 330/1995, Loss: 3.1854\n",
      "Batch 340/1995, Loss: 3.2010\n",
      "Batch 350/1995, Loss: 3.1854\n",
      "Batch 360/1995, Loss: 3.1854\n",
      "Batch 370/1995, Loss: 3.1854\n",
      "Batch 380/1995, Loss: 3.1854\n",
      "Batch 390/1995, Loss: 3.1854\n",
      "Batch 400/1995, Loss: 3.1854\n",
      "Batch 410/1995, Loss: 3.1854\n",
      "Batch 420/1995, Loss: 3.1854\n",
      "Batch 430/1995, Loss: 3.1854\n",
      "Batch 440/1995, Loss: 3.1854\n",
      "Batch 450/1995, Loss: 3.1854\n",
      "Batch 460/1995, Loss: 3.1854\n",
      "Batch 470/1995, Loss: 3.2010\n",
      "Batch 480/1995, Loss: 3.2010\n",
      "Batch 490/1995, Loss: 3.2010\n",
      "Batch 500/1995, Loss: 3.1854\n",
      "Batch 510/1995, Loss: 3.2166\n",
      "Batch 520/1995, Loss: 3.1854\n",
      "Batch 530/1995, Loss: 3.1854\n",
      "Batch 540/1995, Loss: 3.1854\n",
      "Batch 550/1995, Loss: 3.1854\n",
      "Batch 560/1995, Loss: 3.1854\n",
      "Batch 570/1995, Loss: 3.2010\n",
      "Batch 580/1995, Loss: 3.1854\n",
      "Batch 590/1995, Loss: 3.1854\n",
      "Batch 600/1995, Loss: 3.2010\n",
      "Batch 610/1995, Loss: 3.1854\n",
      "Batch 620/1995, Loss: 3.1854\n",
      "Batch 630/1995, Loss: 3.1854\n",
      "Batch 640/1995, Loss: 3.2010\n",
      "Batch 650/1995, Loss: 3.1854\n",
      "Batch 660/1995, Loss: 3.1854\n",
      "Batch 670/1995, Loss: 3.1854\n",
      "Batch 680/1995, Loss: 3.1854\n",
      "Batch 690/1995, Loss: 3.1854\n",
      "Batch 700/1995, Loss: 3.1854\n",
      "Batch 710/1995, Loss: 3.1854\n",
      "Batch 720/1995, Loss: 3.1854\n",
      "Batch 730/1995, Loss: 3.2166\n",
      "Batch 740/1995, Loss: 3.1854\n",
      "Batch 750/1995, Loss: 3.2010\n",
      "Batch 760/1995, Loss: 3.2010\n",
      "Batch 770/1995, Loss: 3.1854\n",
      "Batch 780/1995, Loss: 3.2166\n",
      "Batch 790/1995, Loss: 3.2010\n",
      "Batch 800/1995, Loss: 3.1854\n",
      "Batch 810/1995, Loss: 3.1854\n",
      "Batch 820/1995, Loss: 3.1854\n",
      "Batch 830/1995, Loss: 3.1854\n",
      "Batch 840/1995, Loss: 3.1854\n",
      "Batch 850/1995, Loss: 3.1854\n",
      "Batch 860/1995, Loss: 3.1854\n",
      "Batch 870/1995, Loss: 3.1854\n",
      "Batch 880/1995, Loss: 3.1854\n",
      "Batch 890/1995, Loss: 3.1854\n",
      "Batch 900/1995, Loss: 3.1854\n",
      "Batch 910/1995, Loss: 3.1854\n",
      "Batch 920/1995, Loss: 3.1854\n",
      "Batch 930/1995, Loss: 3.1854\n",
      "Batch 940/1995, Loss: 3.1854\n",
      "Batch 950/1995, Loss: 3.1854\n",
      "Batch 960/1995, Loss: 3.1854\n",
      "Batch 970/1995, Loss: 3.1854\n",
      "Batch 980/1995, Loss: 3.2010\n",
      "Batch 990/1995, Loss: 3.2010\n",
      "Batch 1000/1995, Loss: 3.1854\n",
      "Batch 1010/1995, Loss: 3.1854\n",
      "Batch 1020/1995, Loss: 3.2010\n",
      "Batch 1030/1995, Loss: 3.1854\n",
      "Batch 1040/1995, Loss: 3.1854\n",
      "Batch 1050/1995, Loss: 3.1854\n",
      "Batch 1060/1995, Loss: 3.2166\n",
      "Batch 1070/1995, Loss: 3.2010\n",
      "Batch 1080/1995, Loss: 3.1854\n",
      "Batch 1090/1995, Loss: 3.2010\n",
      "Batch 1100/1995, Loss: 3.1854\n",
      "Batch 1110/1995, Loss: 3.2010\n",
      "Batch 1120/1995, Loss: 3.1854\n",
      "Batch 1130/1995, Loss: 3.2010\n",
      "Batch 1140/1995, Loss: 3.1854\n",
      "Batch 1150/1995, Loss: 3.2010\n",
      "Batch 1160/1995, Loss: 3.2010\n",
      "Batch 1170/1995, Loss: 3.1854\n",
      "Batch 1180/1995, Loss: 3.1854\n",
      "Batch 1190/1995, Loss: 3.1854\n",
      "Batch 1200/1995, Loss: 3.1854\n",
      "Batch 1210/1995, Loss: 3.1854\n",
      "Batch 1220/1995, Loss: 3.1854\n",
      "Batch 1230/1995, Loss: 3.1854\n",
      "Batch 1240/1995, Loss: 3.1854\n",
      "Batch 1250/1995, Loss: 3.1854\n",
      "Batch 1260/1995, Loss: 3.1854\n",
      "Batch 1270/1995, Loss: 3.2010\n",
      "Batch 1280/1995, Loss: 3.2166\n",
      "Batch 1290/1995, Loss: 3.1854\n",
      "Batch 1300/1995, Loss: 3.1854\n",
      "Batch 1310/1995, Loss: 3.1854\n",
      "Batch 1320/1995, Loss: 3.1854\n",
      "Batch 1330/1995, Loss: 3.1854\n",
      "Batch 1340/1995, Loss: 3.1854\n",
      "Batch 1350/1995, Loss: 3.2010\n",
      "Batch 1360/1995, Loss: 3.1854\n",
      "Batch 1370/1995, Loss: 3.2010\n",
      "Batch 1380/1995, Loss: 3.1854\n",
      "Batch 1390/1995, Loss: 3.1854\n",
      "Batch 1400/1995, Loss: 3.1854\n",
      "Batch 1410/1995, Loss: 3.2010\n",
      "Batch 1420/1995, Loss: 3.1854\n",
      "Batch 1430/1995, Loss: 3.1854\n",
      "Batch 1440/1995, Loss: 3.2010\n",
      "Batch 1450/1995, Loss: 3.1854\n",
      "Batch 1460/1995, Loss: 3.1854\n",
      "Batch 1470/1995, Loss: 3.1854\n",
      "Batch 1480/1995, Loss: 3.2010\n",
      "Batch 1490/1995, Loss: 3.2010\n",
      "Batch 1500/1995, Loss: 3.2010\n",
      "Batch 1510/1995, Loss: 3.1854\n",
      "Batch 1520/1995, Loss: 3.1854\n",
      "Batch 1530/1995, Loss: 3.1854\n",
      "Batch 1540/1995, Loss: 3.2010\n",
      "Batch 1550/1995, Loss: 3.2010\n",
      "Batch 1560/1995, Loss: 3.2010\n",
      "Batch 1570/1995, Loss: 3.1854\n",
      "Batch 1580/1995, Loss: 3.1854\n",
      "Batch 1590/1995, Loss: 3.1854\n",
      "Batch 1600/1995, Loss: 3.1854\n",
      "Batch 1610/1995, Loss: 3.2010\n",
      "Batch 1620/1995, Loss: 3.2166\n",
      "Batch 1630/1995, Loss: 3.2166\n",
      "Batch 1640/1995, Loss: 3.2010\n",
      "Batch 1650/1995, Loss: 3.1854\n",
      "Batch 1660/1995, Loss: 3.1854\n",
      "Batch 1670/1995, Loss: 3.2010\n",
      "Batch 1680/1995, Loss: 3.2010\n",
      "Batch 1690/1995, Loss: 3.2010\n",
      "Batch 1700/1995, Loss: 3.1854\n",
      "Batch 1710/1995, Loss: 3.1854\n",
      "Batch 1720/1995, Loss: 3.1854\n",
      "Batch 1730/1995, Loss: 3.1854\n",
      "Batch 1740/1995, Loss: 3.1854\n",
      "Batch 1750/1995, Loss: 3.1854\n",
      "Batch 1760/1995, Loss: 3.1854\n",
      "Batch 1770/1995, Loss: 3.2010\n",
      "Batch 1780/1995, Loss: 3.1854\n",
      "Batch 1790/1995, Loss: 3.1854\n",
      "Batch 1800/1995, Loss: 3.1854\n",
      "Batch 1810/1995, Loss: 3.1854\n",
      "Batch 1820/1995, Loss: 3.1854\n",
      "Batch 1830/1995, Loss: 3.1854\n",
      "Batch 1840/1995, Loss: 3.1854\n",
      "Batch 1850/1995, Loss: 3.2010\n",
      "Batch 1860/1995, Loss: 3.2010\n",
      "Batch 1870/1995, Loss: 3.1854\n",
      "Batch 1880/1995, Loss: 3.1854\n",
      "Batch 1890/1995, Loss: 3.2010\n",
      "Batch 1900/1995, Loss: 3.1854\n",
      "Batch 1910/1995, Loss: 3.1854\n",
      "Batch 1920/1995, Loss: 3.1854\n",
      "Batch 1930/1995, Loss: 3.1854\n",
      "Batch 1940/1995, Loss: 3.2010\n",
      "Batch 1950/1995, Loss: 3.2010\n",
      "Batch 1960/1995, Loss: 3.1854\n",
      "Batch 1970/1995, Loss: 3.1854\n",
      "Batch 1980/1995, Loss: 3.1854\n",
      "Batch 1990/1995, Loss: 3.1854\n",
      "\n",
      "Epoch 8 - Joint Model Training Complete. Loss: 3.1912\n",
      "==================================================\n",
      "==================================================\n",
      "Starting Epoch 9 of Training\n",
      "\n",
      "\n",
      "Training Independent Probabilities Model - Epoch 9\n",
      "Batch 10/1995, Loss: 0.0124\n",
      "Batch 20/1995, Loss: 0.0168\n",
      "Batch 30/1995, Loss: 0.0256\n",
      "Batch 40/1995, Loss: 0.0172\n",
      "Batch 50/1995, Loss: 0.0299\n",
      "Batch 60/1995, Loss: 0.0158\n",
      "Batch 70/1995, Loss: 0.0114\n",
      "Batch 80/1995, Loss: 0.0384\n",
      "Batch 90/1995, Loss: 0.0056\n",
      "Batch 100/1995, Loss: 0.0200\n",
      "Batch 110/1995, Loss: 0.0244\n",
      "Batch 120/1995, Loss: 0.0280\n",
      "Batch 130/1995, Loss: 0.0100\n",
      "Batch 140/1995, Loss: 0.0283\n",
      "Batch 150/1995, Loss: 0.0282\n",
      "Batch 160/1995, Loss: 0.0197\n",
      "Batch 170/1995, Loss: 0.0219\n",
      "Batch 180/1995, Loss: 0.0414\n",
      "Batch 190/1995, Loss: 0.0095\n",
      "Batch 200/1995, Loss: 0.0139\n",
      "Batch 210/1995, Loss: 0.0428\n",
      "Batch 220/1995, Loss: 0.0000\n",
      "Batch 230/1995, Loss: 0.0168\n",
      "Batch 240/1995, Loss: 0.0057\n",
      "Batch 250/1995, Loss: 0.0333\n",
      "Batch 260/1995, Loss: 0.0235\n",
      "Batch 270/1995, Loss: 0.0212\n",
      "Batch 280/1995, Loss: 0.0153\n",
      "Batch 290/1995, Loss: 0.0102\n",
      "Batch 300/1995, Loss: 0.0189\n",
      "Batch 310/1995, Loss: 0.0218\n",
      "Batch 320/1995, Loss: 0.0092\n",
      "Batch 330/1995, Loss: 0.0167\n",
      "Batch 340/1995, Loss: 0.0231\n",
      "Batch 350/1995, Loss: 0.0272\n",
      "Batch 360/1995, Loss: 0.0043\n",
      "Batch 370/1995, Loss: 0.0270\n",
      "Batch 380/1995, Loss: 0.0160\n",
      "Batch 390/1995, Loss: 0.0065\n",
      "Batch 400/1995, Loss: 0.0260\n",
      "Batch 410/1995, Loss: 0.0196\n",
      "Batch 420/1995, Loss: 0.0074\n",
      "Batch 430/1995, Loss: 0.0335\n",
      "Batch 440/1995, Loss: 0.0270\n",
      "Batch 450/1995, Loss: 0.0132\n",
      "Batch 460/1995, Loss: 0.0127\n",
      "Batch 470/1995, Loss: 0.0363\n",
      "Batch 480/1995, Loss: 0.0158\n",
      "Batch 490/1995, Loss: 0.0219\n",
      "Batch 500/1995, Loss: 0.0220\n",
      "Batch 510/1995, Loss: 0.0212\n",
      "Batch 520/1995, Loss: 0.0202\n",
      "Batch 530/1995, Loss: 0.0159\n",
      "Batch 540/1995, Loss: 0.0092\n",
      "Batch 550/1995, Loss: 0.0296\n",
      "Batch 560/1995, Loss: 0.0110\n",
      "Batch 570/1995, Loss: 0.0138\n",
      "Batch 580/1995, Loss: 0.0101\n",
      "Batch 590/1995, Loss: 0.0096\n",
      "Batch 600/1995, Loss: 0.0357\n",
      "Batch 610/1995, Loss: 0.0095\n",
      "Batch 620/1995, Loss: 0.0224\n",
      "Batch 630/1995, Loss: 0.0260\n",
      "Batch 640/1995, Loss: 0.0479\n",
      "Batch 650/1995, Loss: 0.0099\n",
      "Batch 660/1995, Loss: 0.0246\n",
      "Batch 670/1995, Loss: 0.0097\n",
      "Batch 680/1995, Loss: 0.0547\n",
      "Batch 690/1995, Loss: 0.0106\n",
      "Batch 700/1995, Loss: 0.0231\n",
      "Batch 710/1995, Loss: 0.0286\n",
      "Batch 720/1995, Loss: 0.0087\n",
      "Batch 730/1995, Loss: 0.0135\n",
      "Batch 740/1995, Loss: 0.0030\n",
      "Batch 750/1995, Loss: 0.0179\n",
      "Batch 760/1995, Loss: 0.0040\n",
      "Batch 770/1995, Loss: 0.0225\n",
      "Batch 780/1995, Loss: 0.0184\n",
      "Batch 790/1995, Loss: 0.0482\n",
      "Batch 800/1995, Loss: 0.0056\n",
      "Batch 810/1995, Loss: 0.0083\n",
      "Batch 820/1995, Loss: 0.0030\n",
      "Batch 830/1995, Loss: 0.0209\n",
      "Batch 840/1995, Loss: 0.0230\n",
      "Batch 850/1995, Loss: 0.0213\n",
      "Batch 860/1995, Loss: 0.0199\n",
      "Batch 870/1995, Loss: 0.0031\n",
      "Batch 880/1995, Loss: 0.0252\n",
      "Batch 890/1995, Loss: 0.0265\n",
      "Batch 900/1995, Loss: 0.0299\n",
      "Batch 910/1995, Loss: 0.0197\n",
      "Batch 920/1995, Loss: 0.0211\n",
      "Batch 930/1995, Loss: 0.0248\n",
      "Batch 940/1995, Loss: 0.0274\n",
      "Batch 950/1995, Loss: 0.0262\n",
      "Batch 960/1995, Loss: 0.0286\n",
      "Batch 970/1995, Loss: 0.0094\n",
      "Batch 980/1995, Loss: 0.0253\n",
      "Batch 990/1995, Loss: 0.0550\n",
      "Batch 1000/1995, Loss: 0.0151\n",
      "Batch 1010/1995, Loss: 0.0170\n",
      "Batch 1020/1995, Loss: 0.0292\n",
      "Batch 1030/1995, Loss: 0.0825\n",
      "Batch 1040/1995, Loss: 0.0288\n",
      "Batch 1050/1995, Loss: 0.0318\n",
      "Batch 1060/1995, Loss: 0.0138\n",
      "Batch 1070/1995, Loss: 0.0145\n",
      "Batch 1080/1995, Loss: 0.0182\n",
      "Batch 1090/1995, Loss: 0.0625\n",
      "Batch 1100/1995, Loss: 0.0201\n",
      "Batch 1110/1995, Loss: 0.0241\n",
      "Batch 1120/1995, Loss: 0.0182\n",
      "Batch 1130/1995, Loss: 0.0238\n",
      "Batch 1140/1995, Loss: 0.0262\n",
      "Batch 1150/1995, Loss: 0.0136\n",
      "Batch 1160/1995, Loss: 0.0234\n",
      "Batch 1170/1995, Loss: 0.0091\n",
      "Batch 1180/1995, Loss: 0.0350\n",
      "Batch 1190/1995, Loss: 0.0427\n",
      "Batch 1200/1995, Loss: 0.0048\n",
      "Batch 1210/1995, Loss: 0.0269\n",
      "Batch 1220/1995, Loss: 0.0291\n",
      "Batch 1230/1995, Loss: 0.0264\n",
      "Batch 1240/1995, Loss: 0.0077\n",
      "Batch 1250/1995, Loss: 0.0110\n",
      "Batch 1260/1995, Loss: 0.0203\n",
      "Batch 1270/1995, Loss: 0.0109\n",
      "Batch 1280/1995, Loss: 0.0458\n",
      "Batch 1290/1995, Loss: 0.0071\n",
      "Batch 1300/1995, Loss: 0.0463\n",
      "Batch 1310/1995, Loss: 0.0083\n",
      "Batch 1320/1995, Loss: 0.0381\n",
      "Batch 1330/1995, Loss: 0.0197\n",
      "Batch 1340/1995, Loss: 0.0037\n",
      "Batch 1350/1995, Loss: 0.0495\n",
      "Batch 1360/1995, Loss: 0.0275\n",
      "Batch 1370/1995, Loss: 0.0365\n",
      "Batch 1380/1995, Loss: 0.0101\n",
      "Batch 1390/1995, Loss: 0.0048\n",
      "Batch 1400/1995, Loss: 0.0091\n",
      "Batch 1410/1995, Loss: 0.0249\n",
      "Batch 1420/1995, Loss: 0.0333\n",
      "Batch 1430/1995, Loss: 0.0342\n",
      "Batch 1440/1995, Loss: 0.0165\n",
      "Batch 1450/1995, Loss: 0.0204\n",
      "Batch 1460/1995, Loss: 0.0203\n",
      "Batch 1470/1995, Loss: 0.0163\n",
      "Batch 1480/1995, Loss: 0.0063\n",
      "Batch 1490/1995, Loss: 0.0123\n",
      "Batch 1500/1995, Loss: 0.0246\n",
      "Batch 1510/1995, Loss: 0.0287\n",
      "Batch 1520/1995, Loss: 0.0236\n",
      "Batch 1530/1995, Loss: 0.0129\n",
      "Batch 1540/1995, Loss: 0.0162\n",
      "Batch 1550/1995, Loss: 0.0064\n",
      "Batch 1560/1995, Loss: 0.0271\n",
      "Batch 1570/1995, Loss: 0.0465\n",
      "Batch 1580/1995, Loss: 0.0245\n",
      "Batch 1590/1995, Loss: 0.0197\n",
      "Batch 1600/1995, Loss: 0.0133\n",
      "Batch 1610/1995, Loss: 0.0121\n",
      "Batch 1620/1995, Loss: 0.0235\n",
      "Batch 1630/1995, Loss: 0.0416\n",
      "Batch 1640/1995, Loss: 0.0274\n",
      "Batch 1650/1995, Loss: 0.0132\n",
      "Batch 1660/1995, Loss: 0.0231\n",
      "Batch 1670/1995, Loss: 0.0167\n",
      "Batch 1680/1995, Loss: 0.0351\n",
      "Batch 1690/1995, Loss: 0.0300\n",
      "Batch 1700/1995, Loss: 0.0210\n",
      "Batch 1710/1995, Loss: 0.0145\n",
      "Batch 1720/1995, Loss: 0.0218\n",
      "Batch 1730/1995, Loss: 0.0205\n",
      "Batch 1740/1995, Loss: 0.0085\n",
      "Batch 1750/1995, Loss: 0.0359\n",
      "Batch 1760/1995, Loss: 0.0105\n",
      "Batch 1770/1995, Loss: 0.0386\n",
      "Batch 1780/1995, Loss: 0.0237\n",
      "Batch 1790/1995, Loss: 0.0233\n",
      "Batch 1800/1995, Loss: 0.0203\n",
      "Batch 1810/1995, Loss: 0.0263\n",
      "Batch 1820/1995, Loss: 0.0089\n",
      "Batch 1830/1995, Loss: 0.0457\n",
      "Batch 1840/1995, Loss: 0.0149\n",
      "Batch 1850/1995, Loss: 0.0194\n",
      "Batch 1860/1995, Loss: 0.0227\n",
      "Batch 1870/1995, Loss: 0.0095\n",
      "Batch 1880/1995, Loss: 0.0036\n",
      "Batch 1890/1995, Loss: 0.0362\n",
      "Batch 1900/1995, Loss: 0.0325\n",
      "Batch 1910/1995, Loss: 0.0237\n",
      "Batch 1920/1995, Loss: 0.0123\n",
      "Batch 1930/1995, Loss: 0.0710\n",
      "Batch 1940/1995, Loss: 0.0269\n",
      "Batch 1950/1995, Loss: 0.0198\n",
      "Batch 1960/1995, Loss: 0.0554\n",
      "Batch 1970/1995, Loss: 0.0060\n",
      "Batch 1980/1995, Loss: 0.0508\n",
      "Batch 1990/1995, Loss: 0.0058\n",
      "\n",
      "Epoch 9 - Independent Model Training Complete. Loss: 0.0226\n",
      "\n",
      "Training Joint Probability Model - Epoch 9\n",
      "Batch 10/1995, Loss: 3.2010\n",
      "Batch 20/1995, Loss: 3.2010\n",
      "Batch 30/1995, Loss: 3.1854\n",
      "Batch 40/1995, Loss: 3.1854\n",
      "Batch 50/1995, Loss: 3.1854\n",
      "Batch 60/1995, Loss: 3.2010\n",
      "Batch 70/1995, Loss: 3.2010\n",
      "Batch 80/1995, Loss: 3.1854\n",
      "Batch 90/1995, Loss: 3.1854\n",
      "Batch 100/1995, Loss: 3.1854\n",
      "Batch 110/1995, Loss: 3.1854\n",
      "Batch 120/1995, Loss: 3.1854\n",
      "Batch 130/1995, Loss: 3.2010\n",
      "Batch 140/1995, Loss: 3.1854\n",
      "Batch 150/1995, Loss: 3.1854\n",
      "Batch 160/1995, Loss: 3.1854\n",
      "Batch 170/1995, Loss: 3.1854\n",
      "Batch 180/1995, Loss: 3.1854\n",
      "Batch 190/1995, Loss: 3.1854\n",
      "Batch 200/1995, Loss: 3.1854\n",
      "Batch 210/1995, Loss: 3.1854\n",
      "Batch 220/1995, Loss: 3.1854\n",
      "Batch 230/1995, Loss: 3.1854\n",
      "Batch 240/1995, Loss: 3.1854\n",
      "Batch 250/1995, Loss: 3.2010\n",
      "Batch 260/1995, Loss: 3.1854\n",
      "Batch 270/1995, Loss: 3.2166\n",
      "Batch 280/1995, Loss: 3.1854\n",
      "Batch 290/1995, Loss: 3.2010\n",
      "Batch 300/1995, Loss: 3.2010\n",
      "Batch 310/1995, Loss: 3.1854\n",
      "Batch 320/1995, Loss: 3.2010\n",
      "Batch 330/1995, Loss: 3.2010\n",
      "Batch 340/1995, Loss: 3.1854\n",
      "Batch 350/1995, Loss: 3.2010\n",
      "Batch 360/1995, Loss: 3.1854\n",
      "Batch 370/1995, Loss: 3.2010\n",
      "Batch 380/1995, Loss: 3.2166\n",
      "Batch 390/1995, Loss: 3.1854\n",
      "Batch 400/1995, Loss: 3.1854\n",
      "Batch 410/1995, Loss: 3.1854\n",
      "Batch 420/1995, Loss: 3.1854\n",
      "Batch 430/1995, Loss: 3.1854\n",
      "Batch 440/1995, Loss: 3.1854\n",
      "Batch 450/1995, Loss: 3.1854\n",
      "Batch 460/1995, Loss: 3.1854\n",
      "Batch 470/1995, Loss: 3.1854\n",
      "Batch 480/1995, Loss: 3.1854\n",
      "Batch 490/1995, Loss: 3.1854\n",
      "Batch 500/1995, Loss: 3.2323\n",
      "Batch 510/1995, Loss: 3.1854\n",
      "Batch 520/1995, Loss: 3.2010\n",
      "Batch 530/1995, Loss: 3.1854\n",
      "Batch 540/1995, Loss: 3.1854\n",
      "Batch 550/1995, Loss: 3.1854\n",
      "Batch 560/1995, Loss: 3.1854\n",
      "Batch 570/1995, Loss: 3.2010\n",
      "Batch 580/1995, Loss: 3.2323\n",
      "Batch 590/1995, Loss: 3.2010\n",
      "Batch 600/1995, Loss: 3.1854\n",
      "Batch 610/1995, Loss: 3.1854\n",
      "Batch 620/1995, Loss: 3.1854\n",
      "Batch 630/1995, Loss: 3.2010\n",
      "Batch 640/1995, Loss: 3.1854\n",
      "Batch 650/1995, Loss: 3.1854\n",
      "Batch 660/1995, Loss: 3.1854\n",
      "Batch 670/1995, Loss: 3.2166\n",
      "Batch 680/1995, Loss: 3.1854\n",
      "Batch 690/1995, Loss: 3.2010\n",
      "Batch 700/1995, Loss: 3.2166\n",
      "Batch 710/1995, Loss: 3.1854\n",
      "Batch 720/1995, Loss: 3.2010\n",
      "Batch 730/1995, Loss: 3.1854\n",
      "Batch 740/1995, Loss: 3.2010\n",
      "Batch 750/1995, Loss: 3.2166\n",
      "Batch 760/1995, Loss: 3.1854\n",
      "Batch 770/1995, Loss: 3.1854\n",
      "Batch 780/1995, Loss: 3.1854\n",
      "Batch 790/1995, Loss: 3.1854\n",
      "Batch 800/1995, Loss: 3.2010\n",
      "Batch 810/1995, Loss: 3.2010\n",
      "Batch 820/1995, Loss: 3.2010\n",
      "Batch 830/1995, Loss: 3.1854\n",
      "Batch 840/1995, Loss: 3.1854\n",
      "Batch 850/1995, Loss: 3.2010\n",
      "Batch 860/1995, Loss: 3.1854\n",
      "Batch 870/1995, Loss: 3.1854\n",
      "Batch 880/1995, Loss: 3.1854\n",
      "Batch 890/1995, Loss: 3.1854\n",
      "Batch 900/1995, Loss: 3.1854\n",
      "Batch 910/1995, Loss: 3.1854\n",
      "Batch 920/1995, Loss: 3.1854\n",
      "Batch 930/1995, Loss: 3.2010\n",
      "Batch 940/1995, Loss: 3.1854\n",
      "Batch 950/1995, Loss: 3.1854\n",
      "Batch 960/1995, Loss: 3.1854\n",
      "Batch 970/1995, Loss: 3.1854\n",
      "Batch 980/1995, Loss: 3.1854\n",
      "Batch 990/1995, Loss: 3.2010\n",
      "Batch 1000/1995, Loss: 3.2010\n",
      "Batch 1010/1995, Loss: 3.1854\n",
      "Batch 1020/1995, Loss: 3.1854\n",
      "Batch 1030/1995, Loss: 3.1854\n",
      "Batch 1040/1995, Loss: 3.1854\n",
      "Batch 1050/1995, Loss: 3.1854\n",
      "Batch 1060/1995, Loss: 3.1854\n",
      "Batch 1070/1995, Loss: 3.1854\n",
      "Batch 1080/1995, Loss: 3.2010\n",
      "Batch 1090/1995, Loss: 3.1854\n",
      "Batch 1100/1995, Loss: 3.1854\n",
      "Batch 1110/1995, Loss: 3.2010\n",
      "Batch 1120/1995, Loss: 3.2166\n",
      "Batch 1130/1995, Loss: 3.2010\n",
      "Batch 1140/1995, Loss: 3.1854\n",
      "Batch 1150/1995, Loss: 3.2010\n",
      "Batch 1160/1995, Loss: 3.1854\n",
      "Batch 1170/1995, Loss: 3.1854\n",
      "Batch 1180/1995, Loss: 3.2010\n",
      "Batch 1190/1995, Loss: 3.1854\n",
      "Batch 1200/1995, Loss: 3.2010\n",
      "Batch 1210/1995, Loss: 3.1854\n",
      "Batch 1220/1995, Loss: 3.1854\n",
      "Batch 1230/1995, Loss: 3.1854\n",
      "Batch 1240/1995, Loss: 3.2010\n",
      "Batch 1250/1995, Loss: 3.1854\n",
      "Batch 1260/1995, Loss: 3.1854\n",
      "Batch 1270/1995, Loss: 3.1854\n",
      "Batch 1280/1995, Loss: 3.1854\n",
      "Batch 1290/1995, Loss: 3.1854\n",
      "Batch 1300/1995, Loss: 3.2010\n",
      "Batch 1310/1995, Loss: 3.2010\n",
      "Batch 1320/1995, Loss: 3.1854\n",
      "Batch 1330/1995, Loss: 3.1854\n",
      "Batch 1340/1995, Loss: 3.1854\n",
      "Batch 1350/1995, Loss: 3.1854\n",
      "Batch 1360/1995, Loss: 3.1854\n",
      "Batch 1370/1995, Loss: 3.1854\n",
      "Batch 1380/1995, Loss: 3.1854\n",
      "Batch 1390/1995, Loss: 3.2010\n",
      "Batch 1400/1995, Loss: 3.2010\n",
      "Batch 1410/1995, Loss: 3.1854\n",
      "Batch 1420/1995, Loss: 3.1854\n",
      "Batch 1430/1995, Loss: 3.1854\n",
      "Batch 1440/1995, Loss: 3.1854\n",
      "Batch 1450/1995, Loss: 3.1854\n",
      "Batch 1460/1995, Loss: 3.2010\n",
      "Batch 1470/1995, Loss: 3.1854\n",
      "Batch 1480/1995, Loss: 3.1854\n",
      "Batch 1490/1995, Loss: 3.1854\n",
      "Batch 1500/1995, Loss: 3.1854\n",
      "Batch 1510/1995, Loss: 3.1854\n",
      "Batch 1520/1995, Loss: 3.1854\n",
      "Batch 1530/1995, Loss: 3.1854\n",
      "Batch 1540/1995, Loss: 3.1854\n",
      "Batch 1550/1995, Loss: 3.1854\n",
      "Batch 1560/1995, Loss: 3.1854\n",
      "Batch 1570/1995, Loss: 3.1854\n",
      "Batch 1580/1995, Loss: 3.2010\n",
      "Batch 1590/1995, Loss: 3.2010\n",
      "Batch 1600/1995, Loss: 3.1854\n",
      "Batch 1610/1995, Loss: 3.2010\n",
      "Batch 1620/1995, Loss: 3.1854\n",
      "Batch 1630/1995, Loss: 3.1854\n",
      "Batch 1640/1995, Loss: 3.2010\n",
      "Batch 1650/1995, Loss: 3.1854\n",
      "Batch 1660/1995, Loss: 3.1854\n",
      "Batch 1670/1995, Loss: 3.2166\n",
      "Batch 1680/1995, Loss: 3.1854\n",
      "Batch 1690/1995, Loss: 3.1854\n",
      "Batch 1700/1995, Loss: 3.1854\n",
      "Batch 1710/1995, Loss: 3.1854\n",
      "Batch 1720/1995, Loss: 3.1854\n",
      "Batch 1730/1995, Loss: 3.2010\n",
      "Batch 1740/1995, Loss: 3.1854\n",
      "Batch 1750/1995, Loss: 3.1854\n",
      "Batch 1760/1995, Loss: 3.1854\n",
      "Batch 1770/1995, Loss: 3.2010\n",
      "Batch 1780/1995, Loss: 3.1854\n",
      "Batch 1790/1995, Loss: 3.1854\n",
      "Batch 1800/1995, Loss: 3.1854\n",
      "Batch 1810/1995, Loss: 3.2010\n",
      "Batch 1820/1995, Loss: 3.2010\n",
      "Batch 1830/1995, Loss: 3.1854\n",
      "Batch 1840/1995, Loss: 3.1854\n",
      "Batch 1850/1995, Loss: 3.1854\n",
      "Batch 1860/1995, Loss: 3.1854\n",
      "Batch 1870/1995, Loss: 3.1854\n",
      "Batch 1880/1995, Loss: 3.1854\n",
      "Batch 1890/1995, Loss: 3.1854\n",
      "Batch 1900/1995, Loss: 3.1854\n",
      "Batch 1910/1995, Loss: 3.1854\n",
      "Batch 1920/1995, Loss: 3.1854\n",
      "Batch 1930/1995, Loss: 3.1854\n",
      "Batch 1940/1995, Loss: 3.1854\n",
      "Batch 1950/1995, Loss: 3.1854\n",
      "Batch 1960/1995, Loss: 3.1854\n",
      "Batch 1970/1995, Loss: 3.1854\n",
      "Batch 1980/1995, Loss: 3.2010\n",
      "Batch 1990/1995, Loss: 3.1854\n",
      "\n",
      "Epoch 9 - Joint Model Training Complete. Loss: 3.1912\n",
      "==================================================\n",
      "==================================================\n",
      "Starting Epoch 10 of Training\n",
      "\n",
      "\n",
      "Training Independent Probabilities Model - Epoch 10\n",
      "Batch 10/1995, Loss: 0.0135\n",
      "Batch 20/1995, Loss: 0.0336\n",
      "Batch 30/1995, Loss: 0.0023\n",
      "Batch 40/1995, Loss: 0.0192\n",
      "Batch 50/1995, Loss: 0.0254\n",
      "Batch 60/1995, Loss: 0.0169\n",
      "Batch 70/1995, Loss: 0.0250\n",
      "Batch 80/1995, Loss: 0.0146\n",
      "Batch 90/1995, Loss: 0.0401\n",
      "Batch 100/1995, Loss: 0.0344\n",
      "Batch 110/1995, Loss: 0.0189\n",
      "Batch 120/1995, Loss: 0.0227\n",
      "Batch 130/1995, Loss: 0.0271\n",
      "Batch 140/1995, Loss: 0.0143\n",
      "Batch 150/1995, Loss: 0.0247\n",
      "Batch 160/1995, Loss: 0.0036\n",
      "Batch 170/1995, Loss: 0.0053\n",
      "Batch 180/1995, Loss: 0.0348\n",
      "Batch 190/1995, Loss: 0.0336\n",
      "Batch 200/1995, Loss: 0.0338\n",
      "Batch 210/1995, Loss: 0.0148\n",
      "Batch 220/1995, Loss: 0.0292\n",
      "Batch 230/1995, Loss: 0.0373\n",
      "Batch 240/1995, Loss: 0.0236\n",
      "Batch 250/1995, Loss: 0.0247\n",
      "Batch 260/1995, Loss: 0.0111\n",
      "Batch 270/1995, Loss: 0.0340\n",
      "Batch 280/1995, Loss: 0.0276\n",
      "Batch 290/1995, Loss: 0.0367\n",
      "Batch 300/1995, Loss: 0.0149\n",
      "Batch 310/1995, Loss: 0.0234\n",
      "Batch 320/1995, Loss: 0.0411\n",
      "Batch 330/1995, Loss: 0.0109\n",
      "Batch 340/1995, Loss: 0.0186\n",
      "Batch 350/1995, Loss: 0.0376\n",
      "Batch 360/1995, Loss: 0.0031\n",
      "Batch 370/1995, Loss: 0.0139\n",
      "Batch 380/1995, Loss: 0.0493\n",
      "Batch 390/1995, Loss: 0.0379\n",
      "Batch 400/1995, Loss: 0.0285\n",
      "Batch 410/1995, Loss: 0.0016\n",
      "Batch 420/1995, Loss: 0.0154\n",
      "Batch 430/1995, Loss: 0.0146\n",
      "Batch 440/1995, Loss: 0.0311\n",
      "Batch 450/1995, Loss: 0.0115\n",
      "Batch 460/1995, Loss: 0.0051\n",
      "Batch 470/1995, Loss: 0.0127\n",
      "Batch 480/1995, Loss: 0.0058\n",
      "Batch 490/1995, Loss: 0.0309\n",
      "Batch 500/1995, Loss: 0.0126\n",
      "Batch 510/1995, Loss: 0.0082\n",
      "Batch 520/1995, Loss: 0.0390\n",
      "Batch 530/1995, Loss: 0.0283\n",
      "Batch 540/1995, Loss: 0.0157\n",
      "Batch 550/1995, Loss: 0.0299\n",
      "Batch 560/1995, Loss: 0.0586\n",
      "Batch 570/1995, Loss: 0.0000\n",
      "Batch 580/1995, Loss: 0.0144\n",
      "Batch 590/1995, Loss: 0.0029\n",
      "Batch 600/1995, Loss: 0.0138\n",
      "Batch 610/1995, Loss: 0.0263\n",
      "Batch 620/1995, Loss: 0.0248\n",
      "Batch 630/1995, Loss: 0.0373\n",
      "Batch 640/1995, Loss: 0.0290\n",
      "Batch 650/1995, Loss: 0.0159\n",
      "Batch 660/1995, Loss: 0.0354\n",
      "Batch 670/1995, Loss: 0.0271\n",
      "Batch 680/1995, Loss: 0.0202\n",
      "Batch 690/1995, Loss: 0.0467\n",
      "Batch 700/1995, Loss: 0.0212\n",
      "Batch 710/1995, Loss: 0.0162\n",
      "Batch 720/1995, Loss: 0.0061\n",
      "Batch 730/1995, Loss: 0.0312\n",
      "Batch 740/1995, Loss: 0.0052\n",
      "Batch 750/1995, Loss: 0.0263\n",
      "Batch 760/1995, Loss: 0.0033\n",
      "Batch 770/1995, Loss: 0.0197\n",
      "Batch 780/1995, Loss: 0.0362\n",
      "Batch 790/1995, Loss: 0.0311\n",
      "Batch 800/1995, Loss: 0.0202\n",
      "Batch 810/1995, Loss: 0.0141\n",
      "Batch 820/1995, Loss: 0.0105\n",
      "Batch 830/1995, Loss: 0.0035\n",
      "Batch 840/1995, Loss: 0.0285\n",
      "Batch 850/1995, Loss: 0.0113\n",
      "Batch 860/1995, Loss: 0.0106\n",
      "Batch 870/1995, Loss: 0.0205\n",
      "Batch 880/1995, Loss: 0.0268\n",
      "Batch 890/1995, Loss: 0.0133\n",
      "Batch 900/1995, Loss: 0.0230\n",
      "Batch 910/1995, Loss: 0.0066\n",
      "Batch 920/1995, Loss: 0.0091\n",
      "Batch 930/1995, Loss: 0.0184\n",
      "Batch 940/1995, Loss: 0.0426\n",
      "Batch 950/1995, Loss: 0.0212\n",
      "Batch 960/1995, Loss: 0.0198\n",
      "Batch 970/1995, Loss: 0.0131\n",
      "Batch 980/1995, Loss: 0.0089\n",
      "Batch 990/1995, Loss: 0.0011\n",
      "Batch 1000/1995, Loss: 0.0226\n",
      "Batch 1010/1995, Loss: 0.0196\n",
      "Batch 1020/1995, Loss: 0.0051\n",
      "Batch 1030/1995, Loss: 0.0215\n",
      "Batch 1040/1995, Loss: 0.0041\n",
      "Batch 1050/1995, Loss: 0.0043\n",
      "Batch 1060/1995, Loss: 0.0308\n",
      "Batch 1070/1995, Loss: 0.0060\n",
      "Batch 1080/1995, Loss: 0.0243\n",
      "Batch 1090/1995, Loss: 0.0220\n",
      "Batch 1100/1995, Loss: 0.0270\n",
      "Batch 1110/1995, Loss: 0.0199\n",
      "Batch 1120/1995, Loss: 0.0076\n",
      "Batch 1130/1995, Loss: 0.0217\n",
      "Batch 1140/1995, Loss: 0.0206\n",
      "Batch 1150/1995, Loss: 0.0412\n",
      "Batch 1160/1995, Loss: 0.0104\n",
      "Batch 1170/1995, Loss: 0.0319\n",
      "Batch 1180/1995, Loss: 0.0096\n",
      "Batch 1190/1995, Loss: 0.0163\n",
      "Batch 1200/1995, Loss: 0.0110\n",
      "Batch 1210/1995, Loss: 0.0152\n",
      "Batch 1220/1995, Loss: 0.0065\n",
      "Batch 1230/1995, Loss: 0.0370\n",
      "Batch 1240/1995, Loss: 0.0263\n",
      "Batch 1250/1995, Loss: 0.0305\n",
      "Batch 1260/1995, Loss: 0.0076\n",
      "Batch 1270/1995, Loss: 0.0046\n",
      "Batch 1280/1995, Loss: 0.0182\n",
      "Batch 1290/1995, Loss: 0.0013\n",
      "Batch 1300/1995, Loss: 0.0176\n",
      "Batch 1310/1995, Loss: 0.0453\n",
      "Batch 1320/1995, Loss: 0.0173\n",
      "Batch 1330/1995, Loss: 0.0398\n",
      "Batch 1340/1995, Loss: 0.0274\n",
      "Batch 1350/1995, Loss: 0.0124\n",
      "Batch 1360/1995, Loss: 0.0129\n",
      "Batch 1370/1995, Loss: 0.0327\n",
      "Batch 1380/1995, Loss: 0.0095\n",
      "Batch 1390/1995, Loss: 0.0219\n",
      "Batch 1400/1995, Loss: 0.0119\n",
      "Batch 1410/1995, Loss: 0.0495\n",
      "Batch 1420/1995, Loss: 0.0410\n",
      "Batch 1430/1995, Loss: 0.0196\n",
      "Batch 1440/1995, Loss: 0.0383\n",
      "Batch 1450/1995, Loss: 0.0254\n",
      "Batch 1460/1995, Loss: 0.0099\n",
      "Batch 1470/1995, Loss: 0.0257\n",
      "Batch 1480/1995, Loss: 0.0150\n",
      "Batch 1490/1995, Loss: 0.0519\n",
      "Batch 1500/1995, Loss: 0.0211\n",
      "Batch 1510/1995, Loss: 0.0337\n",
      "Batch 1520/1995, Loss: 0.0153\n",
      "Batch 1530/1995, Loss: 0.0064\n",
      "Batch 1540/1995, Loss: 0.0358\n",
      "Batch 1550/1995, Loss: 0.0195\n",
      "Batch 1560/1995, Loss: 0.0518\n",
      "Batch 1570/1995, Loss: 0.0076\n",
      "Batch 1580/1995, Loss: 0.0091\n",
      "Batch 1590/1995, Loss: 0.0042\n",
      "Batch 1600/1995, Loss: 0.0256\n",
      "Batch 1610/1995, Loss: 0.0172\n",
      "Batch 1620/1995, Loss: 0.0276\n",
      "Batch 1630/1995, Loss: 0.0136\n",
      "Batch 1640/1995, Loss: 0.0164\n",
      "Batch 1650/1995, Loss: 0.0122\n",
      "Batch 1660/1995, Loss: 0.0166\n",
      "Batch 1670/1995, Loss: 0.0154\n",
      "Batch 1680/1995, Loss: 0.0125\n",
      "Batch 1690/1995, Loss: 0.0377\n",
      "Batch 1700/1995, Loss: 0.0221\n",
      "Batch 1710/1995, Loss: 0.0304\n",
      "Batch 1720/1995, Loss: 0.0356\n",
      "Batch 1730/1995, Loss: 0.0274\n",
      "Batch 1740/1995, Loss: 0.0280\n",
      "Batch 1750/1995, Loss: 0.0184\n",
      "Batch 1760/1995, Loss: 0.0198\n",
      "Batch 1770/1995, Loss: 0.0211\n",
      "Batch 1780/1995, Loss: 0.0421\n",
      "Batch 1790/1995, Loss: 0.0244\n",
      "Batch 1800/1995, Loss: 0.0109\n",
      "Batch 1810/1995, Loss: 0.0277\n",
      "Batch 1820/1995, Loss: 0.0161\n",
      "Batch 1830/1995, Loss: 0.0295\n",
      "Batch 1840/1995, Loss: 0.0173\n",
      "Batch 1850/1995, Loss: 0.0168\n",
      "Batch 1860/1995, Loss: 0.0122\n",
      "Batch 1870/1995, Loss: 0.0116\n",
      "Batch 1880/1995, Loss: 0.0176\n",
      "Batch 1890/1995, Loss: 0.0063\n",
      "Batch 1900/1995, Loss: 0.0181\n",
      "Batch 1910/1995, Loss: 0.0193\n",
      "Batch 1920/1995, Loss: 0.0254\n",
      "Batch 1930/1995, Loss: 0.0240\n",
      "Batch 1940/1995, Loss: 0.0219\n",
      "Batch 1950/1995, Loss: 0.0193\n",
      "Batch 1960/1995, Loss: 0.0105\n",
      "Batch 1970/1995, Loss: 0.0263\n",
      "Batch 1980/1995, Loss: 0.0105\n",
      "Batch 1990/1995, Loss: 0.0215\n",
      "\n",
      "Epoch 10 - Independent Model Training Complete. Loss: 0.0207\n",
      "\n",
      "Training Joint Probability Model - Epoch 10\n",
      "Batch 10/1995, Loss: 3.1854\n",
      "Batch 20/1995, Loss: 3.1854\n",
      "Batch 30/1995, Loss: 3.1854\n",
      "Batch 40/1995, Loss: 3.2010\n",
      "Batch 50/1995, Loss: 3.1854\n",
      "Batch 60/1995, Loss: 3.2010\n",
      "Batch 70/1995, Loss: 3.2010\n",
      "Batch 80/1995, Loss: 3.1854\n",
      "Batch 90/1995, Loss: 3.2010\n",
      "Batch 100/1995, Loss: 3.1854\n",
      "Batch 110/1995, Loss: 3.1854\n",
      "Batch 120/1995, Loss: 3.1854\n",
      "Batch 130/1995, Loss: 3.1854\n",
      "Batch 140/1995, Loss: 3.2166\n",
      "Batch 150/1995, Loss: 3.1854\n",
      "Batch 160/1995, Loss: 3.1854\n",
      "Batch 170/1995, Loss: 3.1854\n",
      "Batch 180/1995, Loss: 3.1854\n",
      "Batch 190/1995, Loss: 3.1854\n",
      "Batch 200/1995, Loss: 3.1854\n",
      "Batch 210/1995, Loss: 3.1854\n",
      "Batch 220/1995, Loss: 3.1854\n",
      "Batch 230/1995, Loss: 3.1854\n",
      "Batch 240/1995, Loss: 3.1854\n",
      "Batch 250/1995, Loss: 3.1854\n",
      "Batch 260/1995, Loss: 3.1854\n",
      "Batch 270/1995, Loss: 3.1854\n",
      "Batch 280/1995, Loss: 3.2010\n",
      "Batch 290/1995, Loss: 3.2166\n",
      "Batch 300/1995, Loss: 3.1854\n",
      "Batch 310/1995, Loss: 3.2010\n",
      "Batch 320/1995, Loss: 3.1854\n",
      "Batch 330/1995, Loss: 3.2010\n",
      "Batch 340/1995, Loss: 3.1854\n",
      "Batch 350/1995, Loss: 3.2323\n",
      "Batch 360/1995, Loss: 3.1854\n",
      "Batch 370/1995, Loss: 3.1854\n",
      "Batch 380/1995, Loss: 3.1854\n",
      "Batch 390/1995, Loss: 3.1854\n",
      "Batch 400/1995, Loss: 3.1854\n",
      "Batch 410/1995, Loss: 3.1854\n",
      "Batch 420/1995, Loss: 3.1854\n",
      "Batch 430/1995, Loss: 3.1854\n",
      "Batch 440/1995, Loss: 3.1854\n",
      "Batch 450/1995, Loss: 3.1854\n",
      "Batch 460/1995, Loss: 3.1854\n",
      "Batch 470/1995, Loss: 3.1854\n",
      "Batch 480/1995, Loss: 3.1854\n",
      "Batch 490/1995, Loss: 3.2010\n",
      "Batch 500/1995, Loss: 3.2010\n",
      "Batch 510/1995, Loss: 3.2010\n",
      "Batch 520/1995, Loss: 3.1854\n",
      "Batch 530/1995, Loss: 3.1854\n",
      "Batch 540/1995, Loss: 3.1854\n",
      "Batch 550/1995, Loss: 3.1854\n",
      "Batch 560/1995, Loss: 3.1854\n",
      "Batch 570/1995, Loss: 3.2010\n",
      "Batch 580/1995, Loss: 3.1854\n",
      "Batch 590/1995, Loss: 3.1854\n",
      "Batch 600/1995, Loss: 3.2166\n",
      "Batch 610/1995, Loss: 3.1854\n",
      "Batch 620/1995, Loss: 3.1854\n",
      "Batch 630/1995, Loss: 3.1854\n",
      "Batch 640/1995, Loss: 3.2010\n",
      "Batch 650/1995, Loss: 3.1854\n",
      "Batch 660/1995, Loss: 3.1854\n",
      "Batch 670/1995, Loss: 3.2010\n",
      "Batch 680/1995, Loss: 3.1854\n",
      "Batch 690/1995, Loss: 3.2010\n",
      "Batch 700/1995, Loss: 3.1854\n",
      "Batch 710/1995, Loss: 3.2166\n",
      "Batch 720/1995, Loss: 3.2010\n",
      "Batch 730/1995, Loss: 3.1854\n",
      "Batch 740/1995, Loss: 3.1854\n",
      "Batch 750/1995, Loss: 3.1854\n",
      "Batch 760/1995, Loss: 3.1854\n",
      "Batch 770/1995, Loss: 3.1854\n",
      "Batch 780/1995, Loss: 3.1854\n",
      "Batch 790/1995, Loss: 3.1854\n",
      "Batch 800/1995, Loss: 3.2010\n",
      "Batch 810/1995, Loss: 3.1854\n",
      "Batch 820/1995, Loss: 3.2166\n",
      "Batch 830/1995, Loss: 3.1854\n",
      "Batch 840/1995, Loss: 3.2010\n",
      "Batch 850/1995, Loss: 3.1854\n",
      "Batch 860/1995, Loss: 3.1854\n",
      "Batch 870/1995, Loss: 3.1854\n",
      "Batch 880/1995, Loss: 3.2010\n",
      "Batch 890/1995, Loss: 3.2166\n",
      "Batch 900/1995, Loss: 3.1854\n",
      "Batch 910/1995, Loss: 3.1854\n",
      "Batch 920/1995, Loss: 3.2010\n",
      "Batch 930/1995, Loss: 3.2166\n",
      "Batch 940/1995, Loss: 3.1854\n",
      "Batch 950/1995, Loss: 3.1854\n",
      "Batch 960/1995, Loss: 3.1854\n",
      "Batch 970/1995, Loss: 3.2010\n",
      "Batch 980/1995, Loss: 3.1854\n",
      "Batch 990/1995, Loss: 3.1854\n",
      "Batch 1000/1995, Loss: 3.1854\n",
      "Batch 1010/1995, Loss: 3.1854\n",
      "Batch 1020/1995, Loss: 3.1854\n",
      "Batch 1030/1995, Loss: 3.1854\n",
      "Batch 1040/1995, Loss: 3.1854\n",
      "Batch 1050/1995, Loss: 3.2010\n",
      "Batch 1060/1995, Loss: 3.1854\n",
      "Batch 1070/1995, Loss: 3.1854\n",
      "Batch 1080/1995, Loss: 3.2010\n",
      "Batch 1090/1995, Loss: 3.1854\n",
      "Batch 1100/1995, Loss: 3.1854\n",
      "Batch 1110/1995, Loss: 3.1854\n",
      "Batch 1120/1995, Loss: 3.1854\n",
      "Batch 1130/1995, Loss: 3.1854\n",
      "Batch 1140/1995, Loss: 3.1854\n",
      "Batch 1150/1995, Loss: 3.1854\n",
      "Batch 1160/1995, Loss: 3.2010\n",
      "Batch 1170/1995, Loss: 3.2010\n",
      "Batch 1180/1995, Loss: 3.1854\n",
      "Batch 1190/1995, Loss: 3.1854\n",
      "Batch 1200/1995, Loss: 3.2010\n",
      "Batch 1210/1995, Loss: 3.1854\n",
      "Batch 1220/1995, Loss: 3.1854\n",
      "Batch 1230/1995, Loss: 3.1854\n",
      "Batch 1240/1995, Loss: 3.1854\n",
      "Batch 1250/1995, Loss: 3.2166\n",
      "Batch 1260/1995, Loss: 3.1854\n",
      "Batch 1270/1995, Loss: 3.1854\n",
      "Batch 1280/1995, Loss: 3.2010\n",
      "Batch 1290/1995, Loss: 3.2010\n",
      "Batch 1300/1995, Loss: 3.1854\n",
      "Batch 1310/1995, Loss: 3.1854\n",
      "Batch 1320/1995, Loss: 3.2010\n",
      "Batch 1330/1995, Loss: 3.1854\n",
      "Batch 1340/1995, Loss: 3.2010\n",
      "Batch 1350/1995, Loss: 3.2010\n",
      "Batch 1360/1995, Loss: 3.1854\n",
      "Batch 1370/1995, Loss: 3.1854\n",
      "Batch 1380/1995, Loss: 3.1854\n",
      "Batch 1390/1995, Loss: 3.2010\n",
      "Batch 1400/1995, Loss: 3.1854\n",
      "Batch 1410/1995, Loss: 3.1854\n",
      "Batch 1420/1995, Loss: 3.1854\n",
      "Batch 1430/1995, Loss: 3.2010\n",
      "Batch 1440/1995, Loss: 3.1854\n",
      "Batch 1450/1995, Loss: 3.1854\n",
      "Batch 1460/1995, Loss: 3.1854\n",
      "Batch 1470/1995, Loss: 3.2010\n",
      "Batch 1480/1995, Loss: 3.1854\n",
      "Batch 1490/1995, Loss: 3.2010\n",
      "Batch 1500/1995, Loss: 3.1854\n",
      "Batch 1510/1995, Loss: 3.2010\n",
      "Batch 1520/1995, Loss: 3.2010\n",
      "Batch 1530/1995, Loss: 3.2010\n",
      "Batch 1540/1995, Loss: 3.2010\n",
      "Batch 1550/1995, Loss: 3.2010\n",
      "Batch 1560/1995, Loss: 3.1854\n",
      "Batch 1570/1995, Loss: 3.2010\n",
      "Batch 1580/1995, Loss: 3.1854\n",
      "Batch 1590/1995, Loss: 3.1854\n",
      "Batch 1600/1995, Loss: 3.1854\n",
      "Batch 1610/1995, Loss: 3.1854\n",
      "Batch 1620/1995, Loss: 3.1854\n",
      "Batch 1630/1995, Loss: 3.2010\n",
      "Batch 1640/1995, Loss: 3.1854\n",
      "Batch 1650/1995, Loss: 3.1854\n",
      "Batch 1660/1995, Loss: 3.2010\n",
      "Batch 1670/1995, Loss: 3.1854\n",
      "Batch 1680/1995, Loss: 3.1854\n",
      "Batch 1690/1995, Loss: 3.2010\n",
      "Batch 1700/1995, Loss: 3.2010\n",
      "Batch 1710/1995, Loss: 3.2166\n",
      "Batch 1720/1995, Loss: 3.1854\n",
      "Batch 1730/1995, Loss: 3.1854\n",
      "Batch 1740/1995, Loss: 3.1854\n",
      "Batch 1750/1995, Loss: 3.1854\n",
      "Batch 1760/1995, Loss: 3.2010\n",
      "Batch 1770/1995, Loss: 3.2010\n",
      "Batch 1780/1995, Loss: 3.1854\n",
      "Batch 1790/1995, Loss: 3.1854\n",
      "Batch 1800/1995, Loss: 3.1854\n",
      "Batch 1810/1995, Loss: 3.1854\n",
      "Batch 1820/1995, Loss: 3.2010\n",
      "Batch 1830/1995, Loss: 3.1854\n",
      "Batch 1840/1995, Loss: 3.1854\n",
      "Batch 1850/1995, Loss: 3.1854\n",
      "Batch 1860/1995, Loss: 3.1854\n",
      "Batch 1870/1995, Loss: 3.1854\n",
      "Batch 1880/1995, Loss: 3.2010\n",
      "Batch 1890/1995, Loss: 3.1854\n",
      "Batch 1900/1995, Loss: 3.2166\n",
      "Batch 1910/1995, Loss: 3.1854\n",
      "Batch 1920/1995, Loss: 3.2010\n",
      "Batch 1930/1995, Loss: 3.2010\n",
      "Batch 1940/1995, Loss: 3.1854\n",
      "Batch 1950/1995, Loss: 3.1854\n",
      "Batch 1960/1995, Loss: 3.2010\n",
      "Batch 1970/1995, Loss: 3.2010\n",
      "Batch 1980/1995, Loss: 3.1854\n",
      "Batch 1990/1995, Loss: 3.1854\n",
      "\n",
      "Epoch 10 - Joint Model Training Complete. Loss: 3.1912\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "# Optimizers and Loss Functions\n",
    "independent_optimizer = optim.Adam(independent_model.parameters(), lr=0.001)\n",
    "joint_optimizer = optim.Adam(joint_model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 10\n",
    "independent_lr = lr_scheduler.LinearLR(independent_optimizer, 1.0, 0.5, epochs)\n",
    "joint_lr = lr_scheduler.LinearLR(joint_optimizer, 1.0, 0.8, epochs)\n",
    "\n",
    "bce_loss = nn.BCELoss()  # Binary Cross-Entropy Loss for independent model\n",
    "cross_entropy_loss = nn.CrossEntropyLoss()  # Cross-Entropy Loss for joint model\n",
    "\n",
    "# Training loop with clear separation\n",
    "for epoch in range(epochs):\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Starting Epoch {epoch+1} of Training\\n\")\n",
    "    \n",
    "    # Train Independent Model\n",
    "    ind_loss = train_independent_model(independent_model, train_loader, independent_optimizer, bce_loss, device, epoch)\n",
    "    independent_lr.step()\n",
    "    print(f\"\\nEpoch {epoch+1} - Independent Model Training Complete. Loss: {ind_loss:.4f}\")\n",
    "    \n",
    "    # Train Joint Model\n",
    "    joint_loss = train_joint_model(joint_model, train_loader, joint_optimizer, cross_entropy_loss, device, epoch)\n",
    "    joint_lr.step()\n",
    "    print(f\"\\nEpoch {epoch+1} - Joint Model Training Complete. Loss: {joint_loss:.4f}\")\n",
    "    \n",
    "    print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8e779c9-f17d-4430-923e-5c1bad83637a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Model...\n",
      "Processed 10/499 batches\n",
      "Processed 20/499 batches\n",
      "Processed 30/499 batches\n",
      "Processed 40/499 batches\n",
      "Processed 50/499 batches\n",
      "Processed 60/499 batches\n",
      "Processed 70/499 batches\n",
      "Processed 80/499 batches\n",
      "Processed 90/499 batches\n",
      "Processed 100/499 batches\n",
      "Processed 110/499 batches\n",
      "Processed 120/499 batches\n",
      "Processed 130/499 batches\n",
      "Processed 140/499 batches\n",
      "Processed 150/499 batches\n",
      "Processed 160/499 batches\n",
      "Processed 170/499 batches\n",
      "Processed 180/499 batches\n",
      "Processed 190/499 batches\n",
      "Processed 200/499 batches\n",
      "Processed 210/499 batches\n",
      "Processed 220/499 batches\n",
      "Processed 230/499 batches\n",
      "Processed 240/499 batches\n",
      "Processed 250/499 batches\n",
      "Processed 260/499 batches\n",
      "Processed 270/499 batches\n",
      "Processed 280/499 batches\n",
      "Processed 290/499 batches\n",
      "Processed 300/499 batches\n",
      "Processed 310/499 batches\n",
      "Processed 320/499 batches\n",
      "Processed 330/499 batches\n",
      "Processed 340/499 batches\n",
      "Processed 350/499 batches\n",
      "Processed 360/499 batches\n",
      "Processed 370/499 batches\n",
      "Processed 380/499 batches\n",
      "Processed 390/499 batches\n",
      "Processed 400/499 batches\n",
      "Processed 410/499 batches\n",
      "Processed 420/499 batches\n",
      "Processed 430/499 batches\n",
      "Processed 440/499 batches\n",
      "Processed 450/499 batches\n",
      "Processed 460/499 batches\n",
      "Processed 470/499 batches\n",
      "Processed 480/499 batches\n",
      "Processed 490/499 batches\n",
      "\n",
      "Independent Model Metrics:\n",
      "{'accuracy': 0.8948456838477205, 'f1': 0.6837982282743978, 'precision': 0.7091875474563402, 'recall': 0.6601639807746678}\n",
      "\n",
      "Evaluating Model...\n",
      "Processed 10/499 batches\n",
      "Processed 20/499 batches\n",
      "Processed 30/499 batches\n",
      "Processed 40/499 batches\n",
      "Processed 50/499 batches\n",
      "Processed 60/499 batches\n",
      "Processed 70/499 batches\n",
      "Processed 80/499 batches\n",
      "Processed 90/499 batches\n",
      "Processed 100/499 batches\n",
      "Processed 110/499 batches\n",
      "Processed 120/499 batches\n",
      "Processed 130/499 batches\n",
      "Processed 140/499 batches\n",
      "Processed 150/499 batches\n",
      "Processed 160/499 batches\n",
      "Processed 170/499 batches\n",
      "Processed 180/499 batches\n",
      "Processed 190/499 batches\n",
      "Processed 200/499 batches\n",
      "Processed 210/499 batches\n",
      "Processed 220/499 batches\n",
      "Processed 230/499 batches\n",
      "Processed 240/499 batches\n",
      "Processed 250/499 batches\n",
      "Processed 260/499 batches\n",
      "Processed 270/499 batches\n",
      "Processed 280/499 batches\n",
      "Processed 290/499 batches\n",
      "Processed 300/499 batches\n",
      "Processed 310/499 batches\n",
      "Processed 320/499 batches\n",
      "Processed 330/499 batches\n",
      "Processed 340/499 batches\n",
      "Processed 350/499 batches\n",
      "Processed 360/499 batches\n",
      "Processed 370/499 batches\n",
      "Processed 380/499 batches\n",
      "Processed 390/499 batches\n",
      "Processed 400/499 batches\n",
      "Processed 410/499 batches\n",
      "Processed 420/499 batches\n",
      "Processed 430/499 batches\n",
      "Processed 440/499 batches\n",
      "Processed 450/499 batches\n",
      "Processed 460/499 batches\n",
      "Processed 470/499 batches\n",
      "Processed 480/499 batches\n",
      "Processed 490/499 batches\n",
      "\n",
      "Joint Model Metrics:\n",
      "{'accuracy': 0.033745887513708286, 'f1': 0.1567621636871938, 'precision': 0.09575434748550839, 'recall': 0.432004523607577}\n"
     ]
    }
   ],
   "source": [
    "# Function to compute evaluation metrics\n",
    "def compute_metrics(model, data_loader, device, independent=True):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    print(\"\\nEvaluating Model...\")\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (texts, labels) in enumerate(data_loader, start=1):\n",
    "            texts, labels = texts.to(device), labels.to(device)\n",
    "            outputs = model(texts)\n",
    "            if independent:\n",
    "                preds = (outputs > 0.5).float()  # Binary predictions for independent model\n",
    "            else:\n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "                preds = torch.eye(len(labels[0]), device=device)[preds]  # Convert to multi-label format\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "            # Progress log\n",
    "            if batch_idx % 10 == 0:\n",
    "                print(f\"Processed {batch_idx}/{len(data_loader)} batches\")\n",
    "\n",
    "    all_preds = np.vstack(all_preds)\n",
    "    all_labels = np.vstack(all_labels)\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy_score(all_labels, all_preds),\n",
    "        'f1': f1_score(all_labels, all_preds, average='micro'),\n",
    "        'precision': precision_score(all_labels, all_preds, average='micro'),\n",
    "        'recall': recall_score(all_labels, all_preds, average='micro')\n",
    "    }\n",
    "\n",
    "# Compute and print metrics\n",
    "ind_metrics = compute_metrics(independent_model, val_loader, device, independent=True)\n",
    "print(\"\\nIndependent Model Metrics:\")\n",
    "print(ind_metrics)\n",
    "\n",
    "joint_metrics = compute_metrics(joint_model, val_loader, device, independent=False)\n",
    "print(\"\\nJoint Model Metrics:\")\n",
    "print(joint_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
